{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chenyq121/760-2022S2/blob/main/optunaBaselineCNN_blur_2bin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SoPqtE9ARvt",
        "outputId": "521f81c8-8f34-498c-b637-ff5c5cef079c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.7/dist-packages (3.0.2)\n",
            "Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from optuna) (0.8.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.41)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: cliff in /usr/local/lib/python3.7/dist-packages (from optuna) (3.10.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.1)\n",
            "Requirement already satisfied: scipy<1.9.0,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.7.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.7/dist-packages (from optuna) (6.7.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.8.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic>=1.5.0->optuna) (5.9.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic>=1.5.0->optuna) (1.2.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from alembic>=1.5.0->optuna) (4.12.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.3.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (5.10.0)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.4.1)\n",
            "Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.4.2)\n",
            "Requirement already satisfied: autopage>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (0.5.1)\n",
            "Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.5.0)\n",
            "Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (22.1.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->alembic>=1.5.0->optuna) (3.8.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        " pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmXCLHW-h4SH",
        "outputId": "562363a0-3d25-4b36-86d3-4ddbd95c7cb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#mounted to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOERWyx99LnQ",
        "outputId": "2f3c7a94-2dd9-4884-8826-a46de876adf1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['image_Bored_Ape.zip',\n",
              " 'Last_Sale_Price.csv',\n",
              " 'price_cleaned.csv',\n",
              " 'Bored_Ape_Dataset_Analysis.html',\n",
              " 'ape',\n",
              " '1',\n",
              " '2',\n",
              " 'temphold',\n",
              " 'ape copy',\n",
              " 'all_properties.csv',\n",
              " 'test.txt',\n",
              " 'validate.txt',\n",
              " 'train.txt',\n",
              " 'all_properties.gsheet',\n",
              " 'price_cleaned_under200.csv',\n",
              " 'u1.txt',\n",
              " 'u2.txt',\n",
              " 'test',\n",
              " 'train',\n",
              " 'u1',\n",
              " 'u2',\n",
              " 'utrain.txt',\n",
              " 'uvalidate.txt',\n",
              " 'utest.txt',\n",
              " 'Trantimes.csv',\n",
              " 'Tranaction.csv',\n",
              " 'TransactionData.html',\n",
              " 'price_cleaned_under200_log_label.numbers',\n",
              " 'log-bin.gsheet',\n",
              " 'log-bin.xlsx',\n",
              " 'pricewlabel.csv',\n",
              " 'cs760-model result track.xlsx',\n",
              " 'ID-price-label.xlsx',\n",
              " 'grey',\n",
              " 'to_archive_760project data pre-process.ipynb']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# os.chdir('/content/drive/Shareddrives/760/Data/')\n",
        "# os.getcwd()\n",
        "# os.listdir('.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bGx-ag6dALo",
        "outputId": "4a3ceafb-2c71-4985-c7cb-8852f23df434"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "x8Hvz2z2c_GB",
        "outputId": "fbe2482b-8fce-4489-8891-12849cc45ab2"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-0c934370c873>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "# import gc\n",
        "# torch.cuda.empty_cache()\n",
        "# gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZnq7JhEFn7F"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_jla9cIVPq8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import os\n",
        "import torch.utils.data\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import optuna\n",
        "\n",
        "# data processing \n",
        "class ClassifyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self,root_path,data_file,img_size=120):\n",
        "        self.data_files=np.loadtxt(data_file,dtype=np.str)\n",
        "        self.root_path=root_path\n",
        "        self.class_list=os.listdir(\n",
        "            os.path.join(root_path,'')\n",
        "        )\n",
        "        self.transforms=torchvision.transforms.Compose(\n",
        "            [\n",
        "                torchvision.transforms.Resize((img_size,img_size)), \n",
        "                torchvision.transforms.ToTensor()\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        data_file=self.data_files[item]\n",
        "        data_file=os.path.join(self.root_path,data_file)\n",
        "        # get the image\n",
        "        img=Image.open(data_file).convert('RGB') # three channels\n",
        "        # get the label(in this case the label is the folder name)\n",
        "        tmp=data_file.split('/')\n",
        "        label_name=tmp[-2]\n",
        "        #print(\"label_name:\",label_name)\n",
        "        label=self.class_list.index(label_name)\n",
        "        #print(\"label:\",label)\n",
        "        # prepare the images and label\n",
        "        img=self.transforms(img)\n",
        "        label=torch.tensor(label)\n",
        "        #print(\"torch_label:\",label)\n",
        "        return img,label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_files)\n",
        "\n",
        "\n",
        "\n",
        "# model building\n",
        "class CNet(nn.Module):\n",
        "    def __init__(self,num_classes=21, n_layer = 1, kernel_size = 1):\n",
        "        super(CNet,self).__init__()\n",
        "        self.convList = nn.ModuleList()\n",
        "\n",
        "        for i in range(1, n_layer):\n",
        "          input = 2 ** (i + 3)\n",
        "          output = 2 ** (i + 4)\n",
        "          if i == 1:\n",
        "            input = 3\n",
        "            \n",
        "          self.convList.append(\n",
        "              nn.Sequential(\n",
        "                #input, output, kernel size, step, padding\n",
        "                nn.Conv2d(input, output, kernel_size, 1, padding=1),\n",
        "                nn.BatchNorm2d(output), # batch normalization\n",
        "                nn.ReLU()\n",
        "              )\n",
        "          )\n",
        "\n",
        "        self.pool = nn.AvgPool2d(2, 2)\n",
        "        self.fclayer=nn.Sequential(\n",
        "                nn.Linear(2 * input, 2 * output),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(2 * output, num_classes)\n",
        "        )\n",
        "        self.avg_pool=nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.softmax=nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self,x):\n",
        "      x = self.convList[0](x)\n",
        "      x = self.pool(x)\n",
        "      for conv in self.convList[1:]:\n",
        "        x = conv(x)\n",
        "        x = self.pool(x)\n",
        "      x = self.avg_pool(x)\n",
        "      x = torch.flatten(x,1)\n",
        "      logits=self.fclayer(x)\n",
        "      prob=self.softmax(logits)\n",
        "      return logits,prob\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "# training\n",
        "def training(model,root_path,train_data_file,batch_size,lr, epoch_num):\n",
        "    # get training data\n",
        "    train_dataset=ClassifyDataset(root_path,train_data_file)\n",
        "    train_dataloader=torch.utils.data.DataLoader(train_dataset,batch_size,shuffle=True,num_workers=0)\n",
        "\n",
        "\n",
        "    # loss function and optimizer\n",
        "    criterion=nn.CrossEntropyLoss()\n",
        "    optimizer=torch.optim.Adam(model.parameters(),lr=lr)\n",
        "\n",
        "    total_loss=[]\n",
        "\n",
        "    for epoch in range(epoch_num):\n",
        "        # print(epoch+1,\"epoch:\")\n",
        "        total_train_loss=0\n",
        "        res_num=len(train_dataset)\n",
        "        for data in train_dataloader:\n",
        "\n",
        "            if (res_num - batch_size) > 0:\n",
        "                cnt=batch_size\n",
        "                res_num = res_num - batch_size\n",
        "            else:\n",
        "                cnt=res_num\n",
        "                res_num = 0\n",
        "\n",
        "            ## GPU\n",
        "            train_img,train_label=data\n",
        "            train_img=train_img.to(device)\n",
        "            train_label=train_label.to(device)\n",
        "\n",
        "            ## get loss result\n",
        "            train_logits,train_prob=model(train_img)\n",
        "            train_loss=criterion.forward(train_logits,train_label)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            train_pred=torch.argmax(train_prob,dim=1)\n",
        "            train_acc=(train_pred==train_label).float()\n",
        "            train_acc=torch.mean(train_acc)\n",
        "            # print('loss:',train_loss.item(), 'acc:', train_acc.item())\n",
        "            total_train_loss=total_train_loss+train_loss*cnt\n",
        "\n",
        "        total_train_loss=total_train_loss/len(train_dataset)\n",
        "        total_loss.append(total_train_loss.item())\n",
        "\n",
        "    state_dict=model.state_dict()\n",
        "    torch.save(state_dict,'/content/drive/MyDrive/model/60-20-20model_blur2bin_120-optune.pth')\n",
        "\n",
        "    # plt.xlabel('epoch')\n",
        "    # plt.ylabel('loss')\n",
        "    # plt.plot(total_loss)\n",
        "    # plt.legend(['train loss'])\n",
        "    # plt.show()\n",
        "\n",
        "# test\n",
        "def test(model,root_path,test_data_file):\n",
        "    state_dict = torch.load('/content/drive/MyDrive/model/60-20-20model_blur2bin_120-optune.pth')\n",
        "    model.load_state_dict(state_dict)\n",
        "    model.eval() # no BatchNormalization and Dropout\n",
        "\n",
        "    test_dataset=ClassifyDataset(root_path,test_data_file)\n",
        "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    res_num=len(test_dataset)\n",
        "    total_acc=0\n",
        "\n",
        "    for data in test_dataloader:\n",
        "      with torch.no_grad():\n",
        "\n",
        "        if (res_num-batch_size)>0:\n",
        "            cnt=batch_size\n",
        "            res_num = res_num - batch_size\n",
        "        else:\n",
        "            cnt=res_num\n",
        "            res_num = 0\n",
        "\n",
        "        test_img,test_label=data\n",
        "        test_img=test_img.to(device)\n",
        "        test_label=test_label.to(device)\n",
        "\n",
        "        test_logits,test_prob=model(test_img)\n",
        "        test_loss=criterion.forward(test_logits,test_label)\n",
        "\n",
        "        # Top1 accuracy: correct number/total number\n",
        "        test_pred = torch.argmax(test_prob, dim=1)\n",
        "        # print(test_pred)\n",
        "        # print(test_label)\n",
        "        test_acc = (test_pred == test_label).float()\n",
        "        # print(test_acc)\n",
        "        test_acc = torch.mean(test_acc)\n",
        "        total_acc = total_acc + test_acc * cnt\n",
        "\n",
        "        # print('loss:',test_loss.item(), 'top1:',test_acc.item() )\n",
        "\n",
        "    total_acc=total_acc/len(test_dataset)\n",
        "    return total_acc.item()\n",
        "    # print('\\n')\n",
        "    # print('Top-1 Accuracy:',total_acc.item())\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "\n",
        "    params = {\n",
        "              'n_layer': trial.suggest_int('n_layer', 3, 5, step = 2),\n",
        "              'kernel_size': trial.suggest_int('kernel_size', 3, 5, step = 2),\n",
        "              'lr': trial.suggest_categorical('lr', [0.1, 0.01, 0.001]),\n",
        "              'epoch_num': trial.suggest_categorical('epoch_num', [10, 50, 100])\n",
        "              }\n",
        "\n",
        "    # get model and put model on the device\n",
        "    model=CNet(n_layer = params['n_layer'], kernel_size = params['kernel_size'])\n",
        "    model = model.to(device)\n",
        "\n",
        "    training(model,root_path,train_data_file,batch_size,lr = params['lr'], epoch_num = params['epoch_num'])\n",
        "    # torch.cuda.empty_cache()\n",
        "    return test(model,root_path,test_data_file)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrfuOXh1T8ws"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLmTvp6vsaEW",
        "outputId": "d229e706-6e4b-4cf7-da7b-7dc3ff1a8cef"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-09-28 22:05:42,735]\u001b[0m A new study created in memory with name: no-name-a1dff2b1-2948-4c01-a657-8a37b944dd72\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  from ipykernel import kernelapp as app\n",
            "\u001b[32m[I 2022-09-28 23:28:02,746]\u001b[0m Trial 0 finished with value: 0.5207977294921875 and parameters: {'n_layer': 5, 'kernel_size': 5, 'lr': 0.01, 'epoch_num': 50}. Best is trial 0 with value: 0.5207977294921875.\u001b[0m\n",
            "\u001b[32m[I 2022-09-29 00:13:53,352]\u001b[0m Trial 1 finished with value: 0.4792022705078125 and parameters: {'n_layer': 3, 'kernel_size': 5, 'lr': 0.1, 'epoch_num': 50}. Best is trial 0 with value: 0.5207977294921875.\u001b[0m\n",
            "\u001b[32m[I 2022-09-29 01:00:02,035]\u001b[0m Trial 2 finished with value: 0.4792022705078125 and parameters: {'n_layer': 5, 'kernel_size': 3, 'lr': 0.1, 'epoch_num': 50}. Best is trial 0 with value: 0.5207977294921875.\u001b[0m\n",
            "\u001b[32m[I 2022-09-29 02:32:07,566]\u001b[0m Trial 3 finished with value: 0.4980056881904602 and parameters: {'n_layer': 5, 'kernel_size': 3, 'lr': 0.001, 'epoch_num': 100}. Best is trial 0 with value: 0.5207977294921875.\u001b[0m\n",
            "\u001b[32m[I 2022-09-29 04:04:22,502]\u001b[0m Trial 4 finished with value: 0.4792022705078125 and parameters: {'n_layer': 5, 'kernel_size': 5, 'lr': 0.1, 'epoch_num': 100}. Best is trial 0 with value: 0.5207977294921875.\u001b[0m\n",
            "\u001b[32m[I 2022-09-29 04:50:44,155]\u001b[0m Trial 5 finished with value: 0.5111110806465149 and parameters: {'n_layer': 5, 'kernel_size': 5, 'lr': 0.001, 'epoch_num': 50}. Best is trial 0 with value: 0.5207977294921875.\u001b[0m\n",
            "\u001b[32m[I 2022-09-29 06:21:53,725]\u001b[0m Trial 6 finished with value: 0.4792022705078125 and parameters: {'n_layer': 3, 'kernel_size': 5, 'lr': 0.01, 'epoch_num': 100}. Best is trial 0 with value: 0.5207977294921875.\u001b[0m\n",
            "\u001b[32m[I 2022-09-29 07:54:24,293]\u001b[0m Trial 7 finished with value: 0.49458688497543335 and parameters: {'n_layer': 3, 'kernel_size': 3, 'lr': 0.001, 'epoch_num': 100}. Best is trial 0 with value: 0.5207977294921875.\u001b[0m\n",
            "\u001b[32m[I 2022-09-29 08:03:52,624]\u001b[0m Trial 8 finished with value: 0.5236467123031616 and parameters: {'n_layer': 5, 'kernel_size': 3, 'lr': 0.1, 'epoch_num': 10}. Best is trial 8 with value: 0.5236467123031616.\u001b[0m\n",
            "\u001b[32m[I 2022-09-29 09:35:38,584]\u001b[0m Trial 9 finished with value: 0.4792022705078125 and parameters: {'n_layer': 5, 'kernel_size': 3, 'lr': 0.01, 'epoch_num': 100}. Best is trial 8 with value: 0.5236467123031616.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  from ipykernel import kernelapp as app\n",
            "\u001b[32m[I 2022-09-29 09:45:02,267]\u001b[0m Trial 10 finished with value: 0.4792022705078125 and parameters: {'n_layer': 3, 'kernel_size': 3, 'lr': 0.1, 'epoch_num': 10}. Best is trial 8 with value: 0.5236467123031616.\u001b[0m\n",
            "\u001b[32m[I 2022-09-29 09:54:32,220]\u001b[0m Trial 11 finished with value: 0.4792022705078125 and parameters: {'n_layer': 5, 'kernel_size': 5, 'lr': 0.01, 'epoch_num': 10}. Best is trial 8 with value: 0.5236467123031616.\u001b[0m\n",
            "\u001b[32m[I 2022-09-29 10:04:00,516]\u001b[0m Trial 12 finished with value: 0.4792022705078125 and parameters: {'n_layer': 5, 'kernel_size': 3, 'lr': 0.01, 'epoch_num': 10}. Best is trial 8 with value: 0.5236467123031616.\u001b[0m\n",
            "\u001b[32m[I 2022-09-29 10:13:30,952]\u001b[0m Trial 13 finished with value: 0.5207977294921875 and parameters: {'n_layer': 5, 'kernel_size': 5, 'lr': 0.01, 'epoch_num': 10}. Best is trial 8 with value: 0.5236467123031616.\u001b[0m\n",
            "\u001b[32m[I 2022-09-29 10:59:38,069]\u001b[0m Trial 14 finished with value: 0.4792022705078125 and parameters: {'n_layer': 5, 'kernel_size': 3, 'lr': 0.1, 'epoch_num': 50}. Best is trial 8 with value: 0.5236467123031616.\u001b[0m\n",
            "\u001b[32m[I 2022-09-29 11:09:07,538]\u001b[0m Trial 15 finished with value: 0.5207977294921875 and parameters: {'n_layer': 5, 'kernel_size': 5, 'lr': 0.1, 'epoch_num': 10}. Best is trial 8 with value: 0.5236467123031616.\u001b[0m\n",
            "\u001b[32m[I 2022-09-29 11:55:14,159]\u001b[0m Trial 16 finished with value: 0.5207977294921875 and parameters: {'n_layer': 5, 'kernel_size': 3, 'lr': 0.01, 'epoch_num': 50}. Best is trial 8 with value: 0.5236467123031616.\u001b[0m\n",
            "\u001b[32m[I 2022-09-29 12:04:38,273]\u001b[0m Trial 17 finished with value: 0.4792022705078125 and parameters: {'n_layer': 3, 'kernel_size': 5, 'lr': 0.1, 'epoch_num': 10}. Best is trial 8 with value: 0.5236467123031616.\u001b[0m\n",
            "\u001b[32m[I 2022-09-29 12:14:07,088]\u001b[0m Trial 18 finished with value: 0.4792022705078125 and parameters: {'n_layer': 5, 'kernel_size': 3, 'lr': 0.1, 'epoch_num': 10}. Best is trial 8 with value: 0.5236467123031616.\u001b[0m\n",
            "\u001b[32m[I 2022-09-29 13:00:33,889]\u001b[0m Trial 19 finished with value: 0.48547008633613586 and parameters: {'n_layer': 5, 'kernel_size': 5, 'lr': 0.01, 'epoch_num': 50}. Best is trial 8 with value: 0.5236467123031616.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# optuna hyperparameter tuning\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    root_path = r'/content/drive/MyDrive/blur/'\n",
        "    train_data_file=r'/content/drive/MyDrive/blur/2bintrain.txt'\n",
        "    test_data_file=r'/content/drive/MyDrive/blur/2binvalidate.txt'\n",
        "    batch_size=64\n",
        "    os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    \n",
        "    study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
        "    study.optimize(objective, n_trials=40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGIqptr5Lq0M"
      },
      "outputs": [],
      "source": [
        "best_trial = study.best_trial\n",
        "\n",
        "for key, value in best_trial.params.items():\n",
        "    print(\"{}: {}\".format(key, value))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18PQyWnUPSQp",
        "outputId": "b18bf60a-8df5-41e5-f748-637aa7716f9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ead32857dee2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_optimization_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'optuna' is not defined"
          ]
        }
      ],
      "source": [
        "optuna.visualization.plot_optimization_history(study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78US6cYbaYAI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import os\n",
        "import torch.utils.data\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import optuna\n",
        "\n",
        "# data processing \n",
        "class ClassifyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self,root_path,data_file,img_size=120):\n",
        "        self.data_files=np.loadtxt(data_file,dtype=np.str)\n",
        "        self.root_path=root_path\n",
        "        self.class_list=os.listdir(\n",
        "            os.path.join(root_path,'')\n",
        "        )\n",
        "        self.transforms=torchvision.transforms.Compose(\n",
        "            [\n",
        "                torchvision.transforms.Resize((img_size,img_size)), \n",
        "                torchvision.transforms.ToTensor()\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        data_file=self.data_files[item]\n",
        "        data_file=os.path.join(self.root_path,data_file)\n",
        "        # get the image\n",
        "        img=Image.open(data_file).convert('RGB') # three channels\n",
        "        # get the label(in this case the label is the folder name)\n",
        "        tmp=data_file.split('/')\n",
        "        label_name=tmp[-2]\n",
        "        #print(\"label_name:\",label_name)\n",
        "        label=self.class_list.index(label_name)\n",
        "        #print(\"label:\",label)\n",
        "        # prepare the images and label\n",
        "        img=self.transforms(img)\n",
        "        label=torch.tensor(label)\n",
        "        #print(\"torch_label:\",label)\n",
        "        return img,label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_files)\n",
        "\n",
        "\n",
        "\n",
        "# model building\n",
        "class CNet(nn.Module):\n",
        "    def __init__(self,num_classes=21, n_layer = 1, kernel_size = 1):\n",
        "        super(CNet,self).__init__()\n",
        "        self.convList = nn.ModuleList()\n",
        "\n",
        "        for i in range(1, n_layer):\n",
        "          input = 2 ** (i + 3)\n",
        "          output = 2 ** (i + 4)\n",
        "          if i == 1:\n",
        "            input = 3\n",
        "            \n",
        "          self.convList.append(\n",
        "              nn.Sequential(\n",
        "                #input, output, kernel size, step, padding\n",
        "                nn.Conv2d(input, output, kernel_size, 1, padding=1),\n",
        "                nn.BatchNorm2d(output), # batch normalization\n",
        "                nn.ReLU()\n",
        "              )\n",
        "          )\n",
        "\n",
        "        self.pool = nn.AvgPool2d(2, 2)\n",
        "        self.fclayer=nn.Sequential(\n",
        "                nn.Linear(2 * input, 2 * output),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(2 * output, num_classes)\n",
        "        )\n",
        "        self.avg_pool=nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.softmax=nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self,x):\n",
        "      x = self.convList[0](x)\n",
        "      x = self.pool(x)\n",
        "      for conv in self.convList[1:]:\n",
        "        x = conv(x)\n",
        "        x = self.pool(x)\n",
        "      x = self.avg_pool(x)\n",
        "      x = torch.flatten(x,1)\n",
        "      logits=self.fclayer(x)\n",
        "      prob=self.softmax(logits)\n",
        "      return logits,prob\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "# training\n",
        "def training(model,root_path,train_data_file,batch_size,lr, epoch_num):\n",
        "    # get training data\n",
        "    train_dataset=ClassifyDataset(root_path,train_data_file)\n",
        "    train_dataloader=torch.utils.data.DataLoader(train_dataset,batch_size,shuffle=True,num_workers=0)\n",
        "\n",
        "\n",
        "    # loss function and optimizer\n",
        "    criterion=nn.CrossEntropyLoss()\n",
        "    optimizer=torch.optim.Adam(model.parameters(),lr=lr)\n",
        "\n",
        "    total_loss=[]\n",
        "\n",
        "    for epoch in range(epoch_num):\n",
        "        print(epoch+1,\"epoch:\")\n",
        "        total_train_loss=0\n",
        "        res_num=len(train_dataset)\n",
        "        for data in train_dataloader:\n",
        "\n",
        "            if (res_num - batch_size) > 0:\n",
        "                cnt=batch_size\n",
        "                res_num = res_num - batch_size\n",
        "            else:\n",
        "                cnt=res_num\n",
        "                res_num = 0\n",
        "\n",
        "            ## GPU\n",
        "            train_img,train_label=data\n",
        "            train_img=train_img.to(device)\n",
        "            train_label=train_label.to(device)\n",
        "\n",
        "            ## get loss result\n",
        "            train_logits,train_prob=model(train_img)\n",
        "            train_loss=criterion.forward(train_logits,train_label)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            train_pred=torch.argmax(train_prob,dim=1)\n",
        "            train_acc=(train_pred==train_label).float()\n",
        "            train_acc=torch.mean(train_acc)\n",
        "            # print('loss:',train_loss.item(), 'acc:', train_acc.item())\n",
        "            total_train_loss=total_train_loss+train_loss*cnt\n",
        "\n",
        "        total_train_loss=total_train_loss/len(train_dataset)\n",
        "        total_loss.append(total_train_loss.item())\n",
        "\n",
        "    state_dict=model.state_dict()\n",
        "    torch.save(state_dict,'/content/drive/MyDrive/model/60-20-20model_grey2bin_120-optune.pth')\n",
        "\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.plot(total_loss)\n",
        "    plt.legend(['train loss'])\n",
        "    plt.show()\n",
        "\n",
        "# test\n",
        "def test(model,root_path,test_data_file):\n",
        "    state_dict = torch.load('/content/drive/MyDrive/model/60-20-20model_grey2bin_120-optune.pth')\n",
        "    model.load_state_dict(state_dict)\n",
        "    model.eval() # no BatchNormalization and Dropout\n",
        "\n",
        "    test_dataset=ClassifyDataset(root_path,test_data_file)\n",
        "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    res_num=len(test_dataset)\n",
        "    total_acc=0\n",
        "\n",
        "    for data in test_dataloader:\n",
        "      with torch.no_grad():\n",
        "\n",
        "        if (res_num-batch_size)>0:\n",
        "            cnt=batch_size\n",
        "            res_num = res_num - batch_size\n",
        "        else:\n",
        "            cnt=res_num\n",
        "            res_num = 0\n",
        "\n",
        "        test_img,test_label=data\n",
        "        test_img=test_img.to(device)\n",
        "        test_label=test_label.to(device)\n",
        "\n",
        "        test_logits,test_prob=model(test_img)\n",
        "        test_loss=criterion.forward(test_logits,test_label)\n",
        "\n",
        "        # Top1 accuracy: correct number/total number\n",
        "        test_pred = torch.argmax(test_prob, dim=1)\n",
        "        # print(test_pred)\n",
        "        # print(test_label)\n",
        "        test_acc = (test_pred == test_label).float()\n",
        "        # print(test_acc)\n",
        "        test_acc = torch.mean(test_acc)\n",
        "        total_acc = total_acc + test_acc * cnt\n",
        "\n",
        "        print('loss:',test_loss.item(), 'top1:',test_acc.item() )\n",
        "\n",
        "    total_acc=total_acc/len(test_dataset)\n",
        "    # return total_acc.item()\n",
        "    print('\\n')\n",
        "    print('Top-1 Accuracy:',total_acc.item())\n",
        "\n",
        "\n",
        "# def objective(trial):\n",
        "\n",
        "#     params = {\n",
        "#               'n_layer': trial.suggest_int('n_layer', 3, 5, step = 2),\n",
        "#               'kernel_size': trial.suggest_int('kernel_size', 3, 5, step = 2),\n",
        "#               'lr': trial.suggest_categorical('lr', [0.1, 0.01, 0.001]),\n",
        "#               'epoch_num': trial.suggest_categorical('epoch_num', [10, 50, 100])\n",
        "#               }\n",
        "\n",
        "#     # get model and put model on the device\n",
        "#     model=CNet(n_layer = params['n_layer'], kernel_size = params['kernel_size'])\n",
        "#     model = model.to(device)\n",
        "\n",
        "#     training(model,root_path,train_data_file,batch_size,lr = params['lr'], epoch_num = params['epoch_num'])\n",
        "#     # torch.cuda.empty_cache()\n",
        "#     return test(model,root_path,test_data_file)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bXnX0BP_MHNq",
        "outputId": "f11dc9f8-4c2c-483b-a6d2-be42ca9add41"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "loss: 2.090175151824951 acc: 0.203125\n",
            "loss: 2.0603489875793457 acc: 0.15625\n",
            "loss: 2.054953098297119 acc: 0.171875\n",
            "loss: 2.030704975128174 acc: 0.203125\n",
            "loss: 2.0503435134887695 acc: 0.1860465109348297\n",
            "56 epoch:\n",
            "loss: 2.058945417404175 acc: 0.171875\n",
            "loss: 2.0855653285980225 acc: 0.140625\n",
            "loss: 2.0699968338012695 acc: 0.140625\n",
            "loss: 2.062981367111206 acc: 0.15625\n",
            "loss: 2.0892908573150635 acc: 0.078125\n",
            "loss: 2.014535903930664 acc: 0.203125\n",
            "loss: 2.0951430797576904 acc: 0.140625\n",
            "loss: 2.0749154090881348 acc: 0.15625\n",
            "loss: 2.0650835037231445 acc: 0.171875\n",
            "loss: 2.013392210006714 acc: 0.21875\n",
            "loss: 2.0568532943725586 acc: 0.109375\n",
            "loss: 2.0539324283599854 acc: 0.109375\n",
            "loss: 2.0747549533843994 acc: 0.140625\n",
            "loss: 2.041456699371338 acc: 0.15625\n",
            "loss: 2.091939687728882 acc: 0.109375\n",
            "loss: 2.1047286987304688 acc: 0.078125\n",
            "loss: 2.048380136489868 acc: 0.234375\n",
            "loss: 2.0555310249328613 acc: 0.15625\n",
            "loss: 2.1041696071624756 acc: 0.1875\n",
            "loss: 2.0541858673095703 acc: 0.140625\n",
            "loss: 2.093601942062378 acc: 0.140625\n",
            "loss: 2.087441921234131 acc: 0.109375\n",
            "loss: 2.058701276779175 acc: 0.171875\n",
            "loss: 2.084864854812622 acc: 0.140625\n",
            "loss: 2.065110445022583 acc: 0.109375\n",
            "loss: 2.0691821575164795 acc: 0.078125\n",
            "loss: 2.0662357807159424 acc: 0.078125\n",
            "loss: 2.0514650344848633 acc: 0.21875\n",
            "loss: 2.0545921325683594 acc: 0.1875\n",
            "loss: 2.070802688598633 acc: 0.140625\n",
            "loss: 2.097522497177124 acc: 0.09375\n",
            "loss: 2.0676581859588623 acc: 0.125\n",
            "loss: 2.082852602005005 acc: 0.09375\n",
            "loss: 2.0432932376861572 acc: 0.25\n",
            "loss: 2.03732967376709 acc: 0.1875\n",
            "loss: 2.0459961891174316 acc: 0.203125\n",
            "loss: 2.103517532348633 acc: 0.09375\n",
            "loss: 2.055633068084717 acc: 0.171875\n",
            "loss: 2.0512826442718506 acc: 0.15625\n",
            "loss: 2.056802749633789 acc: 0.171875\n",
            "loss: 2.077669620513916 acc: 0.0625\n",
            "loss: 2.0412485599517822 acc: 0.1875\n",
            "loss: 2.019103765487671 acc: 0.234375\n",
            "loss: 2.0431272983551025 acc: 0.203125\n",
            "loss: 2.0855188369750977 acc: 0.15625\n",
            "loss: 2.1107261180877686 acc: 0.046875\n",
            "loss: 2.0655229091644287 acc: 0.171875\n",
            "loss: 2.0836730003356934 acc: 0.140625\n",
            "loss: 2.0422139167785645 acc: 0.0625\n",
            "loss: 2.0299644470214844 acc: 0.234375\n",
            "loss: 2.099538803100586 acc: 0.140625\n",
            "loss: 2.037992238998413 acc: 0.203125\n",
            "loss: 2.0446043014526367 acc: 0.171875\n",
            "loss: 2.0548014640808105 acc: 0.21875\n",
            "loss: 2.0713438987731934 acc: 0.125\n",
            "loss: 2.0454330444335938 acc: 0.140625\n",
            "loss: 2.0619428157806396 acc: 0.09375\n",
            "loss: 2.072718620300293 acc: 0.140625\n",
            "loss: 2.0427405834198 acc: 0.21875\n",
            "loss: 2.096487283706665 acc: 0.140625\n",
            "loss: 2.0791592597961426 acc: 0.171875\n",
            "loss: 2.0732216835021973 acc: 0.140625\n",
            "loss: 2.0889172554016113 acc: 0.171875\n",
            "loss: 2.0627362728118896 acc: 0.15625\n",
            "loss: 2.0799927711486816 acc: 0.140625\n",
            "loss: 2.1027657985687256 acc: 0.109375\n",
            "loss: 2.06152606010437 acc: 0.171875\n",
            "loss: 2.099531650543213 acc: 0.109375\n",
            "loss: 2.099982738494873 acc: 0.09375\n",
            "loss: 2.0880050659179688 acc: 0.203125\n",
            "loss: 2.069744110107422 acc: 0.078125\n",
            "loss: 2.089655637741089 acc: 0.109375\n",
            "loss: 2.0571160316467285 acc: 0.15625\n",
            "loss: 2.054863929748535 acc: 0.15625\n",
            "loss: 2.0682663917541504 acc: 0.1875\n",
            "loss: 2.07075834274292 acc: 0.140625\n",
            "loss: 2.090583562850952 acc: 0.109375\n",
            "loss: 2.040861129760742 acc: 0.15625\n",
            "loss: 2.098703384399414 acc: 0.109375\n",
            "loss: 2.0773422718048096 acc: 0.140625\n",
            "loss: 2.0714898109436035 acc: 0.109375\n",
            "loss: 2.017496109008789 acc: 0.265625\n",
            "loss: 2.0740857124328613 acc: 0.1875\n",
            "loss: 2.0675361156463623 acc: 0.109375\n",
            "loss: 2.06807804107666 acc: 0.171875\n",
            "loss: 2.0518178939819336 acc: 0.1875\n",
            "loss: 2.0837671756744385 acc: 0.09375\n",
            "loss: 2.0302906036376953 acc: 0.15625\n",
            "loss: 2.081390142440796 acc: 0.15625\n",
            "loss: 2.063683032989502 acc: 0.125\n",
            "loss: 2.082548141479492 acc: 0.203125\n",
            "loss: 2.0714850425720215 acc: 0.109375\n",
            "loss: 2.0759096145629883 acc: 0.140625\n",
            "loss: 2.0704944133758545 acc: 0.203125\n",
            "loss: 2.0526881217956543 acc: 0.1875\n",
            "loss: 2.0478272438049316 acc: 0.234375\n",
            "loss: 2.0571675300598145 acc: 0.109375\n",
            "loss: 2.0463781356811523 acc: 0.109375\n",
            "loss: 2.0737783908843994 acc: 0.203125\n",
            "loss: 2.0656371116638184 acc: 0.171875\n",
            "loss: 2.0890696048736572 acc: 0.15625\n",
            "loss: 2.0685126781463623 acc: 0.109375\n",
            "loss: 2.045621633529663 acc: 0.140625\n",
            "loss: 2.080329418182373 acc: 0.078125\n",
            "loss: 2.042543888092041 acc: 0.125\n",
            "loss: 2.026104688644409 acc: 0.21875\n",
            "loss: 2.0789895057678223 acc: 0.171875\n",
            "loss: 2.083352565765381 acc: 0.140625\n",
            "loss: 2.065776824951172 acc: 0.140625\n",
            "loss: 2.0244741439819336 acc: 0.25581395626068115\n",
            "57 epoch:\n",
            "loss: 2.0396318435668945 acc: 0.15625\n",
            "loss: 2.076807975769043 acc: 0.09375\n",
            "loss: 2.086326837539673 acc: 0.09375\n",
            "loss: 2.031217336654663 acc: 0.234375\n",
            "loss: 2.0541839599609375 acc: 0.125\n",
            "loss: 2.0765531063079834 acc: 0.125\n",
            "loss: 2.111740827560425 acc: 0.140625\n",
            "loss: 2.0821785926818848 acc: 0.171875\n",
            "loss: 2.0821619033813477 acc: 0.125\n",
            "loss: 2.080195188522339 acc: 0.09375\n",
            "loss: 2.0251212120056152 acc: 0.171875\n",
            "loss: 2.085519313812256 acc: 0.0625\n",
            "loss: 2.0643582344055176 acc: 0.15625\n",
            "loss: 2.0278992652893066 acc: 0.203125\n",
            "loss: 2.0546317100524902 acc: 0.203125\n",
            "loss: 2.066382884979248 acc: 0.171875\n",
            "loss: 2.07997989654541 acc: 0.125\n",
            "loss: 2.0784943103790283 acc: 0.140625\n",
            "loss: 2.0877134799957275 acc: 0.140625\n",
            "loss: 2.112941026687622 acc: 0.0625\n",
            "loss: 2.0968194007873535 acc: 0.109375\n",
            "loss: 2.049706220626831 acc: 0.203125\n",
            "loss: 2.1326727867126465 acc: 0.0625\n",
            "loss: 2.048874855041504 acc: 0.15625\n",
            "loss: 2.0658762454986572 acc: 0.15625\n",
            "loss: 2.0323128700256348 acc: 0.265625\n",
            "loss: 2.104649782180786 acc: 0.109375\n",
            "loss: 2.052341938018799 acc: 0.1875\n",
            "loss: 2.057997941970825 acc: 0.203125\n",
            "loss: 2.0612189769744873 acc: 0.109375\n",
            "loss: 2.045602560043335 acc: 0.203125\n",
            "loss: 2.0595526695251465 acc: 0.1875\n",
            "loss: 2.0459539890289307 acc: 0.109375\n",
            "loss: 2.0711121559143066 acc: 0.09375\n",
            "loss: 2.086421012878418 acc: 0.109375\n",
            "loss: 2.0502638816833496 acc: 0.140625\n",
            "loss: 2.041829824447632 acc: 0.15625\n",
            "loss: 2.0227112770080566 acc: 0.203125\n",
            "loss: 2.048091173171997 acc: 0.21875\n",
            "loss: 2.072964668273926 acc: 0.109375\n",
            "loss: 2.0635061264038086 acc: 0.09375\n",
            "loss: 2.053502082824707 acc: 0.21875\n",
            "loss: 2.075819969177246 acc: 0.140625\n",
            "loss: 2.0836355686187744 acc: 0.109375\n",
            "loss: 2.0885069370269775 acc: 0.140625\n",
            "loss: 2.039607524871826 acc: 0.15625\n",
            "loss: 2.0706534385681152 acc: 0.21875\n",
            "loss: 2.0767621994018555 acc: 0.109375\n",
            "loss: 2.0640010833740234 acc: 0.140625\n",
            "loss: 2.0611472129821777 acc: 0.109375\n",
            "loss: 2.0902199745178223 acc: 0.15625\n",
            "loss: 2.101919412612915 acc: 0.15625\n",
            "loss: 2.0888512134552 acc: 0.125\n",
            "loss: 2.0859267711639404 acc: 0.125\n",
            "loss: 2.0808563232421875 acc: 0.15625\n",
            "loss: 2.0956919193267822 acc: 0.09375\n",
            "loss: 2.096731185913086 acc: 0.203125\n",
            "loss: 2.0674691200256348 acc: 0.125\n",
            "loss: 2.0692007541656494 acc: 0.203125\n",
            "loss: 2.0885539054870605 acc: 0.140625\n",
            "loss: 2.060380458831787 acc: 0.125\n",
            "loss: 2.0826146602630615 acc: 0.15625\n",
            "loss: 2.0636518001556396 acc: 0.109375\n",
            "loss: 2.0687553882598877 acc: 0.171875\n",
            "loss: 2.0534279346466064 acc: 0.1875\n",
            "loss: 2.0645408630371094 acc: 0.15625\n",
            "loss: 2.0537521839141846 acc: 0.109375\n",
            "loss: 2.088848829269409 acc: 0.125\n",
            "loss: 2.064399242401123 acc: 0.15625\n",
            "loss: 2.045380115509033 acc: 0.125\n",
            "loss: 2.0792927742004395 acc: 0.140625\n",
            "loss: 2.0802743434906006 acc: 0.15625\n",
            "loss: 2.067770481109619 acc: 0.109375\n",
            "loss: 2.024704694747925 acc: 0.21875\n",
            "loss: 2.108217239379883 acc: 0.09375\n",
            "loss: 2.1096720695495605 acc: 0.109375\n",
            "loss: 2.0564162731170654 acc: 0.15625\n",
            "loss: 2.072190046310425 acc: 0.109375\n",
            "loss: 2.0884742736816406 acc: 0.0625\n",
            "loss: 2.0552709102630615 acc: 0.125\n",
            "loss: 2.079841136932373 acc: 0.21875\n",
            "loss: 2.066082715988159 acc: 0.171875\n",
            "loss: 2.0768332481384277 acc: 0.140625\n",
            "loss: 2.067758560180664 acc: 0.1875\n",
            "loss: 2.1080164909362793 acc: 0.09375\n",
            "loss: 2.072805881500244 acc: 0.109375\n",
            "loss: 2.068577289581299 acc: 0.125\n",
            "loss: 2.025031805038452 acc: 0.1875\n",
            "loss: 2.0762059688568115 acc: 0.15625\n",
            "loss: 2.063074827194214 acc: 0.15625\n",
            "loss: 2.0749263763427734 acc: 0.1875\n",
            "loss: 2.0798635482788086 acc: 0.125\n",
            "loss: 2.0531370639801025 acc: 0.125\n",
            "loss: 2.077584981918335 acc: 0.203125\n",
            "loss: 2.0915751457214355 acc: 0.109375\n",
            "loss: 2.0635335445404053 acc: 0.15625\n",
            "loss: 2.11491322517395 acc: 0.09375\n",
            "loss: 2.0671842098236084 acc: 0.125\n",
            "loss: 2.0661487579345703 acc: 0.234375\n",
            "loss: 2.053938627243042 acc: 0.15625\n",
            "loss: 2.0774965286254883 acc: 0.125\n",
            "loss: 2.0952746868133545 acc: 0.09375\n",
            "loss: 2.1100218296051025 acc: 0.171875\n",
            "loss: 2.0744287967681885 acc: 0.140625\n",
            "loss: 2.0618820190429688 acc: 0.125\n",
            "loss: 2.046441078186035 acc: 0.171875\n",
            "loss: 2.0672109127044678 acc: 0.171875\n",
            "loss: 2.075415849685669 acc: 0.140625\n",
            "loss: 2.0685384273529053 acc: 0.125\n",
            "loss: 2.0748274326324463 acc: 0.09302325546741486\n",
            "58 epoch:\n",
            "loss: 2.048847198486328 acc: 0.125\n",
            "loss: 2.0597763061523438 acc: 0.171875\n",
            "loss: 2.056521415710449 acc: 0.21875\n",
            "loss: 2.0538110733032227 acc: 0.171875\n",
            "loss: 2.0480458736419678 acc: 0.15625\n",
            "loss: 2.0914013385772705 acc: 0.203125\n",
            "loss: 2.0559914112091064 acc: 0.140625\n",
            "loss: 2.0783803462982178 acc: 0.15625\n",
            "loss: 2.0591516494750977 acc: 0.109375\n",
            "loss: 2.0567877292633057 acc: 0.15625\n",
            "loss: 2.04231858253479 acc: 0.140625\n",
            "loss: 2.0628769397735596 acc: 0.109375\n",
            "loss: 2.096806049346924 acc: 0.09375\n",
            "loss: 2.057413339614868 acc: 0.1875\n",
            "loss: 2.053192615509033 acc: 0.21875\n",
            "loss: 2.0440969467163086 acc: 0.140625\n",
            "loss: 2.081789970397949 acc: 0.09375\n",
            "loss: 2.0291624069213867 acc: 0.125\n",
            "loss: 2.0782904624938965 acc: 0.078125\n",
            "loss: 2.0698885917663574 acc: 0.15625\n",
            "loss: 2.055469274520874 acc: 0.109375\n",
            "loss: 2.0414819717407227 acc: 0.265625\n",
            "loss: 2.0515496730804443 acc: 0.109375\n",
            "loss: 2.0839078426361084 acc: 0.125\n",
            "loss: 2.0538833141326904 acc: 0.125\n",
            "loss: 2.056891918182373 acc: 0.125\n",
            "loss: 2.0688440799713135 acc: 0.171875\n",
            "loss: 2.095071792602539 acc: 0.15625\n",
            "loss: 2.0715887546539307 acc: 0.125\n",
            "loss: 2.061278820037842 acc: 0.21875\n",
            "loss: 2.076467990875244 acc: 0.1875\n",
            "loss: 2.08320951461792 acc: 0.125\n",
            "loss: 2.045536518096924 acc: 0.125\n",
            "loss: 2.093987226486206 acc: 0.109375\n",
            "loss: 2.0425498485565186 acc: 0.203125\n",
            "loss: 2.0689773559570312 acc: 0.109375\n",
            "loss: 2.079399347305298 acc: 0.125\n",
            "loss: 2.040822744369507 acc: 0.15625\n",
            "loss: 2.0597939491271973 acc: 0.203125\n",
            "loss: 2.084312915802002 acc: 0.15625\n",
            "loss: 2.0865931510925293 acc: 0.109375\n",
            "loss: 2.0650241374969482 acc: 0.109375\n",
            "loss: 2.0455803871154785 acc: 0.140625\n",
            "loss: 2.071829319000244 acc: 0.171875\n",
            "loss: 2.058372735977173 acc: 0.171875\n",
            "loss: 2.0536246299743652 acc: 0.265625\n",
            "loss: 2.095227003097534 acc: 0.0625\n",
            "loss: 2.061455726623535 acc: 0.109375\n",
            "loss: 2.0866456031799316 acc: 0.203125\n",
            "loss: 2.061386823654175 acc: 0.140625\n",
            "loss: 2.030263900756836 acc: 0.21875\n",
            "loss: 2.0826416015625 acc: 0.1875\n",
            "loss: 2.060960054397583 acc: 0.15625\n",
            "loss: 2.087095260620117 acc: 0.078125\n",
            "loss: 2.0558531284332275 acc: 0.171875\n",
            "loss: 2.085822105407715 acc: 0.171875\n",
            "loss: 2.0288240909576416 acc: 0.25\n",
            "loss: 2.0787675380706787 acc: 0.125\n",
            "loss: 2.056999683380127 acc: 0.125\n",
            "loss: 2.0454423427581787 acc: 0.171875\n",
            "loss: 2.0684621334075928 acc: 0.1875\n",
            "loss: 2.0623421669006348 acc: 0.140625\n",
            "loss: 2.0728492736816406 acc: 0.125\n",
            "loss: 2.0803017616271973 acc: 0.1875\n",
            "loss: 2.044780969619751 acc: 0.109375\n",
            "loss: 2.0891318321228027 acc: 0.0625\n",
            "loss: 2.083916664123535 acc: 0.15625\n",
            "loss: 2.0520899295806885 acc: 0.140625\n",
            "loss: 2.079233169555664 acc: 0.0625\n",
            "loss: 2.1230390071868896 acc: 0.140625\n",
            "loss: 2.066931962966919 acc: 0.1875\n",
            "loss: 2.072553873062134 acc: 0.171875\n",
            "loss: 2.0513322353363037 acc: 0.1875\n",
            "loss: 2.0483717918395996 acc: 0.25\n",
            "loss: 2.048966646194458 acc: 0.171875\n",
            "loss: 2.0500545501708984 acc: 0.09375\n",
            "loss: 2.0668699741363525 acc: 0.140625\n",
            "loss: 2.0869762897491455 acc: 0.171875\n",
            "loss: 2.095064640045166 acc: 0.125\n",
            "loss: 2.030061960220337 acc: 0.203125\n",
            "loss: 2.0848538875579834 acc: 0.125\n",
            "loss: 2.0399250984191895 acc: 0.203125\n",
            "loss: 2.0540473461151123 acc: 0.203125\n",
            "loss: 2.0569186210632324 acc: 0.1875\n",
            "loss: 2.071366548538208 acc: 0.171875\n",
            "loss: 2.0761783123016357 acc: 0.109375\n",
            "loss: 2.1114437580108643 acc: 0.046875\n",
            "loss: 2.076596975326538 acc: 0.109375\n",
            "loss: 2.041682243347168 acc: 0.15625\n",
            "loss: 2.0641634464263916 acc: 0.171875\n",
            "loss: 2.053802967071533 acc: 0.140625\n",
            "loss: 2.0486762523651123 acc: 0.109375\n",
            "loss: 2.062258243560791 acc: 0.140625\n",
            "loss: 2.088052749633789 acc: 0.203125\n",
            "loss: 2.09032940864563 acc: 0.109375\n",
            "loss: 2.051459550857544 acc: 0.078125\n",
            "loss: 2.0161561965942383 acc: 0.3125\n",
            "loss: 2.1268341541290283 acc: 0.046875\n",
            "loss: 2.051767587661743 acc: 0.140625\n",
            "loss: 2.093743085861206 acc: 0.15625\n",
            "loss: 2.0873587131500244 acc: 0.140625\n",
            "loss: 2.053682804107666 acc: 0.203125\n",
            "loss: 2.0590996742248535 acc: 0.171875\n",
            "loss: 2.074185371398926 acc: 0.109375\n",
            "loss: 2.0583853721618652 acc: 0.1875\n",
            "loss: 2.0465774536132812 acc: 0.203125\n",
            "loss: 2.0723278522491455 acc: 0.140625\n",
            "loss: 2.072058916091919 acc: 0.109375\n",
            "loss: 2.0635523796081543 acc: 0.140625\n",
            "loss: 2.0844533443450928 acc: 0.11627906560897827\n",
            "59 epoch:\n",
            "loss: 2.085723638534546 acc: 0.09375\n",
            "loss: 2.0383524894714355 acc: 0.15625\n",
            "loss: 2.0867130756378174 acc: 0.1875\n",
            "loss: 2.0557641983032227 acc: 0.1875\n",
            "loss: 2.04827880859375 acc: 0.25\n",
            "loss: 2.0900566577911377 acc: 0.09375\n",
            "loss: 2.0613625049591064 acc: 0.140625\n",
            "loss: 2.0508534908294678 acc: 0.171875\n",
            "loss: 2.0711781978607178 acc: 0.125\n",
            "loss: 2.075841188430786 acc: 0.109375\n",
            "loss: 2.050912857055664 acc: 0.171875\n",
            "loss: 2.069657802581787 acc: 0.125\n",
            "loss: 2.0901095867156982 acc: 0.140625\n",
            "loss: 2.043400287628174 acc: 0.1875\n",
            "loss: 2.0452961921691895 acc: 0.046875\n",
            "loss: 2.0559775829315186 acc: 0.1875\n",
            "loss: 2.0510382652282715 acc: 0.265625\n",
            "loss: 2.040870189666748 acc: 0.125\n",
            "loss: 2.0503997802734375 acc: 0.140625\n",
            "loss: 2.063074827194214 acc: 0.109375\n",
            "loss: 2.096304178237915 acc: 0.078125\n",
            "loss: 2.1000006198883057 acc: 0.140625\n",
            "loss: 2.082864999771118 acc: 0.140625\n",
            "loss: 2.027102470397949 acc: 0.1875\n",
            "loss: 2.080820322036743 acc: 0.140625\n",
            "loss: 2.0410571098327637 acc: 0.296875\n",
            "loss: 2.0700864791870117 acc: 0.140625\n",
            "loss: 2.048614740371704 acc: 0.15625\n",
            "loss: 2.0561771392822266 acc: 0.1875\n",
            "loss: 2.0620648860931396 acc: 0.171875\n",
            "loss: 2.0641605854034424 acc: 0.078125\n",
            "loss: 2.0982799530029297 acc: 0.140625\n",
            "loss: 2.067739963531494 acc: 0.09375\n",
            "loss: 2.0421524047851562 acc: 0.15625\n",
            "loss: 2.0870304107666016 acc: 0.09375\n",
            "loss: 2.0571746826171875 acc: 0.15625\n",
            "loss: 2.0720603466033936 acc: 0.21875\n",
            "loss: 2.085554838180542 acc: 0.109375\n",
            "loss: 2.045696973800659 acc: 0.234375\n",
            "loss: 2.0285117626190186 acc: 0.1875\n",
            "loss: 2.0156824588775635 acc: 0.21875\n",
            "loss: 2.050123691558838 acc: 0.171875\n",
            "loss: 2.071824073791504 acc: 0.171875\n",
            "loss: 2.043482542037964 acc: 0.234375\n",
            "loss: 2.092337131500244 acc: 0.171875\n",
            "loss: 2.071967840194702 acc: 0.171875\n",
            "loss: 2.0425586700439453 acc: 0.1875\n",
            "loss: 2.0470614433288574 acc: 0.15625\n",
            "loss: 2.066154956817627 acc: 0.234375\n",
            "loss: 2.104888677597046 acc: 0.109375\n",
            "loss: 2.0943081378936768 acc: 0.09375\n",
            "loss: 2.0777454376220703 acc: 0.140625\n",
            "loss: 2.0497937202453613 acc: 0.1875\n",
            "loss: 2.0669398307800293 acc: 0.15625\n",
            "loss: 2.0603349208831787 acc: 0.1875\n",
            "loss: 2.053813934326172 acc: 0.15625\n",
            "loss: 2.1096549034118652 acc: 0.171875\n",
            "loss: 2.084270715713501 acc: 0.140625\n",
            "loss: 2.0456604957580566 acc: 0.265625\n",
            "loss: 2.1029508113861084 acc: 0.09375\n",
            "loss: 2.061621904373169 acc: 0.125\n",
            "loss: 2.0628111362457275 acc: 0.140625\n",
            "loss: 2.025137424468994 acc: 0.21875\n",
            "loss: 2.1163506507873535 acc: 0.078125\n",
            "loss: 2.073026180267334 acc: 0.171875\n",
            "loss: 2.0671021938323975 acc: 0.140625\n",
            "loss: 2.014800786972046 acc: 0.265625\n",
            "loss: 2.0798590183258057 acc: 0.125\n",
            "loss: 2.06050968170166 acc: 0.1875\n",
            "loss: 2.045353889465332 acc: 0.125\n",
            "loss: 2.060394763946533 acc: 0.1875\n",
            "loss: 2.0782384872436523 acc: 0.140625\n",
            "loss: 2.0728390216827393 acc: 0.09375\n",
            "loss: 2.079347848892212 acc: 0.140625\n",
            "loss: 2.0983123779296875 acc: 0.140625\n",
            "loss: 2.1062607765197754 acc: 0.125\n",
            "loss: 2.0632834434509277 acc: 0.15625\n",
            "loss: 2.061222553253174 acc: 0.125\n",
            "loss: 2.045727491378784 acc: 0.203125\n",
            "loss: 2.0550174713134766 acc: 0.125\n",
            "loss: 2.0724222660064697 acc: 0.15625\n",
            "loss: 2.0786514282226562 acc: 0.109375\n",
            "loss: 2.0795934200286865 acc: 0.140625\n",
            "loss: 2.0705575942993164 acc: 0.203125\n",
            "loss: 2.051623821258545 acc: 0.140625\n",
            "loss: 2.0770788192749023 acc: 0.09375\n",
            "loss: 2.031419277191162 acc: 0.234375\n",
            "loss: 2.0726544857025146 acc: 0.125\n",
            "loss: 2.1055755615234375 acc: 0.09375\n",
            "loss: 2.1355254650115967 acc: 0.15625\n",
            "loss: 2.0508503913879395 acc: 0.1875\n",
            "loss: 2.0517914295196533 acc: 0.15625\n",
            "loss: 2.0561585426330566 acc: 0.171875\n",
            "loss: 2.0592005252838135 acc: 0.1875\n",
            "loss: 2.0649657249450684 acc: 0.140625\n",
            "loss: 2.066420316696167 acc: 0.078125\n",
            "loss: 2.056931972503662 acc: 0.125\n",
            "loss: 2.070280075073242 acc: 0.171875\n",
            "loss: 2.0835869312286377 acc: 0.140625\n",
            "loss: 2.072092056274414 acc: 0.125\n",
            "loss: 2.025702953338623 acc: 0.171875\n",
            "loss: 2.0393288135528564 acc: 0.171875\n",
            "loss: 2.050452947616577 acc: 0.21875\n",
            "loss: 2.069624662399292 acc: 0.15625\n",
            "loss: 2.048668384552002 acc: 0.15625\n",
            "loss: 2.037721872329712 acc: 0.265625\n",
            "loss: 2.0408363342285156 acc: 0.234375\n",
            "loss: 2.068939685821533 acc: 0.125\n",
            "loss: 2.0440375804901123 acc: 0.203125\n",
            "loss: 2.0788440704345703 acc: 0.04651162773370743\n",
            "60 epoch:\n",
            "loss: 2.055603265762329 acc: 0.1875\n",
            "loss: 2.0551366806030273 acc: 0.21875\n",
            "loss: 2.075437068939209 acc: 0.203125\n",
            "loss: 2.0513458251953125 acc: 0.140625\n",
            "loss: 2.0300166606903076 acc: 0.203125\n",
            "loss: 2.014078140258789 acc: 0.15625\n",
            "loss: 2.035848617553711 acc: 0.1875\n",
            "loss: 2.037665605545044 acc: 0.15625\n",
            "loss: 2.0841493606567383 acc: 0.171875\n",
            "loss: 1.992728590965271 acc: 0.21875\n",
            "loss: 2.1135759353637695 acc: 0.109375\n",
            "loss: 2.0638625621795654 acc: 0.109375\n",
            "loss: 2.07987642288208 acc: 0.125\n",
            "loss: 2.0348470211029053 acc: 0.1875\n",
            "loss: 2.0791594982147217 acc: 0.078125\n",
            "loss: 2.032463788986206 acc: 0.15625\n",
            "loss: 2.0571062564849854 acc: 0.15625\n",
            "loss: 2.0179548263549805 acc: 0.234375\n",
            "loss: 2.039825201034546 acc: 0.203125\n",
            "loss: 2.0351436138153076 acc: 0.171875\n",
            "loss: 2.0775227546691895 acc: 0.109375\n",
            "loss: 2.05250883102417 acc: 0.125\n",
            "loss: 2.1138641834259033 acc: 0.109375\n",
            "loss: 2.035550117492676 acc: 0.21875\n",
            "loss: 2.098111152648926 acc: 0.078125\n",
            "loss: 2.0568666458129883 acc: 0.28125\n",
            "loss: 2.0986578464508057 acc: 0.125\n",
            "loss: 2.074712038040161 acc: 0.109375\n",
            "loss: 2.05308198928833 acc: 0.140625\n",
            "loss: 2.114738941192627 acc: 0.125\n",
            "loss: 2.033153533935547 acc: 0.203125\n",
            "loss: 2.097288131713867 acc: 0.09375\n",
            "loss: 2.080317258834839 acc: 0.140625\n",
            "loss: 2.060786724090576 acc: 0.15625\n",
            "loss: 2.098769187927246 acc: 0.109375\n",
            "loss: 2.065671682357788 acc: 0.140625\n",
            "loss: 2.0917611122131348 acc: 0.140625\n",
            "loss: 2.0835912227630615 acc: 0.1875\n",
            "loss: 2.0212337970733643 acc: 0.1875\n",
            "loss: 2.054685115814209 acc: 0.171875\n",
            "loss: 2.0488407611846924 acc: 0.125\n",
            "loss: 2.065976858139038 acc: 0.140625\n",
            "loss: 2.0948009490966797 acc: 0.140625\n",
            "loss: 2.0441792011260986 acc: 0.21875\n",
            "loss: 2.0845422744750977 acc: 0.140625\n",
            "loss: 2.041165351867676 acc: 0.265625\n",
            "loss: 2.0644314289093018 acc: 0.09375\n",
            "loss: 2.1031923294067383 acc: 0.1875\n",
            "loss: 2.086677312850952 acc: 0.109375\n",
            "loss: 2.095883846282959 acc: 0.078125\n",
            "loss: 2.0852601528167725 acc: 0.109375\n",
            "loss: 2.0352141857147217 acc: 0.21875\n",
            "loss: 2.0880448818206787 acc: 0.09375\n",
            "loss: 2.0368220806121826 acc: 0.15625\n",
            "loss: 2.0477945804595947 acc: 0.203125\n",
            "loss: 2.045574903488159 acc: 0.15625\n",
            "loss: 2.0606305599212646 acc: 0.140625\n",
            "loss: 2.0698559284210205 acc: 0.140625\n",
            "loss: 2.0260982513427734 acc: 0.1875\n",
            "loss: 2.0600545406341553 acc: 0.234375\n",
            "loss: 2.0484752655029297 acc: 0.171875\n",
            "loss: 2.0483410358428955 acc: 0.171875\n",
            "loss: 2.0544943809509277 acc: 0.15625\n",
            "loss: 2.0782968997955322 acc: 0.109375\n",
            "loss: 2.0549492835998535 acc: 0.15625\n",
            "loss: 2.0214104652404785 acc: 0.234375\n",
            "loss: 2.04906964302063 acc: 0.21875\n",
            "loss: 2.06567120552063 acc: 0.125\n",
            "loss: 2.071957588195801 acc: 0.15625\n",
            "loss: 2.0791091918945312 acc: 0.15625\n",
            "loss: 2.0538125038146973 acc: 0.15625\n",
            "loss: 2.0511794090270996 acc: 0.15625\n",
            "loss: 2.106377124786377 acc: 0.109375\n",
            "loss: 2.0804343223571777 acc: 0.140625\n",
            "loss: 2.0329935550689697 acc: 0.171875\n",
            "loss: 2.0540196895599365 acc: 0.15625\n",
            "loss: 2.0353221893310547 acc: 0.1875\n",
            "loss: 2.03908634185791 acc: 0.1875\n",
            "loss: 2.05842661857605 acc: 0.125\n",
            "loss: 2.065053939819336 acc: 0.171875\n",
            "loss: 2.0978269577026367 acc: 0.171875\n",
            "loss: 2.0464887619018555 acc: 0.1875\n",
            "loss: 2.0562384128570557 acc: 0.203125\n",
            "loss: 2.076643705368042 acc: 0.09375\n",
            "loss: 2.0926480293273926 acc: 0.0625\n",
            "loss: 2.0582902431488037 acc: 0.15625\n",
            "loss: 2.0851807594299316 acc: 0.15625\n",
            "loss: 2.0449156761169434 acc: 0.1875\n",
            "loss: 2.109398603439331 acc: 0.203125\n",
            "loss: 2.0903329849243164 acc: 0.140625\n",
            "loss: 2.049400568008423 acc: 0.1875\n",
            "loss: 2.078042984008789 acc: 0.140625\n",
            "loss: 2.0631942749023438 acc: 0.234375\n",
            "loss: 2.0659403800964355 acc: 0.140625\n",
            "loss: 2.0777649879455566 acc: 0.09375\n",
            "loss: 2.0607452392578125 acc: 0.078125\n",
            "loss: 2.115492343902588 acc: 0.0625\n",
            "loss: 2.0677850246429443 acc: 0.09375\n",
            "loss: 2.0224478244781494 acc: 0.203125\n",
            "loss: 2.0890989303588867 acc: 0.09375\n",
            "loss: 2.038478374481201 acc: 0.21875\n",
            "loss: 2.0934433937072754 acc: 0.125\n",
            "loss: 2.0370965003967285 acc: 0.15625\n",
            "loss: 2.0555615425109863 acc: 0.140625\n",
            "loss: 2.0589897632598877 acc: 0.1875\n",
            "loss: 2.094519853591919 acc: 0.109375\n",
            "loss: 2.081707000732422 acc: 0.15625\n",
            "loss: 2.0510811805725098 acc: 0.171875\n",
            "loss: 2.0649712085723877 acc: 0.171875\n",
            "loss: 2.0904345512390137 acc: 0.13953489065170288\n",
            "61 epoch:\n",
            "loss: 2.0689218044281006 acc: 0.140625\n",
            "loss: 2.0560836791992188 acc: 0.171875\n",
            "loss: 2.0669915676116943 acc: 0.21875\n",
            "loss: 2.083017110824585 acc: 0.125\n",
            "loss: 2.015615463256836 acc: 0.21875\n",
            "loss: 2.024596691131592 acc: 0.171875\n",
            "loss: 2.0857207775115967 acc: 0.125\n",
            "loss: 2.083521842956543 acc: 0.140625\n",
            "loss: 2.0629472732543945 acc: 0.125\n",
            "loss: 2.0541293621063232 acc: 0.140625\n",
            "loss: 2.056720018386841 acc: 0.171875\n",
            "loss: 2.0867209434509277 acc: 0.09375\n",
            "loss: 2.056975841522217 acc: 0.171875\n",
            "loss: 2.0768280029296875 acc: 0.125\n",
            "loss: 2.017029047012329 acc: 0.203125\n",
            "loss: 1.9943662881851196 acc: 0.203125\n",
            "loss: 2.0895040035247803 acc: 0.171875\n",
            "loss: 2.077608346939087 acc: 0.09375\n",
            "loss: 2.0859363079071045 acc: 0.125\n",
            "loss: 2.070847749710083 acc: 0.1875\n",
            "loss: 2.0196592807769775 acc: 0.1875\n",
            "loss: 2.0370242595672607 acc: 0.109375\n",
            "loss: 2.0533504486083984 acc: 0.203125\n",
            "loss: 2.09234356880188 acc: 0.125\n",
            "loss: 2.0375819206237793 acc: 0.203125\n",
            "loss: 2.0585403442382812 acc: 0.171875\n",
            "loss: 1.9933044910430908 acc: 0.234375\n",
            "loss: 2.1058974266052246 acc: 0.109375\n",
            "loss: 2.045466184616089 acc: 0.140625\n",
            "loss: 2.0599172115325928 acc: 0.140625\n",
            "loss: 2.039316415786743 acc: 0.1875\n",
            "loss: 2.0675673484802246 acc: 0.125\n",
            "loss: 2.029000997543335 acc: 0.1875\n",
            "loss: 2.0665030479431152 acc: 0.125\n",
            "loss: 2.0887205600738525 acc: 0.171875\n",
            "loss: 2.0554134845733643 acc: 0.203125\n",
            "loss: 2.0530142784118652 acc: 0.171875\n",
            "loss: 2.0384576320648193 acc: 0.125\n",
            "loss: 2.0190019607543945 acc: 0.171875\n",
            "loss: 2.0619332790374756 acc: 0.203125\n",
            "loss: 2.069751739501953 acc: 0.125\n",
            "loss: 2.0559797286987305 acc: 0.140625\n",
            "loss: 2.075556516647339 acc: 0.15625\n",
            "loss: 2.0830607414245605 acc: 0.0625\n",
            "loss: 2.102895736694336 acc: 0.109375\n",
            "loss: 2.0489745140075684 acc: 0.1875\n",
            "loss: 2.0478625297546387 acc: 0.09375\n",
            "loss: 2.0667171478271484 acc: 0.171875\n",
            "loss: 2.070492744445801 acc: 0.078125\n",
            "loss: 2.048524856567383 acc: 0.1875\n",
            "loss: 2.051447868347168 acc: 0.125\n",
            "loss: 2.061464548110962 acc: 0.125\n",
            "loss: 2.1181702613830566 acc: 0.171875\n",
            "loss: 2.0632662773132324 acc: 0.140625\n",
            "loss: 2.071640729904175 acc: 0.109375\n",
            "loss: 2.0691022872924805 acc: 0.109375\n",
            "loss: 2.0768508911132812 acc: 0.078125\n",
            "loss: 2.0630366802215576 acc: 0.125\n",
            "loss: 2.0230207443237305 acc: 0.21875\n",
            "loss: 2.060518503189087 acc: 0.125\n",
            "loss: 2.1125564575195312 acc: 0.125\n",
            "loss: 2.052359104156494 acc: 0.078125\n",
            "loss: 1.9851988554000854 acc: 0.25\n",
            "loss: 2.064326286315918 acc: 0.125\n",
            "loss: 2.0804502964019775 acc: 0.09375\n",
            "loss: 2.077843427658081 acc: 0.046875\n",
            "loss: 2.060663938522339 acc: 0.140625\n",
            "loss: 2.0257952213287354 acc: 0.171875\n",
            "loss: 2.0461528301239014 acc: 0.234375\n",
            "loss: 2.0421652793884277 acc: 0.15625\n",
            "loss: 2.0886263847351074 acc: 0.125\n",
            "loss: 2.0909578800201416 acc: 0.125\n",
            "loss: 2.0548255443573 acc: 0.21875\n",
            "loss: 2.0817553997039795 acc: 0.09375\n",
            "loss: 2.1132307052612305 acc: 0.140625\n",
            "loss: 2.094284772872925 acc: 0.09375\n",
            "loss: 2.0371813774108887 acc: 0.234375\n",
            "loss: 2.051030158996582 acc: 0.1875\n",
            "loss: 2.1047987937927246 acc: 0.109375\n",
            "loss: 2.052133321762085 acc: 0.21875\n",
            "loss: 2.0951685905456543 acc: 0.078125\n",
            "loss: 2.0629661083221436 acc: 0.109375\n",
            "loss: 2.022761821746826 acc: 0.203125\n",
            "loss: 2.0311062335968018 acc: 0.171875\n",
            "loss: 2.056867837905884 acc: 0.140625\n",
            "loss: 2.0274600982666016 acc: 0.234375\n",
            "loss: 2.0521655082702637 acc: 0.1875\n",
            "loss: 2.0885934829711914 acc: 0.140625\n",
            "loss: 2.073665142059326 acc: 0.21875\n",
            "loss: 2.080996513366699 acc: 0.171875\n",
            "loss: 2.0141513347625732 acc: 0.21875\n",
            "loss: 2.090266704559326 acc: 0.1875\n",
            "loss: 2.086186170578003 acc: 0.171875\n",
            "loss: 2.0764784812927246 acc: 0.109375\n",
            "loss: 2.0471670627593994 acc: 0.1875\n",
            "loss: 2.044025421142578 acc: 0.234375\n",
            "loss: 2.0558383464813232 acc: 0.140625\n",
            "loss: 2.0353024005889893 acc: 0.1875\n",
            "loss: 2.0594213008880615 acc: 0.140625\n",
            "loss: 2.0584497451782227 acc: 0.15625\n",
            "loss: 2.0541019439697266 acc: 0.140625\n",
            "loss: 2.0742571353912354 acc: 0.109375\n",
            "loss: 2.066493511199951 acc: 0.15625\n",
            "loss: 2.107390880584717 acc: 0.078125\n",
            "loss: 2.100165843963623 acc: 0.171875\n",
            "loss: 2.0403122901916504 acc: 0.203125\n",
            "loss: 2.0659401416778564 acc: 0.171875\n",
            "loss: 2.026480197906494 acc: 0.203125\n",
            "loss: 2.063833713531494 acc: 0.171875\n",
            "loss: 2.048750400543213 acc: 0.1627907007932663\n",
            "62 epoch:\n",
            "loss: 1.9702250957489014 acc: 0.25\n",
            "loss: 2.1101486682891846 acc: 0.1875\n",
            "loss: 2.085200309753418 acc: 0.171875\n",
            "loss: 2.090616226196289 acc: 0.125\n",
            "loss: 2.1141791343688965 acc: 0.09375\n",
            "loss: 2.0321311950683594 acc: 0.171875\n",
            "loss: 2.0771071910858154 acc: 0.140625\n",
            "loss: 2.069418430328369 acc: 0.1875\n",
            "loss: 2.032557249069214 acc: 0.21875\n",
            "loss: 2.051407814025879 acc: 0.109375\n",
            "loss: 2.071028709411621 acc: 0.125\n",
            "loss: 2.0512168407440186 acc: 0.203125\n",
            "loss: 2.057985305786133 acc: 0.203125\n",
            "loss: 2.049572706222534 acc: 0.171875\n",
            "loss: 2.0359344482421875 acc: 0.1875\n",
            "loss: 2.048672676086426 acc: 0.09375\n",
            "loss: 2.068922519683838 acc: 0.21875\n",
            "loss: 2.0278563499450684 acc: 0.15625\n",
            "loss: 2.0513246059417725 acc: 0.21875\n",
            "loss: 2.0829813480377197 acc: 0.125\n",
            "loss: 2.074812889099121 acc: 0.078125\n",
            "loss: 2.0860378742218018 acc: 0.109375\n",
            "loss: 2.055297613143921 acc: 0.15625\n",
            "loss: 2.0730347633361816 acc: 0.125\n",
            "loss: 2.0642542839050293 acc: 0.15625\n",
            "loss: 2.0313801765441895 acc: 0.1875\n",
            "loss: 2.053774833679199 acc: 0.15625\n",
            "loss: 2.0349788665771484 acc: 0.171875\n",
            "loss: 2.06246018409729 acc: 0.109375\n",
            "loss: 2.094369411468506 acc: 0.09375\n",
            "loss: 2.0260250568389893 acc: 0.234375\n",
            "loss: 2.0309860706329346 acc: 0.140625\n",
            "loss: 2.069622039794922 acc: 0.09375\n",
            "loss: 2.054107904434204 acc: 0.09375\n",
            "loss: 2.0644407272338867 acc: 0.09375\n",
            "loss: 2.0831127166748047 acc: 0.15625\n",
            "loss: 2.0569536685943604 acc: 0.171875\n",
            "loss: 2.0658888816833496 acc: 0.109375\n",
            "loss: 2.0623185634613037 acc: 0.09375\n",
            "loss: 2.0551233291625977 acc: 0.234375\n",
            "loss: 2.066138505935669 acc: 0.15625\n",
            "loss: 2.0522782802581787 acc: 0.109375\n",
            "loss: 2.0597071647644043 acc: 0.140625\n",
            "loss: 2.0706746578216553 acc: 0.140625\n",
            "loss: 2.0745186805725098 acc: 0.078125\n",
            "loss: 2.0630970001220703 acc: 0.171875\n",
            "loss: 2.057752847671509 acc: 0.125\n",
            "loss: 2.0225493907928467 acc: 0.15625\n",
            "loss: 2.0422656536102295 acc: 0.140625\n",
            "loss: 2.0372564792633057 acc: 0.203125\n",
            "loss: 2.1118416786193848 acc: 0.21875\n",
            "loss: 2.0613129138946533 acc: 0.171875\n",
            "loss: 2.0770111083984375 acc: 0.078125\n",
            "loss: 2.05074405670166 acc: 0.203125\n",
            "loss: 2.0519776344299316 acc: 0.15625\n",
            "loss: 2.099216938018799 acc: 0.171875\n",
            "loss: 2.0264089107513428 acc: 0.25\n",
            "loss: 2.0233936309814453 acc: 0.25\n",
            "loss: 2.0674593448638916 acc: 0.109375\n",
            "loss: 2.068089008331299 acc: 0.171875\n",
            "loss: 2.081106185913086 acc: 0.125\n",
            "loss: 1.9974344968795776 acc: 0.203125\n",
            "loss: 2.147219657897949 acc: 0.09375\n",
            "loss: 2.0733015537261963 acc: 0.078125\n",
            "loss: 2.078403949737549 acc: 0.15625\n",
            "loss: 2.042795181274414 acc: 0.171875\n",
            "loss: 2.0685625076293945 acc: 0.078125\n",
            "loss: 2.047358751296997 acc: 0.125\n",
            "loss: 2.092635154724121 acc: 0.15625\n",
            "loss: 2.082756996154785 acc: 0.171875\n",
            "loss: 2.0944530963897705 acc: 0.078125\n",
            "loss: 2.074326753616333 acc: 0.140625\n",
            "loss: 2.074103355407715 acc: 0.09375\n",
            "loss: 2.0581681728363037 acc: 0.140625\n",
            "loss: 2.0844249725341797 acc: 0.109375\n",
            "loss: 2.079270601272583 acc: 0.109375\n",
            "loss: 2.082672595977783 acc: 0.0625\n",
            "loss: 2.0854482650756836 acc: 0.125\n",
            "loss: 2.0762665271759033 acc: 0.125\n",
            "loss: 2.063694715499878 acc: 0.09375\n",
            "loss: 2.033867359161377 acc: 0.265625\n",
            "loss: 2.084188222885132 acc: 0.203125\n",
            "loss: 2.073521852493286 acc: 0.140625\n",
            "loss: 2.0691394805908203 acc: 0.140625\n",
            "loss: 2.045351505279541 acc: 0.1875\n",
            "loss: 2.0473825931549072 acc: 0.171875\n",
            "loss: 2.0519423484802246 acc: 0.1875\n",
            "loss: 2.086324453353882 acc: 0.109375\n",
            "loss: 2.052635908126831 acc: 0.1875\n",
            "loss: 2.1085660457611084 acc: 0.109375\n",
            "loss: 2.087580680847168 acc: 0.171875\n",
            "loss: 2.071657180786133 acc: 0.234375\n",
            "loss: 2.0860791206359863 acc: 0.15625\n",
            "loss: 2.0585341453552246 acc: 0.171875\n",
            "loss: 2.084684133529663 acc: 0.09375\n",
            "loss: 2.0159881114959717 acc: 0.25\n",
            "loss: 2.022261381149292 acc: 0.171875\n",
            "loss: 2.0533580780029297 acc: 0.1875\n",
            "loss: 2.074082374572754 acc: 0.109375\n",
            "loss: 2.1038269996643066 acc: 0.125\n",
            "loss: 2.0579285621643066 acc: 0.109375\n",
            "loss: 2.05798077583313 acc: 0.140625\n",
            "loss: 2.0631842613220215 acc: 0.09375\n",
            "loss: 2.05948543548584 acc: 0.1875\n",
            "loss: 2.045435667037964 acc: 0.171875\n",
            "loss: 2.1052441596984863 acc: 0.140625\n",
            "loss: 2.0447933673858643 acc: 0.21875\n",
            "loss: 2.101547956466675 acc: 0.125\n",
            "loss: 2.053208827972412 acc: 0.265625\n",
            "loss: 2.0262386798858643 acc: 0.1860465109348297\n",
            "63 epoch:\n",
            "loss: 2.027986526489258 acc: 0.15625\n",
            "loss: 2.060518264770508 acc: 0.1875\n",
            "loss: 2.050292491912842 acc: 0.15625\n",
            "loss: 2.041949510574341 acc: 0.234375\n",
            "loss: 1.971602201461792 acc: 0.203125\n",
            "loss: 2.088683605194092 acc: 0.03125\n",
            "loss: 2.0501577854156494 acc: 0.109375\n",
            "loss: 2.111262321472168 acc: 0.171875\n",
            "loss: 2.0583536624908447 acc: 0.140625\n",
            "loss: 2.0704901218414307 acc: 0.15625\n",
            "loss: 2.0900638103485107 acc: 0.109375\n",
            "loss: 2.0699617862701416 acc: 0.1875\n",
            "loss: 2.0425119400024414 acc: 0.125\n",
            "loss: 2.062519073486328 acc: 0.125\n",
            "loss: 2.077747106552124 acc: 0.09375\n",
            "loss: 2.0540874004364014 acc: 0.109375\n",
            "loss: 2.04860258102417 acc: 0.109375\n",
            "loss: 2.075042724609375 acc: 0.078125\n",
            "loss: 2.076586961746216 acc: 0.171875\n",
            "loss: 2.0677616596221924 acc: 0.140625\n",
            "loss: 2.0529415607452393 acc: 0.140625\n",
            "loss: 2.066970109939575 acc: 0.109375\n",
            "loss: 2.0466837882995605 acc: 0.15625\n",
            "loss: 2.0919413566589355 acc: 0.109375\n",
            "loss: 2.0923821926116943 acc: 0.109375\n",
            "loss: 2.0488595962524414 acc: 0.140625\n",
            "loss: 2.053924560546875 acc: 0.078125\n",
            "loss: 2.0570271015167236 acc: 0.15625\n",
            "loss: 2.096219539642334 acc: 0.125\n",
            "loss: 2.0287837982177734 acc: 0.21875\n",
            "loss: 2.071556806564331 acc: 0.140625\n",
            "loss: 2.0476889610290527 acc: 0.203125\n",
            "loss: 2.086085557937622 acc: 0.109375\n",
            "loss: 2.0406134128570557 acc: 0.125\n",
            "loss: 2.0652544498443604 acc: 0.125\n",
            "loss: 2.0638089179992676 acc: 0.1875\n",
            "loss: 2.0530734062194824 acc: 0.109375\n",
            "loss: 2.0636215209960938 acc: 0.109375\n",
            "loss: 2.049219846725464 acc: 0.203125\n",
            "loss: 2.1288158893585205 acc: 0.15625\n",
            "loss: 2.0443739891052246 acc: 0.171875\n",
            "loss: 2.081657886505127 acc: 0.15625\n",
            "loss: 2.0308830738067627 acc: 0.21875\n",
            "loss: 2.087718963623047 acc: 0.140625\n",
            "loss: 2.0599374771118164 acc: 0.109375\n",
            "loss: 2.0337014198303223 acc: 0.21875\n",
            "loss: 2.0472943782806396 acc: 0.21875\n",
            "loss: 2.033372402191162 acc: 0.171875\n",
            "loss: 2.019773483276367 acc: 0.203125\n",
            "loss: 2.067542791366577 acc: 0.125\n",
            "loss: 2.0768485069274902 acc: 0.171875\n",
            "loss: 2.045478105545044 acc: 0.1875\n",
            "loss: 2.0777621269226074 acc: 0.140625\n",
            "loss: 2.058180809020996 acc: 0.171875\n",
            "loss: 2.044848918914795 acc: 0.203125\n",
            "loss: 2.0563082695007324 acc: 0.21875\n",
            "loss: 2.052293062210083 acc: 0.171875\n",
            "loss: 2.066633701324463 acc: 0.09375\n",
            "loss: 2.0956859588623047 acc: 0.15625\n",
            "loss: 2.061832904815674 acc: 0.140625\n",
            "loss: 2.066443920135498 acc: 0.15625\n",
            "loss: 2.063749313354492 acc: 0.140625\n",
            "loss: 2.0305652618408203 acc: 0.171875\n",
            "loss: 2.0713624954223633 acc: 0.140625\n",
            "loss: 2.0398788452148438 acc: 0.125\n",
            "loss: 2.0566482543945312 acc: 0.15625\n",
            "loss: 2.0512781143188477 acc: 0.1875\n",
            "loss: 2.0599918365478516 acc: 0.15625\n",
            "loss: 2.075578212738037 acc: 0.171875\n",
            "loss: 2.0525758266448975 acc: 0.125\n",
            "loss: 2.075894832611084 acc: 0.203125\n",
            "loss: 2.044431686401367 acc: 0.171875\n",
            "loss: 2.0834872722625732 acc: 0.15625\n",
            "loss: 2.079524278640747 acc: 0.171875\n",
            "loss: 2.0905303955078125 acc: 0.09375\n",
            "loss: 2.075674057006836 acc: 0.09375\n",
            "loss: 2.0478532314300537 acc: 0.140625\n",
            "loss: 2.0787718296051025 acc: 0.15625\n",
            "loss: 2.052269697189331 acc: 0.171875\n",
            "loss: 2.041212558746338 acc: 0.25\n",
            "loss: 2.0534815788269043 acc: 0.171875\n",
            "loss: 2.045164108276367 acc: 0.078125\n",
            "loss: 2.0211949348449707 acc: 0.171875\n",
            "loss: 2.033291816711426 acc: 0.15625\n",
            "loss: 2.039896011352539 acc: 0.171875\n",
            "loss: 2.014685869216919 acc: 0.15625\n",
            "loss: 2.0478999614715576 acc: 0.15625\n",
            "loss: 2.072397470474243 acc: 0.1875\n",
            "loss: 2.015472173690796 acc: 0.25\n",
            "loss: 2.1433334350585938 acc: 0.140625\n",
            "loss: 2.0227508544921875 acc: 0.1875\n",
            "loss: 2.0687906742095947 acc: 0.09375\n",
            "loss: 2.080875873565674 acc: 0.21875\n",
            "loss: 2.085998296737671 acc: 0.125\n",
            "loss: 2.065361738204956 acc: 0.203125\n",
            "loss: 2.0634281635284424 acc: 0.109375\n",
            "loss: 2.061136245727539 acc: 0.234375\n",
            "loss: 2.08955717086792 acc: 0.140625\n",
            "loss: 2.0977718830108643 acc: 0.109375\n",
            "loss: 2.041962146759033 acc: 0.203125\n",
            "loss: 2.0395455360412598 acc: 0.1875\n",
            "loss: 2.069077491760254 acc: 0.171875\n",
            "loss: 2.0608086585998535 acc: 0.09375\n",
            "loss: 2.036406993865967 acc: 0.25\n",
            "loss: 2.0477824211120605 acc: 0.09375\n",
            "loss: 2.046133279800415 acc: 0.203125\n",
            "loss: 2.0218288898468018 acc: 0.234375\n",
            "loss: 2.087467670440674 acc: 0.125\n",
            "loss: 2.0759027004241943 acc: 0.203125\n",
            "loss: 2.0659689903259277 acc: 0.09302325546741486\n",
            "64 epoch:\n",
            "loss: 2.1181039810180664 acc: 0.09375\n",
            "loss: 2.061182975769043 acc: 0.15625\n",
            "loss: 2.046861410140991 acc: 0.109375\n",
            "loss: 2.0430920124053955 acc: 0.171875\n",
            "loss: 2.0660269260406494 acc: 0.125\n",
            "loss: 2.059502124786377 acc: 0.09375\n",
            "loss: 2.0452468395233154 acc: 0.15625\n",
            "loss: 2.0496928691864014 acc: 0.109375\n",
            "loss: 2.0497124195098877 acc: 0.140625\n",
            "loss: 2.0862741470336914 acc: 0.09375\n",
            "loss: 2.055478811264038 acc: 0.15625\n",
            "loss: 2.0698494911193848 acc: 0.140625\n",
            "loss: 2.032984972000122 acc: 0.140625\n",
            "loss: 2.0329396724700928 acc: 0.15625\n",
            "loss: 2.0991077423095703 acc: 0.09375\n",
            "loss: 2.004483461380005 acc: 0.234375\n",
            "loss: 2.053279161453247 acc: 0.15625\n",
            "loss: 2.00477933883667 acc: 0.25\n",
            "loss: 2.028956174850464 acc: 0.1875\n",
            "loss: 2.0052127838134766 acc: 0.21875\n",
            "loss: 2.0518386363983154 acc: 0.15625\n",
            "loss: 1.9936531782150269 acc: 0.296875\n",
            "loss: 2.0858232975006104 acc: 0.109375\n",
            "loss: 2.0179474353790283 acc: 0.171875\n",
            "loss: 2.052528142929077 acc: 0.234375\n",
            "loss: 2.099763870239258 acc: 0.078125\n",
            "loss: 2.0334625244140625 acc: 0.171875\n",
            "loss: 2.0129811763763428 acc: 0.203125\n",
            "loss: 2.0453715324401855 acc: 0.125\n",
            "loss: 2.013918876647949 acc: 0.171875\n",
            "loss: 2.0466818809509277 acc: 0.203125\n",
            "loss: 2.059190034866333 acc: 0.109375\n",
            "loss: 2.0480945110321045 acc: 0.21875\n",
            "loss: 2.0941531658172607 acc: 0.1875\n",
            "loss: 2.023080587387085 acc: 0.21875\n",
            "loss: 2.0983715057373047 acc: 0.078125\n",
            "loss: 2.0741257667541504 acc: 0.109375\n",
            "loss: 2.0711989402770996 acc: 0.203125\n",
            "loss: 2.0258307456970215 acc: 0.203125\n",
            "loss: 2.0807178020477295 acc: 0.15625\n",
            "loss: 2.0505459308624268 acc: 0.15625\n",
            "loss: 2.078028678894043 acc: 0.125\n",
            "loss: 2.0066826343536377 acc: 0.234375\n",
            "loss: 2.041123867034912 acc: 0.15625\n",
            "loss: 2.029606342315674 acc: 0.171875\n",
            "loss: 2.0039355754852295 acc: 0.25\n",
            "loss: 2.018282890319824 acc: 0.15625\n",
            "loss: 2.085204601287842 acc: 0.15625\n",
            "loss: 2.0786068439483643 acc: 0.15625\n",
            "loss: 2.0360021591186523 acc: 0.21875\n",
            "loss: 2.0138869285583496 acc: 0.203125\n",
            "loss: 2.096235513687134 acc: 0.1875\n",
            "loss: 2.0375611782073975 acc: 0.125\n",
            "loss: 2.0635533332824707 acc: 0.171875\n",
            "loss: 2.0804903507232666 acc: 0.109375\n",
            "loss: 2.1060690879821777 acc: 0.140625\n",
            "loss: 2.01605224609375 acc: 0.171875\n",
            "loss: 2.108001470565796 acc: 0.109375\n",
            "loss: 2.054901599884033 acc: 0.171875\n",
            "loss: 2.080617904663086 acc: 0.1875\n",
            "loss: 2.0475924015045166 acc: 0.21875\n",
            "loss: 2.041447401046753 acc: 0.15625\n",
            "loss: 2.063249349594116 acc: 0.171875\n",
            "loss: 2.036421775817871 acc: 0.15625\n",
            "loss: 2.054457664489746 acc: 0.1875\n",
            "loss: 2.0561306476593018 acc: 0.140625\n",
            "loss: 2.09938383102417 acc: 0.140625\n",
            "loss: 2.0762267112731934 acc: 0.140625\n",
            "loss: 2.0687737464904785 acc: 0.15625\n",
            "loss: 2.0471549034118652 acc: 0.140625\n",
            "loss: 2.0815858840942383 acc: 0.15625\n",
            "loss: 2.0200161933898926 acc: 0.140625\n",
            "loss: 2.0422730445861816 acc: 0.203125\n",
            "loss: 2.0755906105041504 acc: 0.171875\n",
            "loss: 2.1426496505737305 acc: 0.0625\n",
            "loss: 2.066697597503662 acc: 0.171875\n",
            "loss: 2.0413694381713867 acc: 0.125\n",
            "loss: 2.098386526107788 acc: 0.0625\n",
            "loss: 2.058295965194702 acc: 0.140625\n",
            "loss: 2.0815465450286865 acc: 0.171875\n",
            "loss: 2.087329864501953 acc: 0.09375\n",
            "loss: 2.0341010093688965 acc: 0.203125\n",
            "loss: 2.0685782432556152 acc: 0.09375\n",
            "loss: 2.0769202709198 acc: 0.09375\n",
            "loss: 2.0386314392089844 acc: 0.140625\n",
            "loss: 2.081881523132324 acc: 0.203125\n",
            "loss: 2.0562684535980225 acc: 0.03125\n",
            "loss: 2.0587151050567627 acc: 0.125\n",
            "loss: 2.0416250228881836 acc: 0.171875\n",
            "loss: 2.0661327838897705 acc: 0.140625\n",
            "loss: 2.0686049461364746 acc: 0.1875\n",
            "loss: 2.0367324352264404 acc: 0.078125\n",
            "loss: 2.0771963596343994 acc: 0.109375\n",
            "loss: 2.068289279937744 acc: 0.125\n",
            "loss: 2.098398447036743 acc: 0.0625\n",
            "loss: 2.023353338241577 acc: 0.234375\n",
            "loss: 2.0846126079559326 acc: 0.15625\n",
            "loss: 2.029834032058716 acc: 0.171875\n",
            "loss: 2.0532963275909424 acc: 0.15625\n",
            "loss: 2.055651903152466 acc: 0.1875\n",
            "loss: 2.0560712814331055 acc: 0.109375\n",
            "loss: 2.0081729888916016 acc: 0.265625\n",
            "loss: 2.08390212059021 acc: 0.15625\n",
            "loss: 2.0949771404266357 acc: 0.171875\n",
            "loss: 2.0303332805633545 acc: 0.203125\n",
            "loss: 2.0493547916412354 acc: 0.15625\n",
            "loss: 2.1231772899627686 acc: 0.0625\n",
            "loss: 2.097851276397705 acc: 0.171875\n",
            "loss: 2.062018394470215 acc: 0.109375\n",
            "loss: 2.1213185787200928 acc: 0.023255813866853714\n",
            "65 epoch:\n",
            "loss: 2.078709840774536 acc: 0.171875\n",
            "loss: 2.0410051345825195 acc: 0.15625\n",
            "loss: 2.0855298042297363 acc: 0.109375\n",
            "loss: 2.037883758544922 acc: 0.15625\n",
            "loss: 2.059807300567627 acc: 0.171875\n",
            "loss: 2.054574966430664 acc: 0.25\n",
            "loss: 2.077984094619751 acc: 0.140625\n",
            "loss: 2.035653829574585 acc: 0.25\n",
            "loss: 2.038638114929199 acc: 0.234375\n",
            "loss: 2.072991371154785 acc: 0.125\n",
            "loss: 2.115109920501709 acc: 0.03125\n",
            "loss: 2.059694290161133 acc: 0.25\n",
            "loss: 2.066934585571289 acc: 0.171875\n",
            "loss: 2.0453503131866455 acc: 0.203125\n",
            "loss: 2.036728858947754 acc: 0.1875\n",
            "loss: 2.0452992916107178 acc: 0.203125\n",
            "loss: 2.0932445526123047 acc: 0.171875\n",
            "loss: 2.0367090702056885 acc: 0.15625\n",
            "loss: 2.0455586910247803 acc: 0.140625\n",
            "loss: 2.057004928588867 acc: 0.1875\n",
            "loss: 2.0320117473602295 acc: 0.1875\n",
            "loss: 2.0531396865844727 acc: 0.140625\n",
            "loss: 2.060598373413086 acc: 0.109375\n",
            "loss: 2.0802597999572754 acc: 0.109375\n",
            "loss: 2.0531065464019775 acc: 0.140625\n",
            "loss: 2.0549986362457275 acc: 0.15625\n",
            "loss: 2.0797064304351807 acc: 0.234375\n",
            "loss: 2.0887534618377686 acc: 0.109375\n",
            "loss: 2.050880193710327 acc: 0.140625\n",
            "loss: 2.0567638874053955 acc: 0.140625\n",
            "loss: 2.067004442214966 acc: 0.109375\n",
            "loss: 2.0095720291137695 acc: 0.1875\n",
            "loss: 2.0480706691741943 acc: 0.140625\n",
            "loss: 2.024226665496826 acc: 0.21875\n",
            "loss: 2.0528316497802734 acc: 0.234375\n",
            "loss: 2.0444891452789307 acc: 0.1875\n",
            "loss: 2.0670862197875977 acc: 0.078125\n",
            "loss: 2.0198023319244385 acc: 0.15625\n",
            "loss: 2.0211448669433594 acc: 0.140625\n",
            "loss: 2.0555319786071777 acc: 0.234375\n",
            "loss: 2.0383200645446777 acc: 0.15625\n",
            "loss: 2.0744869709014893 acc: 0.1875\n",
            "loss: 2.0341997146606445 acc: 0.1875\n",
            "loss: 2.030921697616577 acc: 0.1875\n",
            "loss: 2.049250841140747 acc: 0.234375\n",
            "loss: 2.053220510482788 acc: 0.1875\n",
            "loss: 2.058260202407837 acc: 0.203125\n",
            "loss: 2.012006998062134 acc: 0.15625\n",
            "loss: 2.1089138984680176 acc: 0.171875\n",
            "loss: 2.12751841545105 acc: 0.0625\n",
            "loss: 2.061016082763672 acc: 0.140625\n",
            "loss: 2.0402514934539795 acc: 0.21875\n",
            "loss: 2.0724925994873047 acc: 0.125\n",
            "loss: 2.047788619995117 acc: 0.109375\n",
            "loss: 2.0268170833587646 acc: 0.15625\n",
            "loss: 2.032500982284546 acc: 0.1875\n",
            "loss: 2.04242205619812 acc: 0.171875\n",
            "loss: 2.08494234085083 acc: 0.1875\n",
            "loss: 2.028286933898926 acc: 0.203125\n",
            "loss: 2.0933310985565186 acc: 0.171875\n",
            "loss: 2.0247671604156494 acc: 0.1875\n",
            "loss: 2.050931453704834 acc: 0.109375\n",
            "loss: 2.058748483657837 acc: 0.140625\n",
            "loss: 2.0854785442352295 acc: 0.15625\n",
            "loss: 2.0182619094848633 acc: 0.140625\n",
            "loss: 2.0484421253204346 acc: 0.140625\n",
            "loss: 2.047243356704712 acc: 0.234375\n",
            "loss: 2.101649522781372 acc: 0.0625\n",
            "loss: 2.0785088539123535 acc: 0.109375\n",
            "loss: 2.076000928878784 acc: 0.140625\n",
            "loss: 2.0455665588378906 acc: 0.1875\n",
            "loss: 2.044074296951294 acc: 0.203125\n",
            "loss: 2.073354482650757 acc: 0.140625\n",
            "loss: 1.998082160949707 acc: 0.21875\n",
            "loss: 2.0346555709838867 acc: 0.15625\n",
            "loss: 2.0426876544952393 acc: 0.15625\n",
            "loss: 2.0690529346466064 acc: 0.09375\n",
            "loss: 1.9942049980163574 acc: 0.28125\n",
            "loss: 2.0257349014282227 acc: 0.21875\n",
            "loss: 2.0402450561523438 acc: 0.109375\n",
            "loss: 2.0503954887390137 acc: 0.171875\n",
            "loss: 2.056201457977295 acc: 0.109375\n",
            "loss: 2.060885429382324 acc: 0.203125\n",
            "loss: 2.1124465465545654 acc: 0.171875\n",
            "loss: 2.0818309783935547 acc: 0.140625\n",
            "loss: 2.051485776901245 acc: 0.109375\n",
            "loss: 2.013296604156494 acc: 0.1875\n",
            "loss: 2.0415472984313965 acc: 0.140625\n",
            "loss: 2.0690245628356934 acc: 0.109375\n",
            "loss: 2.0246810913085938 acc: 0.1875\n",
            "loss: 2.037827253341675 acc: 0.140625\n",
            "loss: 2.0293588638305664 acc: 0.171875\n",
            "loss: 2.037954092025757 acc: 0.21875\n",
            "loss: 2.1000523567199707 acc: 0.078125\n",
            "loss: 2.024779796600342 acc: 0.21875\n",
            "loss: 2.084670066833496 acc: 0.171875\n",
            "loss: 2.0516021251678467 acc: 0.140625\n",
            "loss: 2.1036553382873535 acc: 0.125\n",
            "loss: 2.1001110076904297 acc: 0.109375\n",
            "loss: 2.0424458980560303 acc: 0.1875\n",
            "loss: 2.082026243209839 acc: 0.09375\n",
            "loss: 2.087364673614502 acc: 0.171875\n",
            "loss: 2.0087034702301025 acc: 0.1875\n",
            "loss: 2.0721259117126465 acc: 0.15625\n",
            "loss: 2.0735957622528076 acc: 0.15625\n",
            "loss: 2.0599162578582764 acc: 0.171875\n",
            "loss: 2.0514914989471436 acc: 0.140625\n",
            "loss: 2.0560216903686523 acc: 0.15625\n",
            "loss: 2.0901405811309814 acc: 0.109375\n",
            "loss: 2.054993152618408 acc: 0.1627907007932663\n",
            "66 epoch:\n",
            "loss: 2.0309977531433105 acc: 0.140625\n",
            "loss: 2.0250163078308105 acc: 0.203125\n",
            "loss: 2.0565052032470703 acc: 0.21875\n",
            "loss: 2.0769529342651367 acc: 0.140625\n",
            "loss: 2.0208792686462402 acc: 0.265625\n",
            "loss: 2.0423240661621094 acc: 0.1875\n",
            "loss: 2.0310072898864746 acc: 0.15625\n",
            "loss: 2.0543837547302246 acc: 0.15625\n",
            "loss: 2.0693917274475098 acc: 0.109375\n",
            "loss: 2.070298433303833 acc: 0.171875\n",
            "loss: 2.047886371612549 acc: 0.125\n",
            "loss: 2.049415111541748 acc: 0.21875\n",
            "loss: 2.045398235321045 acc: 0.234375\n",
            "loss: 2.0387532711029053 acc: 0.234375\n",
            "loss: 2.0259296894073486 acc: 0.171875\n",
            "loss: 2.06672739982605 acc: 0.15625\n",
            "loss: 2.0524868965148926 acc: 0.15625\n",
            "loss: 2.026630401611328 acc: 0.15625\n",
            "loss: 2.0330042839050293 acc: 0.125\n",
            "loss: 2.042140245437622 acc: 0.21875\n",
            "loss: 2.055729866027832 acc: 0.109375\n",
            "loss: 2.074284076690674 acc: 0.15625\n",
            "loss: 2.0831961631774902 acc: 0.109375\n",
            "loss: 2.043401002883911 acc: 0.15625\n",
            "loss: 2.043027639389038 acc: 0.15625\n",
            "loss: 2.0870361328125 acc: 0.15625\n",
            "loss: 2.0671560764312744 acc: 0.171875\n",
            "loss: 2.067596435546875 acc: 0.21875\n",
            "loss: 2.0248305797576904 acc: 0.171875\n",
            "loss: 2.018012523651123 acc: 0.109375\n",
            "loss: 2.0457677841186523 acc: 0.15625\n",
            "loss: 2.0206892490386963 acc: 0.1875\n",
            "loss: 2.018187999725342 acc: 0.28125\n",
            "loss: 2.0156009197235107 acc: 0.203125\n",
            "loss: 2.048231601715088 acc: 0.21875\n",
            "loss: 2.0744516849517822 acc: 0.15625\n",
            "loss: 2.007211685180664 acc: 0.203125\n",
            "loss: 2.0106680393218994 acc: 0.171875\n",
            "loss: 2.0333733558654785 acc: 0.109375\n",
            "loss: 2.0146000385284424 acc: 0.15625\n",
            "loss: 2.060267686843872 acc: 0.15625\n",
            "loss: 2.030937433242798 acc: 0.21875\n",
            "loss: 2.0764682292938232 acc: 0.109375\n",
            "loss: 2.064847946166992 acc: 0.109375\n",
            "loss: 2.0732076168060303 acc: 0.125\n",
            "loss: 2.055271863937378 acc: 0.140625\n",
            "loss: 2.09846568107605 acc: 0.125\n",
            "loss: 2.059070587158203 acc: 0.109375\n",
            "loss: 2.105846405029297 acc: 0.0625\n",
            "loss: 2.0484814643859863 acc: 0.125\n",
            "loss: 2.0523924827575684 acc: 0.15625\n",
            "loss: 2.0691070556640625 acc: 0.109375\n",
            "loss: 2.0252788066864014 acc: 0.171875\n",
            "loss: 2.0620927810668945 acc: 0.1875\n",
            "loss: 2.0786101818084717 acc: 0.171875\n",
            "loss: 2.049955368041992 acc: 0.125\n",
            "loss: 2.051976442337036 acc: 0.1875\n",
            "loss: 2.080504894256592 acc: 0.15625\n",
            "loss: 2.0937561988830566 acc: 0.1875\n",
            "loss: 2.014702558517456 acc: 0.171875\n",
            "loss: 2.0520308017730713 acc: 0.21875\n",
            "loss: 2.0602071285247803 acc: 0.171875\n",
            "loss: 2.063559055328369 acc: 0.1875\n",
            "loss: 2.061438798904419 acc: 0.15625\n",
            "loss: 2.075244665145874 acc: 0.171875\n",
            "loss: 2.0486538410186768 acc: 0.15625\n",
            "loss: 2.0570523738861084 acc: 0.1875\n",
            "loss: 2.046945095062256 acc: 0.1875\n",
            "loss: 2.0600929260253906 acc: 0.125\n",
            "loss: 2.0915420055389404 acc: 0.15625\n",
            "loss: 2.058840751647949 acc: 0.109375\n",
            "loss: 2.134711503982544 acc: 0.09375\n",
            "loss: 2.0627949237823486 acc: 0.078125\n",
            "loss: 2.066488742828369 acc: 0.171875\n",
            "loss: 2.04369854927063 acc: 0.15625\n",
            "loss: 2.0854835510253906 acc: 0.09375\n",
            "loss: 2.0988857746124268 acc: 0.109375\n",
            "loss: 2.0714550018310547 acc: 0.125\n",
            "loss: 2.0494754314422607 acc: 0.1875\n",
            "loss: 2.036695957183838 acc: 0.15625\n",
            "loss: 2.0728704929351807 acc: 0.125\n",
            "loss: 2.0532069206237793 acc: 0.0625\n",
            "loss: 2.017375946044922 acc: 0.125\n",
            "loss: 2.071242332458496 acc: 0.15625\n",
            "loss: 2.036202907562256 acc: 0.171875\n",
            "loss: 2.0855417251586914 acc: 0.125\n",
            "loss: 2.0722153186798096 acc: 0.140625\n",
            "loss: 2.0462284088134766 acc: 0.125\n",
            "loss: 2.108438730239868 acc: 0.0625\n",
            "loss: 2.0954225063323975 acc: 0.171875\n",
            "loss: 2.0535147190093994 acc: 0.171875\n",
            "loss: 2.0485458374023438 acc: 0.171875\n",
            "loss: 2.0408756732940674 acc: 0.171875\n",
            "loss: 2.0633504390716553 acc: 0.15625\n",
            "loss: 2.027017116546631 acc: 0.15625\n",
            "loss: 2.0886847972869873 acc: 0.109375\n",
            "loss: 2.0612266063690186 acc: 0.15625\n",
            "loss: 2.04140305519104 acc: 0.15625\n",
            "loss: 2.067774772644043 acc: 0.140625\n",
            "loss: 2.079955816268921 acc: 0.171875\n",
            "loss: 2.0783510208129883 acc: 0.109375\n",
            "loss: 2.0342674255371094 acc: 0.15625\n",
            "loss: 2.0849854946136475 acc: 0.140625\n",
            "loss: 2.078409433364868 acc: 0.171875\n",
            "loss: 2.07837176322937 acc: 0.140625\n",
            "loss: 2.1318414211273193 acc: 0.109375\n",
            "loss: 1.9888477325439453 acc: 0.15625\n",
            "loss: 2.0741002559661865 acc: 0.140625\n",
            "loss: 2.0686275959014893 acc: 0.1875\n",
            "loss: 2.0465245246887207 acc: 0.13953489065170288\n",
            "67 epoch:\n",
            "loss: 2.0809433460235596 acc: 0.15625\n",
            "loss: 2.092984676361084 acc: 0.125\n",
            "loss: 2.100971221923828 acc: 0.125\n",
            "loss: 2.099912643432617 acc: 0.125\n",
            "loss: 2.058891534805298 acc: 0.15625\n",
            "loss: 2.0440356731414795 acc: 0.1875\n",
            "loss: 2.0415031909942627 acc: 0.140625\n",
            "loss: 2.0811452865600586 acc: 0.125\n",
            "loss: 2.054795265197754 acc: 0.25\n",
            "loss: 2.0880823135375977 acc: 0.0625\n",
            "loss: 2.050501823425293 acc: 0.15625\n",
            "loss: 2.04951810836792 acc: 0.140625\n",
            "loss: 2.0332682132720947 acc: 0.203125\n",
            "loss: 2.038355827331543 acc: 0.15625\n",
            "loss: 2.0551910400390625 acc: 0.171875\n",
            "loss: 2.017073154449463 acc: 0.21875\n",
            "loss: 2.0414795875549316 acc: 0.171875\n",
            "loss: 2.018831491470337 acc: 0.171875\n",
            "loss: 2.019763231277466 acc: 0.109375\n",
            "loss: 2.04427170753479 acc: 0.1875\n",
            "loss: 2.036194324493408 acc: 0.203125\n",
            "loss: 2.0582122802734375 acc: 0.140625\n",
            "loss: 2.0166304111480713 acc: 0.28125\n",
            "loss: 2.041815996170044 acc: 0.203125\n",
            "loss: 2.0439867973327637 acc: 0.171875\n",
            "loss: 2.05643630027771 acc: 0.09375\n",
            "loss: 2.0251307487487793 acc: 0.21875\n",
            "loss: 2.067230224609375 acc: 0.25\n",
            "loss: 2.078047037124634 acc: 0.140625\n",
            "loss: 2.0612809658050537 acc: 0.125\n",
            "loss: 2.0759799480438232 acc: 0.171875\n",
            "loss: 2.065197706222534 acc: 0.171875\n",
            "loss: 2.0869369506835938 acc: 0.125\n",
            "loss: 2.048036813735962 acc: 0.140625\n",
            "loss: 2.0486791133880615 acc: 0.125\n",
            "loss: 2.044797897338867 acc: 0.203125\n",
            "loss: 2.067425012588501 acc: 0.203125\n",
            "loss: 2.0597715377807617 acc: 0.09375\n",
            "loss: 2.1108641624450684 acc: 0.1875\n",
            "loss: 1.9847140312194824 acc: 0.234375\n",
            "loss: 2.066728115081787 acc: 0.1875\n",
            "loss: 2.0323524475097656 acc: 0.140625\n",
            "loss: 2.0197739601135254 acc: 0.171875\n",
            "loss: 2.0383307933807373 acc: 0.1875\n",
            "loss: 2.061815023422241 acc: 0.171875\n",
            "loss: 2.0254204273223877 acc: 0.15625\n",
            "loss: 2.131129026412964 acc: 0.140625\n",
            "loss: 2.0676584243774414 acc: 0.140625\n",
            "loss: 1.995341181755066 acc: 0.1875\n",
            "loss: 2.0258407592773438 acc: 0.1875\n",
            "loss: 2.031625747680664 acc: 0.171875\n",
            "loss: 2.053912878036499 acc: 0.15625\n",
            "loss: 2.017793893814087 acc: 0.234375\n",
            "loss: 2.094409704208374 acc: 0.109375\n",
            "loss: 2.0158896446228027 acc: 0.234375\n",
            "loss: 2.063284158706665 acc: 0.15625\n",
            "loss: 2.056443929672241 acc: 0.078125\n",
            "loss: 2.017042875289917 acc: 0.15625\n",
            "loss: 2.1297433376312256 acc: 0.171875\n",
            "loss: 2.0842885971069336 acc: 0.078125\n",
            "loss: 2.0669548511505127 acc: 0.1875\n",
            "loss: 2.0313730239868164 acc: 0.09375\n",
            "loss: 2.0189404487609863 acc: 0.21875\n",
            "loss: 2.0344226360321045 acc: 0.15625\n",
            "loss: 2.067004680633545 acc: 0.109375\n",
            "loss: 2.024620532989502 acc: 0.1875\n",
            "loss: 2.073814868927002 acc: 0.125\n",
            "loss: 2.033757448196411 acc: 0.140625\n",
            "loss: 2.0944268703460693 acc: 0.0625\n",
            "loss: 2.0217397212982178 acc: 0.203125\n",
            "loss: 2.021282434463501 acc: 0.1875\n",
            "loss: 2.043806552886963 acc: 0.1875\n",
            "loss: 2.0592873096466064 acc: 0.125\n",
            "loss: 2.0815930366516113 acc: 0.09375\n",
            "loss: 2.0244245529174805 acc: 0.140625\n",
            "loss: 2.049751043319702 acc: 0.25\n",
            "loss: 2.0687859058380127 acc: 0.15625\n",
            "loss: 2.084221839904785 acc: 0.109375\n",
            "loss: 2.0611019134521484 acc: 0.125\n",
            "loss: 2.0532989501953125 acc: 0.21875\n",
            "loss: 2.068938970565796 acc: 0.0625\n",
            "loss: 1.991346001625061 acc: 0.25\n",
            "loss: 2.054020404815674 acc: 0.140625\n",
            "loss: 2.0285327434539795 acc: 0.1875\n",
            "loss: 2.085716962814331 acc: 0.140625\n",
            "loss: 2.092700719833374 acc: 0.171875\n",
            "loss: 2.0461394786834717 acc: 0.15625\n",
            "loss: 2.068211078643799 acc: 0.171875\n",
            "loss: 2.072314977645874 acc: 0.140625\n",
            "loss: 2.034719944000244 acc: 0.1875\n",
            "loss: 2.0303125381469727 acc: 0.25\n",
            "loss: 2.0507898330688477 acc: 0.15625\n",
            "loss: 2.083595037460327 acc: 0.09375\n",
            "loss: 2.0377650260925293 acc: 0.203125\n",
            "loss: 2.0790982246398926 acc: 0.125\n",
            "loss: 2.007873058319092 acc: 0.1875\n",
            "loss: 2.064171314239502 acc: 0.15625\n",
            "loss: 2.044159173965454 acc: 0.15625\n",
            "loss: 2.0243802070617676 acc: 0.234375\n",
            "loss: 2.0557031631469727 acc: 0.265625\n",
            "loss: 2.024945020675659 acc: 0.140625\n",
            "loss: 2.016098976135254 acc: 0.171875\n",
            "loss: 2.0519042015075684 acc: 0.203125\n",
            "loss: 2.0382392406463623 acc: 0.1875\n",
            "loss: 2.0393495559692383 acc: 0.15625\n",
            "loss: 2.0536491870880127 acc: 0.140625\n",
            "loss: 2.027662515640259 acc: 0.25\n",
            "loss: 1.9820343255996704 acc: 0.171875\n",
            "loss: 2.05147647857666 acc: 0.140625\n",
            "loss: 2.0695242881774902 acc: 0.1627907007932663\n",
            "68 epoch:\n",
            "loss: 2.0971643924713135 acc: 0.125\n",
            "loss: 2.0681488513946533 acc: 0.15625\n",
            "loss: 2.0157008171081543 acc: 0.1875\n",
            "loss: 2.078821897506714 acc: 0.125\n",
            "loss: 2.0064034461975098 acc: 0.15625\n",
            "loss: 2.0124664306640625 acc: 0.25\n",
            "loss: 2.041081190109253 acc: 0.171875\n",
            "loss: 2.0552735328674316 acc: 0.203125\n",
            "loss: 2.035494327545166 acc: 0.109375\n",
            "loss: 2.0577707290649414 acc: 0.078125\n",
            "loss: 2.0370121002197266 acc: 0.140625\n",
            "loss: 2.0494768619537354 acc: 0.171875\n",
            "loss: 2.0575053691864014 acc: 0.21875\n",
            "loss: 2.0300474166870117 acc: 0.140625\n",
            "loss: 2.046093702316284 acc: 0.171875\n",
            "loss: 2.064823627471924 acc: 0.265625\n",
            "loss: 2.069706439971924 acc: 0.140625\n",
            "loss: 2.0337107181549072 acc: 0.21875\n",
            "loss: 2.0097625255584717 acc: 0.171875\n",
            "loss: 2.048750400543213 acc: 0.125\n",
            "loss: 2.003025531768799 acc: 0.234375\n",
            "loss: 2.0675389766693115 acc: 0.171875\n",
            "loss: 2.115250587463379 acc: 0.09375\n",
            "loss: 2.048290729522705 acc: 0.171875\n",
            "loss: 2.0909109115600586 acc: 0.109375\n",
            "loss: 2.0586345195770264 acc: 0.1875\n",
            "loss: 2.0179922580718994 acc: 0.1875\n",
            "loss: 1.9940848350524902 acc: 0.1875\n",
            "loss: 2.0185024738311768 acc: 0.1875\n",
            "loss: 2.0277211666107178 acc: 0.15625\n",
            "loss: 1.9639052152633667 acc: 0.171875\n",
            "loss: 2.0840659141540527 acc: 0.15625\n",
            "loss: 2.0938720703125 acc: 0.15625\n",
            "loss: 1.9747035503387451 acc: 0.234375\n",
            "loss: 2.0424163341522217 acc: 0.15625\n",
            "loss: 2.045787811279297 acc: 0.171875\n",
            "loss: 2.0045151710510254 acc: 0.1875\n",
            "loss: 2.077671766281128 acc: 0.140625\n",
            "loss: 2.056053638458252 acc: 0.171875\n",
            "loss: 2.056309700012207 acc: 0.203125\n",
            "loss: 2.060248374938965 acc: 0.1875\n",
            "loss: 2.064866781234741 acc: 0.171875\n",
            "loss: 2.066953659057617 acc: 0.046875\n",
            "loss: 2.040262460708618 acc: 0.15625\n",
            "loss: 2.0727999210357666 acc: 0.125\n",
            "loss: 2.091844320297241 acc: 0.140625\n",
            "loss: 2.0561885833740234 acc: 0.140625\n",
            "loss: 2.062807083129883 acc: 0.171875\n",
            "loss: 2.0624172687530518 acc: 0.125\n",
            "loss: 2.057647943496704 acc: 0.140625\n",
            "loss: 2.0437166690826416 acc: 0.125\n",
            "loss: 2.0519309043884277 acc: 0.1875\n",
            "loss: 2.0636096000671387 acc: 0.125\n",
            "loss: 2.0488696098327637 acc: 0.28125\n",
            "loss: 2.080775499343872 acc: 0.125\n",
            "loss: 2.0836055278778076 acc: 0.125\n",
            "loss: 2.0881316661834717 acc: 0.109375\n",
            "loss: 2.0793542861938477 acc: 0.125\n",
            "loss: 2.050837278366089 acc: 0.125\n",
            "loss: 2.0383732318878174 acc: 0.15625\n",
            "loss: 2.0896413326263428 acc: 0.109375\n",
            "loss: 2.054328203201294 acc: 0.140625\n",
            "loss: 2.0675103664398193 acc: 0.09375\n",
            "loss: 2.0146522521972656 acc: 0.171875\n",
            "loss: 2.115431308746338 acc: 0.109375\n",
            "loss: 2.0389750003814697 acc: 0.15625\n",
            "loss: 2.0215835571289062 acc: 0.1875\n",
            "loss: 2.053361654281616 acc: 0.171875\n",
            "loss: 2.034813404083252 acc: 0.09375\n",
            "loss: 2.047717571258545 acc: 0.15625\n",
            "loss: 2.0362582206726074 acc: 0.171875\n",
            "loss: 2.058699607849121 acc: 0.1875\n",
            "loss: 2.036480665206909 acc: 0.171875\n",
            "loss: 2.0126023292541504 acc: 0.15625\n",
            "loss: 2.0048835277557373 acc: 0.1875\n",
            "loss: 2.085554361343384 acc: 0.125\n",
            "loss: 2.04618763923645 acc: 0.140625\n",
            "loss: 2.036421775817871 acc: 0.203125\n",
            "loss: 1.9966959953308105 acc: 0.234375\n",
            "loss: 2.049887180328369 acc: 0.15625\n",
            "loss: 2.1221930980682373 acc: 0.078125\n",
            "loss: 2.0030171871185303 acc: 0.09375\n",
            "loss: 2.041487216949463 acc: 0.203125\n",
            "loss: 2.075946092605591 acc: 0.15625\n",
            "loss: 2.0148181915283203 acc: 0.171875\n",
            "loss: 2.029573440551758 acc: 0.203125\n",
            "loss: 2.0379371643066406 acc: 0.125\n",
            "loss: 2.04642915725708 acc: 0.171875\n",
            "loss: 2.0616989135742188 acc: 0.1875\n",
            "loss: 2.006173849105835 acc: 0.21875\n",
            "loss: 2.0243148803710938 acc: 0.203125\n",
            "loss: 2.054260492324829 acc: 0.21875\n",
            "loss: 2.071406602859497 acc: 0.125\n",
            "loss: 2.0157320499420166 acc: 0.171875\n",
            "loss: 2.046785831451416 acc: 0.203125\n",
            "loss: 2.078613758087158 acc: 0.15625\n",
            "loss: 2.0603995323181152 acc: 0.125\n",
            "loss: 1.9715720415115356 acc: 0.28125\n",
            "loss: 2.044449806213379 acc: 0.15625\n",
            "loss: 2.016911506652832 acc: 0.28125\n",
            "loss: 2.0875754356384277 acc: 0.140625\n",
            "loss: 2.0156373977661133 acc: 0.21875\n",
            "loss: 2.036198139190674 acc: 0.21875\n",
            "loss: 2.0646378993988037 acc: 0.234375\n",
            "loss: 2.079728841781616 acc: 0.140625\n",
            "loss: 2.0336103439331055 acc: 0.171875\n",
            "loss: 2.04366135597229 acc: 0.140625\n",
            "loss: 2.0442917346954346 acc: 0.109375\n",
            "loss: 2.110609531402588 acc: 0.125\n",
            "loss: 2.0584959983825684 acc: 0.1860465109348297\n",
            "69 epoch:\n",
            "loss: 2.067749500274658 acc: 0.15625\n",
            "loss: 2.027963399887085 acc: 0.1875\n",
            "loss: 2.0278377532958984 acc: 0.171875\n",
            "loss: 2.073495388031006 acc: 0.140625\n",
            "loss: 2.0080230236053467 acc: 0.234375\n",
            "loss: 2.0558061599731445 acc: 0.15625\n",
            "loss: 2.0651938915252686 acc: 0.171875\n",
            "loss: 2.04874324798584 acc: 0.203125\n",
            "loss: 2.0450382232666016 acc: 0.15625\n",
            "loss: 2.045254707336426 acc: 0.203125\n",
            "loss: 2.05810546875 acc: 0.15625\n",
            "loss: 2.0432348251342773 acc: 0.125\n",
            "loss: 2.0372934341430664 acc: 0.125\n",
            "loss: 2.0730502605438232 acc: 0.109375\n",
            "loss: 2.0433719158172607 acc: 0.171875\n",
            "loss: 2.021043539047241 acc: 0.265625\n",
            "loss: 2.02852463722229 acc: 0.171875\n",
            "loss: 2.06268310546875 acc: 0.078125\n",
            "loss: 2.035627603530884 acc: 0.1875\n",
            "loss: 2.033705472946167 acc: 0.203125\n",
            "loss: 2.020080327987671 acc: 0.234375\n",
            "loss: 2.041912078857422 acc: 0.140625\n",
            "loss: 2.0390431880950928 acc: 0.21875\n",
            "loss: 2.0480854511260986 acc: 0.1875\n",
            "loss: 2.0775678157806396 acc: 0.109375\n",
            "loss: 2.002944231033325 acc: 0.1875\n",
            "loss: 2.0080249309539795 acc: 0.265625\n",
            "loss: 2.010104179382324 acc: 0.171875\n",
            "loss: 2.039607524871826 acc: 0.15625\n",
            "loss: 2.019944906234741 acc: 0.140625\n",
            "loss: 2.0387706756591797 acc: 0.125\n",
            "loss: 2.055234670639038 acc: 0.1875\n",
            "loss: 2.096125602722168 acc: 0.15625\n",
            "loss: 2.1028993129730225 acc: 0.125\n",
            "loss: 2.0719449520111084 acc: 0.140625\n",
            "loss: 2.036919116973877 acc: 0.1875\n",
            "loss: 2.037339210510254 acc: 0.171875\n",
            "loss: 2.061185359954834 acc: 0.203125\n",
            "loss: 2.0362370014190674 acc: 0.125\n",
            "loss: 2.10684871673584 acc: 0.078125\n",
            "loss: 2.049680471420288 acc: 0.1875\n",
            "loss: 2.038130760192871 acc: 0.171875\n",
            "loss: 2.0997402667999268 acc: 0.078125\n",
            "loss: 2.030444383621216 acc: 0.15625\n",
            "loss: 2.051802396774292 acc: 0.140625\n",
            "loss: 2.053314685821533 acc: 0.15625\n",
            "loss: 2.0707664489746094 acc: 0.171875\n",
            "loss: 2.065101385116577 acc: 0.140625\n",
            "loss: 2.0557327270507812 acc: 0.171875\n",
            "loss: 2.0425925254821777 acc: 0.21875\n",
            "loss: 2.06386399269104 acc: 0.15625\n",
            "loss: 2.0574991703033447 acc: 0.1875\n",
            "loss: 2.046473741531372 acc: 0.15625\n",
            "loss: 2.1084048748016357 acc: 0.109375\n",
            "loss: 2.0360705852508545 acc: 0.15625\n",
            "loss: 2.0324225425720215 acc: 0.171875\n",
            "loss: 2.0354461669921875 acc: 0.15625\n",
            "loss: 2.041485071182251 acc: 0.125\n",
            "loss: 2.0611817836761475 acc: 0.1875\n",
            "loss: 1.9981341361999512 acc: 0.265625\n",
            "loss: 2.040546178817749 acc: 0.234375\n",
            "loss: 2.0638468265533447 acc: 0.171875\n",
            "loss: 2.0292625427246094 acc: 0.1875\n",
            "loss: 2.0147392749786377 acc: 0.171875\n",
            "loss: 2.0816590785980225 acc: 0.09375\n",
            "loss: 2.079381227493286 acc: 0.125\n",
            "loss: 2.0690364837646484 acc: 0.25\n",
            "loss: 2.0151708126068115 acc: 0.140625\n",
            "loss: 2.1546459197998047 acc: 0.046875\n",
            "loss: 2.036151885986328 acc: 0.21875\n",
            "loss: 2.02193284034729 acc: 0.140625\n",
            "loss: 2.0606319904327393 acc: 0.109375\n",
            "loss: 2.0538320541381836 acc: 0.1875\n",
            "loss: 2.1172056198120117 acc: 0.171875\n",
            "loss: 2.0120692253112793 acc: 0.203125\n",
            "loss: 2.054887294769287 acc: 0.09375\n",
            "loss: 2.0146095752716064 acc: 0.1875\n",
            "loss: 2.065206289291382 acc: 0.140625\n",
            "loss: 2.0691659450531006 acc: 0.234375\n",
            "loss: 2.1154472827911377 acc: 0.078125\n",
            "loss: 2.0116488933563232 acc: 0.21875\n",
            "loss: 2.0012917518615723 acc: 0.09375\n",
            "loss: 2.0797719955444336 acc: 0.1875\n",
            "loss: 2.075416088104248 acc: 0.140625\n",
            "loss: 2.0673234462738037 acc: 0.1875\n",
            "loss: 2.088815450668335 acc: 0.078125\n",
            "loss: 2.0397379398345947 acc: 0.1875\n",
            "loss: 2.010502815246582 acc: 0.15625\n",
            "loss: 2.047454833984375 acc: 0.203125\n",
            "loss: 2.0430245399475098 acc: 0.234375\n",
            "loss: 2.031869888305664 acc: 0.234375\n",
            "loss: 2.0290541648864746 acc: 0.234375\n",
            "loss: 2.0491936206817627 acc: 0.1875\n",
            "loss: 2.003185987472534 acc: 0.171875\n",
            "loss: 2.0184624195098877 acc: 0.125\n",
            "loss: 2.0936977863311768 acc: 0.15625\n",
            "loss: 2.038365125656128 acc: 0.203125\n",
            "loss: 2.027597427368164 acc: 0.125\n",
            "loss: 2.059723377227783 acc: 0.15625\n",
            "loss: 2.0023646354675293 acc: 0.234375\n",
            "loss: 2.0199713706970215 acc: 0.203125\n",
            "loss: 2.098280429840088 acc: 0.15625\n",
            "loss: 2.048079252243042 acc: 0.140625\n",
            "loss: 1.992425799369812 acc: 0.09375\n",
            "loss: 2.051701545715332 acc: 0.203125\n",
            "loss: 2.050488233566284 acc: 0.125\n",
            "loss: 2.0322375297546387 acc: 0.234375\n",
            "loss: 2.013831615447998 acc: 0.109375\n",
            "loss: 2.0596604347229004 acc: 0.109375\n",
            "loss: 2.0755465030670166 acc: 0.1860465109348297\n",
            "70 epoch:\n",
            "loss: 2.063971757888794 acc: 0.1875\n",
            "loss: 2.019763231277466 acc: 0.140625\n",
            "loss: 2.0465240478515625 acc: 0.1875\n",
            "loss: 2.030141592025757 acc: 0.140625\n",
            "loss: 2.0547475814819336 acc: 0.125\n",
            "loss: 2.0771400928497314 acc: 0.203125\n",
            "loss: 2.0125832557678223 acc: 0.171875\n",
            "loss: 2.0045149326324463 acc: 0.15625\n",
            "loss: 2.070037364959717 acc: 0.09375\n",
            "loss: 2.050015926361084 acc: 0.25\n",
            "loss: 2.017570734024048 acc: 0.203125\n",
            "loss: 1.9788799285888672 acc: 0.21875\n",
            "loss: 2.05263352394104 acc: 0.25\n",
            "loss: 2.0117135047912598 acc: 0.21875\n",
            "loss: 2.0439233779907227 acc: 0.140625\n",
            "loss: 2.0310351848602295 acc: 0.1875\n",
            "loss: 2.051105260848999 acc: 0.203125\n",
            "loss: 1.9953292608261108 acc: 0.234375\n",
            "loss: 1.9825471639633179 acc: 0.25\n",
            "loss: 2.073460817337036 acc: 0.171875\n",
            "loss: 2.0347838401794434 acc: 0.171875\n",
            "loss: 2.1013031005859375 acc: 0.171875\n",
            "loss: 2.0852577686309814 acc: 0.125\n",
            "loss: 2.0858750343322754 acc: 0.140625\n",
            "loss: 2.0123131275177 acc: 0.265625\n",
            "loss: 2.049945592880249 acc: 0.234375\n",
            "loss: 2.0538578033447266 acc: 0.15625\n",
            "loss: 2.0565545558929443 acc: 0.1875\n",
            "loss: 2.052766799926758 acc: 0.234375\n",
            "loss: 2.025256633758545 acc: 0.140625\n",
            "loss: 2.0148937702178955 acc: 0.15625\n",
            "loss: 2.012334108352661 acc: 0.125\n",
            "loss: 2.1052298545837402 acc: 0.15625\n",
            "loss: 2.019383192062378 acc: 0.09375\n",
            "loss: 2.050967216491699 acc: 0.1875\n",
            "loss: 2.0663185119628906 acc: 0.140625\n",
            "loss: 2.057111978530884 acc: 0.171875\n",
            "loss: 1.9772018194198608 acc: 0.203125\n",
            "loss: 2.0628015995025635 acc: 0.109375\n",
            "loss: 2.109607458114624 acc: 0.15625\n",
            "loss: 1.9808238744735718 acc: 0.21875\n",
            "loss: 2.037799596786499 acc: 0.171875\n",
            "loss: 2.025635004043579 acc: 0.234375\n",
            "loss: 2.001394510269165 acc: 0.21875\n",
            "loss: 2.0834569931030273 acc: 0.1875\n",
            "loss: 2.005059003829956 acc: 0.15625\n",
            "loss: 1.9709594249725342 acc: 0.265625\n",
            "loss: 2.0115644931793213 acc: 0.1875\n",
            "loss: 2.0362374782562256 acc: 0.21875\n",
            "loss: 2.084120750427246 acc: 0.125\n",
            "loss: 2.0955352783203125 acc: 0.140625\n",
            "loss: 2.0326991081237793 acc: 0.140625\n",
            "loss: 2.0982065200805664 acc: 0.15625\n",
            "loss: 2.033313035964966 acc: 0.171875\n",
            "loss: 2.028956890106201 acc: 0.203125\n",
            "loss: 2.0168886184692383 acc: 0.203125\n",
            "loss: 2.0349366664886475 acc: 0.171875\n",
            "loss: 2.072723150253296 acc: 0.140625\n",
            "loss: 2.040785789489746 acc: 0.15625\n",
            "loss: 2.0560035705566406 acc: 0.125\n",
            "loss: 2.0654616355895996 acc: 0.171875\n",
            "loss: 2.0700645446777344 acc: 0.203125\n",
            "loss: 2.030418872833252 acc: 0.15625\n",
            "loss: 2.034538745880127 acc: 0.234375\n",
            "loss: 2.025538444519043 acc: 0.25\n",
            "loss: 2.042687177658081 acc: 0.21875\n",
            "loss: 2.029157876968384 acc: 0.171875\n",
            "loss: 2.045579195022583 acc: 0.109375\n",
            "loss: 2.054746389389038 acc: 0.15625\n",
            "loss: 2.0283541679382324 acc: 0.1875\n",
            "loss: 1.9881582260131836 acc: 0.28125\n",
            "loss: 2.0948309898376465 acc: 0.09375\n",
            "loss: 2.0282535552978516 acc: 0.15625\n",
            "loss: 2.0078821182250977 acc: 0.1875\n",
            "loss: 2.0015625953674316 acc: 0.15625\n",
            "loss: 2.119054079055786 acc: 0.09375\n",
            "loss: 2.060514211654663 acc: 0.109375\n",
            "loss: 2.037626266479492 acc: 0.1875\n",
            "loss: 2.006578207015991 acc: 0.1875\n",
            "loss: 2.019300937652588 acc: 0.109375\n",
            "loss: 2.070348024368286 acc: 0.171875\n",
            "loss: 2.0016541481018066 acc: 0.171875\n",
            "loss: 2.0548226833343506 acc: 0.171875\n",
            "loss: 2.0045018196105957 acc: 0.171875\n",
            "loss: 2.054980754852295 acc: 0.109375\n",
            "loss: 2.0898942947387695 acc: 0.234375\n",
            "loss: 2.155349016189575 acc: 0.09375\n",
            "loss: 2.0618910789489746 acc: 0.171875\n",
            "loss: 2.0618040561676025 acc: 0.171875\n",
            "loss: 2.0901827812194824 acc: 0.140625\n",
            "loss: 2.0197980403900146 acc: 0.1875\n",
            "loss: 2.058333396911621 acc: 0.15625\n",
            "loss: 2.030674934387207 acc: 0.15625\n",
            "loss: 2.0931103229522705 acc: 0.09375\n",
            "loss: 1.9809951782226562 acc: 0.265625\n",
            "loss: 2.081547498703003 acc: 0.078125\n",
            "loss: 2.0677945613861084 acc: 0.109375\n",
            "loss: 2.0447797775268555 acc: 0.140625\n",
            "loss: 2.065563440322876 acc: 0.125\n",
            "loss: 2.039410352706909 acc: 0.1875\n",
            "loss: 2.1132161617279053 acc: 0.125\n",
            "loss: 2.0076634883880615 acc: 0.21875\n",
            "loss: 2.071493148803711 acc: 0.1875\n",
            "loss: 2.0369739532470703 acc: 0.125\n",
            "loss: 2.077518939971924 acc: 0.171875\n",
            "loss: 2.0338737964630127 acc: 0.203125\n",
            "loss: 2.0487587451934814 acc: 0.203125\n",
            "loss: 2.0852298736572266 acc: 0.09375\n",
            "loss: 2.0260236263275146 acc: 0.1875\n",
            "loss: 2.0660951137542725 acc: 0.1627907007932663\n",
            "71 epoch:\n",
            "loss: 2.0340564250946045 acc: 0.25\n",
            "loss: 2.073227643966675 acc: 0.203125\n",
            "loss: 2.042447566986084 acc: 0.203125\n",
            "loss: 2.0622990131378174 acc: 0.1875\n",
            "loss: 2.0167858600616455 acc: 0.25\n",
            "loss: 2.059452533721924 acc: 0.140625\n",
            "loss: 2.0436654090881348 acc: 0.109375\n",
            "loss: 2.0393266677856445 acc: 0.1875\n",
            "loss: 2.0032100677490234 acc: 0.1875\n",
            "loss: 2.034689426422119 acc: 0.171875\n",
            "loss: 1.9991451501846313 acc: 0.1875\n",
            "loss: 2.0422282218933105 acc: 0.234375\n",
            "loss: 2.035278797149658 acc: 0.15625\n",
            "loss: 2.0670714378356934 acc: 0.109375\n",
            "loss: 2.0164566040039062 acc: 0.25\n",
            "loss: 2.0500271320343018 acc: 0.140625\n",
            "loss: 2.0405445098876953 acc: 0.15625\n",
            "loss: 2.060453176498413 acc: 0.140625\n",
            "loss: 2.044867753982544 acc: 0.140625\n",
            "loss: 2.011903762817383 acc: 0.21875\n",
            "loss: 1.9996508359909058 acc: 0.265625\n",
            "loss: 2.0449390411376953 acc: 0.15625\n",
            "loss: 2.1489953994750977 acc: 0.140625\n",
            "loss: 2.0809454917907715 acc: 0.21875\n",
            "loss: 2.086735486984253 acc: 0.171875\n",
            "loss: 1.966030240058899 acc: 0.203125\n",
            "loss: 1.992941975593567 acc: 0.265625\n",
            "loss: 2.0332539081573486 acc: 0.1875\n",
            "loss: 2.0427045822143555 acc: 0.109375\n",
            "loss: 2.004263401031494 acc: 0.1875\n",
            "loss: 2.002845287322998 acc: 0.21875\n",
            "loss: 2.0548434257507324 acc: 0.234375\n",
            "loss: 2.004638433456421 acc: 0.234375\n",
            "loss: 2.010770320892334 acc: 0.140625\n",
            "loss: 2.0658345222473145 acc: 0.140625\n",
            "loss: 2.0670032501220703 acc: 0.078125\n",
            "loss: 2.055203676223755 acc: 0.140625\n",
            "loss: 2.021634101867676 acc: 0.15625\n",
            "loss: 2.082237720489502 acc: 0.21875\n",
            "loss: 2.0403494834899902 acc: 0.171875\n",
            "loss: 2.0310513973236084 acc: 0.15625\n",
            "loss: 2.031561851501465 acc: 0.171875\n",
            "loss: 2.046370029449463 acc: 0.140625\n",
            "loss: 2.0176444053649902 acc: 0.171875\n",
            "loss: 2.0812952518463135 acc: 0.109375\n",
            "loss: 2.019685983657837 acc: 0.15625\n",
            "loss: 2.054685115814209 acc: 0.125\n",
            "loss: 2.0281410217285156 acc: 0.171875\n",
            "loss: 2.007246732711792 acc: 0.1875\n",
            "loss: 2.0010383129119873 acc: 0.234375\n",
            "loss: 2.020519495010376 acc: 0.15625\n",
            "loss: 1.9863166809082031 acc: 0.171875\n",
            "loss: 2.0512473583221436 acc: 0.1875\n",
            "loss: 2.0350501537323 acc: 0.171875\n",
            "loss: 2.0353829860687256 acc: 0.15625\n",
            "loss: 2.07875394821167 acc: 0.15625\n",
            "loss: 2.0631935596466064 acc: 0.1875\n",
            "loss: 2.0305118560791016 acc: 0.1875\n",
            "loss: 2.0717461109161377 acc: 0.1875\n",
            "loss: 2.033154249191284 acc: 0.15625\n",
            "loss: 2.0248095989227295 acc: 0.21875\n",
            "loss: 2.0048155784606934 acc: 0.203125\n",
            "loss: 2.0491161346435547 acc: 0.109375\n",
            "loss: 2.0751261711120605 acc: 0.171875\n",
            "loss: 2.06418776512146 acc: 0.15625\n",
            "loss: 2.026398181915283 acc: 0.1875\n",
            "loss: 2.0625383853912354 acc: 0.15625\n",
            "loss: 2.089411735534668 acc: 0.125\n",
            "loss: 2.0261621475219727 acc: 0.109375\n",
            "loss: 2.042783737182617 acc: 0.203125\n",
            "loss: 1.9703831672668457 acc: 0.234375\n",
            "loss: 2.022413969039917 acc: 0.15625\n",
            "loss: 2.058715343475342 acc: 0.171875\n",
            "loss: 1.9860998392105103 acc: 0.28125\n",
            "loss: 1.9820047616958618 acc: 0.234375\n",
            "loss: 2.058105945587158 acc: 0.203125\n",
            "loss: 2.062055826187134 acc: 0.125\n",
            "loss: 2.0763285160064697 acc: 0.0625\n",
            "loss: 2.055756092071533 acc: 0.1875\n",
            "loss: 2.0612127780914307 acc: 0.140625\n",
            "loss: 2.051337480545044 acc: 0.21875\n",
            "loss: 2.0123300552368164 acc: 0.1875\n",
            "loss: 2.062957763671875 acc: 0.15625\n",
            "loss: 2.0330898761749268 acc: 0.15625\n",
            "loss: 2.0291974544525146 acc: 0.234375\n",
            "loss: 2.0863664150238037 acc: 0.109375\n",
            "loss: 2.020864248275757 acc: 0.203125\n",
            "loss: 2.0558300018310547 acc: 0.171875\n",
            "loss: 2.0230696201324463 acc: 0.15625\n",
            "loss: 2.0831780433654785 acc: 0.078125\n",
            "loss: 2.031825304031372 acc: 0.125\n",
            "loss: 2.0113468170166016 acc: 0.25\n",
            "loss: 2.035991907119751 acc: 0.171875\n",
            "loss: 2.0834174156188965 acc: 0.09375\n",
            "loss: 2.08132266998291 acc: 0.171875\n",
            "loss: 2.099551200866699 acc: 0.171875\n",
            "loss: 2.047191619873047 acc: 0.234375\n",
            "loss: 1.9727336168289185 acc: 0.234375\n",
            "loss: 2.028048038482666 acc: 0.15625\n",
            "loss: 2.0513155460357666 acc: 0.171875\n",
            "loss: 2.1025147438049316 acc: 0.09375\n",
            "loss: 2.044861316680908 acc: 0.203125\n",
            "loss: 2.0535826683044434 acc: 0.140625\n",
            "loss: 2.093172311782837 acc: 0.203125\n",
            "loss: 2.029201030731201 acc: 0.1875\n",
            "loss: 2.010138988494873 acc: 0.09375\n",
            "loss: 1.9897780418395996 acc: 0.234375\n",
            "loss: 2.0668342113494873 acc: 0.140625\n",
            "loss: 2.0231311321258545 acc: 0.15625\n",
            "loss: 2.084761381149292 acc: 0.25581395626068115\n",
            "72 epoch:\n",
            "loss: 2.0389537811279297 acc: 0.15625\n",
            "loss: 2.007512092590332 acc: 0.140625\n",
            "loss: 2.0222842693328857 acc: 0.21875\n",
            "loss: 2.008633852005005 acc: 0.140625\n",
            "loss: 2.0320956707000732 acc: 0.25\n",
            "loss: 2.0451667308807373 acc: 0.171875\n",
            "loss: 2.0329911708831787 acc: 0.15625\n",
            "loss: 2.0573768615722656 acc: 0.1875\n",
            "loss: 2.0892815589904785 acc: 0.109375\n",
            "loss: 2.0312631130218506 acc: 0.15625\n",
            "loss: 1.9937349557876587 acc: 0.28125\n",
            "loss: 1.9896271228790283 acc: 0.171875\n",
            "loss: 2.0099542140960693 acc: 0.25\n",
            "loss: 2.03908371925354 acc: 0.140625\n",
            "loss: 2.036895513534546 acc: 0.171875\n",
            "loss: 2.0178709030151367 acc: 0.25\n",
            "loss: 2.0229904651641846 acc: 0.140625\n",
            "loss: 2.0453381538391113 acc: 0.140625\n",
            "loss: 2.0982627868652344 acc: 0.109375\n",
            "loss: 1.9952033758163452 acc: 0.21875\n",
            "loss: 2.05031418800354 acc: 0.140625\n",
            "loss: 2.0880892276763916 acc: 0.15625\n",
            "loss: 2.0260963439941406 acc: 0.203125\n",
            "loss: 2.0611534118652344 acc: 0.1875\n",
            "loss: 2.049358367919922 acc: 0.171875\n",
            "loss: 2.084397315979004 acc: 0.140625\n",
            "loss: 2.0799176692962646 acc: 0.1875\n",
            "loss: 2.0472307205200195 acc: 0.125\n",
            "loss: 2.0445077419281006 acc: 0.109375\n",
            "loss: 2.0324108600616455 acc: 0.203125\n",
            "loss: 1.9882230758666992 acc: 0.203125\n",
            "loss: 1.999835729598999 acc: 0.234375\n",
            "loss: 2.038914918899536 acc: 0.15625\n",
            "loss: 2.0799012184143066 acc: 0.171875\n",
            "loss: 2.0348269939422607 acc: 0.15625\n",
            "loss: 2.047515630722046 acc: 0.109375\n",
            "loss: 2.033442974090576 acc: 0.1875\n",
            "loss: 2.028811454772949 acc: 0.15625\n",
            "loss: 1.9978102445602417 acc: 0.21875\n",
            "loss: 2.012666702270508 acc: 0.1875\n",
            "loss: 1.98531973361969 acc: 0.21875\n",
            "loss: 2.0303683280944824 acc: 0.171875\n",
            "loss: 1.9822783470153809 acc: 0.3125\n",
            "loss: 2.0536937713623047 acc: 0.15625\n",
            "loss: 2.0879271030426025 acc: 0.125\n",
            "loss: 2.024200439453125 acc: 0.171875\n",
            "loss: 2.0305163860321045 acc: 0.203125\n",
            "loss: 1.981672763824463 acc: 0.234375\n",
            "loss: 1.9859153032302856 acc: 0.25\n",
            "loss: 2.0566954612731934 acc: 0.15625\n",
            "loss: 2.0866506099700928 acc: 0.125\n",
            "loss: 2.0784549713134766 acc: 0.15625\n",
            "loss: 2.0469348430633545 acc: 0.1875\n",
            "loss: 2.0323069095611572 acc: 0.171875\n",
            "loss: 1.992173194885254 acc: 0.203125\n",
            "loss: 2.0529322624206543 acc: 0.171875\n",
            "loss: 2.0131938457489014 acc: 0.171875\n",
            "loss: 2.0327181816101074 acc: 0.1875\n",
            "loss: 2.0306661128997803 acc: 0.1875\n",
            "loss: 2.0972814559936523 acc: 0.078125\n",
            "loss: 2.0536985397338867 acc: 0.171875\n",
            "loss: 2.153542995452881 acc: 0.0625\n",
            "loss: 2.03230357170105 acc: 0.203125\n",
            "loss: 1.988559603691101 acc: 0.203125\n",
            "loss: 2.0269720554351807 acc: 0.15625\n",
            "loss: 2.06898832321167 acc: 0.171875\n",
            "loss: 2.086042881011963 acc: 0.125\n",
            "loss: 2.0593245029449463 acc: 0.1875\n",
            "loss: 2.0471725463867188 acc: 0.171875\n",
            "loss: 2.062309741973877 acc: 0.15625\n",
            "loss: 2.005723476409912 acc: 0.125\n",
            "loss: 2.0456178188323975 acc: 0.1875\n",
            "loss: 2.0251224040985107 acc: 0.171875\n",
            "loss: 2.047978639602661 acc: 0.1875\n",
            "loss: 2.05446195602417 acc: 0.203125\n",
            "loss: 2.082444906234741 acc: 0.203125\n",
            "loss: 2.1089212894439697 acc: 0.171875\n",
            "loss: 2.060816764831543 acc: 0.171875\n",
            "loss: 1.9939708709716797 acc: 0.28125\n",
            "loss: 2.1109378337860107 acc: 0.09375\n",
            "loss: 2.065713405609131 acc: 0.203125\n",
            "loss: 2.043109655380249 acc: 0.203125\n",
            "loss: 2.009387493133545 acc: 0.15625\n",
            "loss: 2.014942169189453 acc: 0.296875\n",
            "loss: 2.0273585319519043 acc: 0.171875\n",
            "loss: 2.088299512863159 acc: 0.0625\n",
            "loss: 2.056375741958618 acc: 0.1875\n",
            "loss: 2.024038314819336 acc: 0.234375\n",
            "loss: 2.084867238998413 acc: 0.1875\n",
            "loss: 2.0673916339874268 acc: 0.09375\n",
            "loss: 2.0973103046417236 acc: 0.171875\n",
            "loss: 2.026496648788452 acc: 0.234375\n",
            "loss: 2.0486977100372314 acc: 0.140625\n",
            "loss: 2.0440311431884766 acc: 0.125\n",
            "loss: 1.993347406387329 acc: 0.125\n",
            "loss: 2.053480625152588 acc: 0.125\n",
            "loss: 2.035271406173706 acc: 0.125\n",
            "loss: 1.9991202354431152 acc: 0.296875\n",
            "loss: 1.986800193786621 acc: 0.25\n",
            "loss: 2.0487778186798096 acc: 0.203125\n",
            "loss: 2.0066866874694824 acc: 0.1875\n",
            "loss: 1.9952181577682495 acc: 0.203125\n",
            "loss: 2.0721535682678223 acc: 0.203125\n",
            "loss: 2.055392265319824 acc: 0.25\n",
            "loss: 2.0134878158569336 acc: 0.1875\n",
            "loss: 2.102947473526001 acc: 0.15625\n",
            "loss: 2.0153286457061768 acc: 0.171875\n",
            "loss: 2.0123491287231445 acc: 0.1875\n",
            "loss: 2.003153085708618 acc: 0.21875\n",
            "loss: 1.9860516786575317 acc: 0.23255813121795654\n",
            "73 epoch:\n",
            "loss: 2.001422166824341 acc: 0.203125\n",
            "loss: 2.049063205718994 acc: 0.21875\n",
            "loss: 2.0027475357055664 acc: 0.140625\n",
            "loss: 2.1030168533325195 acc: 0.078125\n",
            "loss: 2.096424102783203 acc: 0.140625\n",
            "loss: 2.0388081073760986 acc: 0.15625\n",
            "loss: 2.05454158782959 acc: 0.171875\n",
            "loss: 1.9562773704528809 acc: 0.3125\n",
            "loss: 2.0170676708221436 acc: 0.203125\n",
            "loss: 2.081204414367676 acc: 0.109375\n",
            "loss: 1.9969197511672974 acc: 0.140625\n",
            "loss: 2.01859974861145 acc: 0.234375\n",
            "loss: 2.051414728164673 acc: 0.203125\n",
            "loss: 2.04803204536438 acc: 0.15625\n",
            "loss: 1.9993857145309448 acc: 0.15625\n",
            "loss: 2.0019140243530273 acc: 0.203125\n",
            "loss: 1.9847962856292725 acc: 0.1875\n",
            "loss: 1.9843504428863525 acc: 0.1875\n",
            "loss: 2.044135808944702 acc: 0.09375\n",
            "loss: 2.0536770820617676 acc: 0.15625\n",
            "loss: 2.0324246883392334 acc: 0.1875\n",
            "loss: 2.0486741065979004 acc: 0.140625\n",
            "loss: 2.0377047061920166 acc: 0.203125\n",
            "loss: 2.0353338718414307 acc: 0.203125\n",
            "loss: 2.0304205417633057 acc: 0.203125\n",
            "loss: 2.124678134918213 acc: 0.125\n",
            "loss: 2.0426321029663086 acc: 0.15625\n",
            "loss: 2.0358645915985107 acc: 0.140625\n",
            "loss: 2.0659730434417725 acc: 0.171875\n",
            "loss: 2.0183300971984863 acc: 0.171875\n",
            "loss: 2.0852878093719482 acc: 0.15625\n",
            "loss: 2.0623679161071777 acc: 0.171875\n",
            "loss: 2.062939167022705 acc: 0.203125\n",
            "loss: 2.0394818782806396 acc: 0.15625\n",
            "loss: 2.005934238433838 acc: 0.234375\n",
            "loss: 2.0506210327148438 acc: 0.0625\n",
            "loss: 2.0157742500305176 acc: 0.125\n",
            "loss: 2.0198867321014404 acc: 0.203125\n",
            "loss: 2.0243923664093018 acc: 0.171875\n",
            "loss: 2.0425119400024414 acc: 0.15625\n",
            "loss: 2.0474727153778076 acc: 0.171875\n",
            "loss: 2.070646047592163 acc: 0.109375\n",
            "loss: 2.0456676483154297 acc: 0.171875\n",
            "loss: 2.038766622543335 acc: 0.1875\n",
            "loss: 2.0316524505615234 acc: 0.1875\n",
            "loss: 1.9613432884216309 acc: 0.1875\n",
            "loss: 2.012746810913086 acc: 0.28125\n",
            "loss: 2.0166544914245605 acc: 0.25\n",
            "loss: 2.050095319747925 acc: 0.140625\n",
            "loss: 2.0727462768554688 acc: 0.140625\n",
            "loss: 2.0581700801849365 acc: 0.171875\n",
            "loss: 2.0641469955444336 acc: 0.140625\n",
            "loss: 2.032372236251831 acc: 0.203125\n",
            "loss: 2.0468251705169678 acc: 0.203125\n",
            "loss: 2.044344902038574 acc: 0.1875\n",
            "loss: 2.043339967727661 acc: 0.125\n",
            "loss: 2.063115119934082 acc: 0.140625\n",
            "loss: 2.0008490085601807 acc: 0.234375\n",
            "loss: 2.020416021347046 acc: 0.125\n",
            "loss: 2.0069241523742676 acc: 0.15625\n",
            "loss: 2.0438356399536133 acc: 0.203125\n",
            "loss: 2.0675227642059326 acc: 0.15625\n",
            "loss: 1.9942781925201416 acc: 0.203125\n",
            "loss: 2.023109197616577 acc: 0.21875\n",
            "loss: 2.029644012451172 acc: 0.171875\n",
            "loss: 2.000286817550659 acc: 0.1875\n",
            "loss: 2.028425455093384 acc: 0.171875\n",
            "loss: 2.0429208278656006 acc: 0.125\n",
            "loss: 2.0187554359436035 acc: 0.15625\n",
            "loss: 2.0097177028656006 acc: 0.234375\n",
            "loss: 2.0877621173858643 acc: 0.15625\n",
            "loss: 1.9710042476654053 acc: 0.203125\n",
            "loss: 2.036086320877075 acc: 0.140625\n",
            "loss: 2.094277858734131 acc: 0.109375\n",
            "loss: 2.0040078163146973 acc: 0.1875\n",
            "loss: 2.0926051139831543 acc: 0.140625\n",
            "loss: 1.9902865886688232 acc: 0.234375\n",
            "loss: 2.108025550842285 acc: 0.140625\n",
            "loss: 2.0964608192443848 acc: 0.171875\n",
            "loss: 2.0516109466552734 acc: 0.140625\n",
            "loss: 2.0919811725616455 acc: 0.109375\n",
            "loss: 2.0658793449401855 acc: 0.140625\n",
            "loss: 2.014004945755005 acc: 0.25\n",
            "loss: 1.9926397800445557 acc: 0.21875\n",
            "loss: 2.058492660522461 acc: 0.140625\n",
            "loss: 2.0209569931030273 acc: 0.140625\n",
            "loss: 2.027270555496216 acc: 0.15625\n",
            "loss: 2.0698742866516113 acc: 0.15625\n",
            "loss: 2.042786121368408 acc: 0.1875\n",
            "loss: 2.02223801612854 acc: 0.1875\n",
            "loss: 1.9602996110916138 acc: 0.21875\n",
            "loss: 1.9521924257278442 acc: 0.234375\n",
            "loss: 2.0068349838256836 acc: 0.203125\n",
            "loss: 2.0258827209472656 acc: 0.234375\n",
            "loss: 2.061809539794922 acc: 0.140625\n",
            "loss: 2.0620369911193848 acc: 0.171875\n",
            "loss: 2.017502546310425 acc: 0.15625\n",
            "loss: 2.0325098037719727 acc: 0.15625\n",
            "loss: 2.0479512214660645 acc: 0.203125\n",
            "loss: 2.0082554817199707 acc: 0.15625\n",
            "loss: 2.0343501567840576 acc: 0.203125\n",
            "loss: 1.9707709550857544 acc: 0.171875\n",
            "loss: 2.0304627418518066 acc: 0.171875\n",
            "loss: 2.032815933227539 acc: 0.203125\n",
            "loss: 2.0237534046173096 acc: 0.234375\n",
            "loss: 2.059833288192749 acc: 0.203125\n",
            "loss: 2.0643386840820312 acc: 0.125\n",
            "loss: 1.9869109392166138 acc: 0.140625\n",
            "loss: 2.031125783920288 acc: 0.171875\n",
            "loss: 2.032470941543579 acc: 0.1860465109348297\n",
            "74 epoch:\n",
            "loss: 2.0372447967529297 acc: 0.203125\n",
            "loss: 2.017371654510498 acc: 0.109375\n",
            "loss: 2.02994966506958 acc: 0.140625\n",
            "loss: 2.0531504154205322 acc: 0.171875\n",
            "loss: 2.161076545715332 acc: 0.140625\n",
            "loss: 2.06801176071167 acc: 0.09375\n",
            "loss: 1.9663456678390503 acc: 0.21875\n",
            "loss: 2.047417640686035 acc: 0.0625\n",
            "loss: 2.0141890048980713 acc: 0.171875\n",
            "loss: 2.0627002716064453 acc: 0.109375\n",
            "loss: 1.988466501235962 acc: 0.15625\n",
            "loss: 2.0112595558166504 acc: 0.21875\n",
            "loss: 1.9624987840652466 acc: 0.234375\n",
            "loss: 2.028183937072754 acc: 0.140625\n",
            "loss: 1.975316047668457 acc: 0.21875\n",
            "loss: 2.0762784481048584 acc: 0.15625\n",
            "loss: 2.036240816116333 acc: 0.15625\n",
            "loss: 2.0513710975646973 acc: 0.296875\n",
            "loss: 1.9630951881408691 acc: 0.1875\n",
            "loss: 2.0943517684936523 acc: 0.203125\n",
            "loss: 1.9857380390167236 acc: 0.203125\n",
            "loss: 2.053588390350342 acc: 0.125\n",
            "loss: 1.9944382905960083 acc: 0.21875\n",
            "loss: 2.0234534740448 acc: 0.25\n",
            "loss: 2.018399238586426 acc: 0.171875\n",
            "loss: 2.0852930545806885 acc: 0.203125\n",
            "loss: 2.043205499649048 acc: 0.203125\n",
            "loss: 1.9708290100097656 acc: 0.1875\n",
            "loss: 2.021113634109497 acc: 0.109375\n",
            "loss: 2.090762138366699 acc: 0.109375\n",
            "loss: 2.0249831676483154 acc: 0.15625\n",
            "loss: 2.0240707397460938 acc: 0.21875\n",
            "loss: 2.0763802528381348 acc: 0.171875\n",
            "loss: 2.0697672367095947 acc: 0.109375\n",
            "loss: 2.060029983520508 acc: 0.125\n",
            "loss: 2.048900842666626 acc: 0.171875\n",
            "loss: 2.0527305603027344 acc: 0.171875\n",
            "loss: 1.9867205619812012 acc: 0.234375\n",
            "loss: 2.0598464012145996 acc: 0.15625\n",
            "loss: 2.0281784534454346 acc: 0.203125\n",
            "loss: 2.0544209480285645 acc: 0.171875\n",
            "loss: 1.986504316329956 acc: 0.15625\n",
            "loss: 1.9987730979919434 acc: 0.203125\n",
            "loss: 2.0374915599823 acc: 0.203125\n",
            "loss: 2.031365394592285 acc: 0.15625\n",
            "loss: 2.0090579986572266 acc: 0.140625\n",
            "loss: 2.00807785987854 acc: 0.171875\n",
            "loss: 2.00268816947937 acc: 0.140625\n",
            "loss: 2.0023717880249023 acc: 0.25\n",
            "loss: 2.0710651874542236 acc: 0.171875\n",
            "loss: 2.068718433380127 acc: 0.171875\n",
            "loss: 2.0389182567596436 acc: 0.171875\n",
            "loss: 2.050577163696289 acc: 0.125\n",
            "loss: 2.0395071506500244 acc: 0.203125\n",
            "loss: 2.0757381916046143 acc: 0.171875\n",
            "loss: 2.010331392288208 acc: 0.171875\n",
            "loss: 1.9964174032211304 acc: 0.1875\n",
            "loss: 2.015979528427124 acc: 0.140625\n",
            "loss: 2.0312416553497314 acc: 0.265625\n",
            "loss: 2.060235023498535 acc: 0.21875\n",
            "loss: 2.0736310482025146 acc: 0.125\n",
            "loss: 2.005632162094116 acc: 0.28125\n",
            "loss: 2.0539472103118896 acc: 0.15625\n",
            "loss: 2.023646116256714 acc: 0.15625\n",
            "loss: 2.0234735012054443 acc: 0.140625\n",
            "loss: 1.9964463710784912 acc: 0.234375\n",
            "loss: 2.0172314643859863 acc: 0.234375\n",
            "loss: 2.013648748397827 acc: 0.21875\n",
            "loss: 1.9998458623886108 acc: 0.21875\n",
            "loss: 1.9742083549499512 acc: 0.15625\n",
            "loss: 2.05141019821167 acc: 0.28125\n",
            "loss: 2.0984482765197754 acc: 0.15625\n",
            "loss: 2.0486040115356445 acc: 0.1875\n",
            "loss: 2.009976863861084 acc: 0.1875\n",
            "loss: 2.0509769916534424 acc: 0.125\n",
            "loss: 2.0240159034729004 acc: 0.15625\n",
            "loss: 2.0646209716796875 acc: 0.140625\n",
            "loss: 2.0036873817443848 acc: 0.21875\n",
            "loss: 2.061044692993164 acc: 0.09375\n",
            "loss: 1.9786139726638794 acc: 0.203125\n",
            "loss: 2.0948896408081055 acc: 0.140625\n",
            "loss: 1.9811915159225464 acc: 0.1875\n",
            "loss: 2.0319020748138428 acc: 0.203125\n",
            "loss: 2.064737319946289 acc: 0.140625\n",
            "loss: 2.045179843902588 acc: 0.1875\n",
            "loss: 2.04150128364563 acc: 0.1875\n",
            "loss: 2.0133113861083984 acc: 0.15625\n",
            "loss: 1.9863497018814087 acc: 0.1875\n",
            "loss: 1.9887473583221436 acc: 0.265625\n",
            "loss: 2.051053047180176 acc: 0.1875\n",
            "loss: 2.06299090385437 acc: 0.109375\n",
            "loss: 2.045557975769043 acc: 0.15625\n",
            "loss: 2.057791233062744 acc: 0.171875\n",
            "loss: 2.0461831092834473 acc: 0.1875\n",
            "loss: 1.982384443283081 acc: 0.265625\n",
            "loss: 1.9765859842300415 acc: 0.25\n",
            "loss: 2.0740838050842285 acc: 0.140625\n",
            "loss: 2.0348827838897705 acc: 0.125\n",
            "loss: 2.05922532081604 acc: 0.203125\n",
            "loss: 2.0088353157043457 acc: 0.1875\n",
            "loss: 2.079275131225586 acc: 0.1875\n",
            "loss: 2.057899236679077 acc: 0.1875\n",
            "loss: 2.046741247177124 acc: 0.15625\n",
            "loss: 2.0227246284484863 acc: 0.171875\n",
            "loss: 2.0753331184387207 acc: 0.09375\n",
            "loss: 1.989585518836975 acc: 0.21875\n",
            "loss: 2.026228666305542 acc: 0.203125\n",
            "loss: 2.01674485206604 acc: 0.171875\n",
            "loss: 2.0332419872283936 acc: 0.125\n",
            "loss: 2.132094144821167 acc: 0.11627906560897827\n",
            "75 epoch:\n",
            "loss: 2.10483717918396 acc: 0.1875\n",
            "loss: 2.028561592102051 acc: 0.234375\n",
            "loss: 2.038339138031006 acc: 0.234375\n",
            "loss: 2.017230272293091 acc: 0.1875\n",
            "loss: 2.0657742023468018 acc: 0.140625\n",
            "loss: 2.0751914978027344 acc: 0.21875\n",
            "loss: 2.039456367492676 acc: 0.125\n",
            "loss: 2.063248872756958 acc: 0.140625\n",
            "loss: 2.0062224864959717 acc: 0.1875\n",
            "loss: 2.0439422130584717 acc: 0.140625\n",
            "loss: 1.9867678880691528 acc: 0.21875\n",
            "loss: 2.0408387184143066 acc: 0.203125\n",
            "loss: 2.0389294624328613 acc: 0.140625\n",
            "loss: 2.0338850021362305 acc: 0.1875\n",
            "loss: 1.9527175426483154 acc: 0.265625\n",
            "loss: 2.015841484069824 acc: 0.171875\n",
            "loss: 1.9988062381744385 acc: 0.1875\n",
            "loss: 2.039123058319092 acc: 0.1875\n",
            "loss: 2.0314154624938965 acc: 0.09375\n",
            "loss: 2.038658618927002 acc: 0.140625\n",
            "loss: 2.0508413314819336 acc: 0.15625\n",
            "loss: 1.9534826278686523 acc: 0.171875\n",
            "loss: 1.989475965499878 acc: 0.203125\n",
            "loss: 1.9996590614318848 acc: 0.171875\n",
            "loss: 2.0247554779052734 acc: 0.140625\n",
            "loss: 2.0431811809539795 acc: 0.125\n",
            "loss: 2.0220961570739746 acc: 0.1875\n",
            "loss: 2.0119264125823975 acc: 0.140625\n",
            "loss: 1.9906922578811646 acc: 0.21875\n",
            "loss: 2.021944761276245 acc: 0.265625\n",
            "loss: 2.0064632892608643 acc: 0.25\n",
            "loss: 1.9970316886901855 acc: 0.15625\n",
            "loss: 2.0461981296539307 acc: 0.25\n",
            "loss: 2.1091620922088623 acc: 0.125\n",
            "loss: 2.0535311698913574 acc: 0.0625\n",
            "loss: 2.0871078968048096 acc: 0.140625\n",
            "loss: 2.096121072769165 acc: 0.125\n",
            "loss: 2.0170340538024902 acc: 0.1875\n",
            "loss: 2.0208258628845215 acc: 0.234375\n",
            "loss: 2.0223731994628906 acc: 0.109375\n",
            "loss: 1.9451463222503662 acc: 0.203125\n",
            "loss: 2.0066123008728027 acc: 0.140625\n",
            "loss: 2.0861716270446777 acc: 0.140625\n",
            "loss: 2.010842800140381 acc: 0.21875\n",
            "loss: 2.0607175827026367 acc: 0.21875\n",
            "loss: 2.0451574325561523 acc: 0.234375\n",
            "loss: 2.031567096710205 acc: 0.203125\n",
            "loss: 2.100780487060547 acc: 0.125\n",
            "loss: 2.0762112140655518 acc: 0.171875\n",
            "loss: 2.123039722442627 acc: 0.09375\n",
            "loss: 2.0695693492889404 acc: 0.09375\n",
            "loss: 2.041745662689209 acc: 0.15625\n",
            "loss: 2.0519723892211914 acc: 0.140625\n",
            "loss: 2.0612094402313232 acc: 0.09375\n",
            "loss: 2.0555243492126465 acc: 0.140625\n",
            "loss: 1.9719358682632446 acc: 0.28125\n",
            "loss: 2.0259852409362793 acc: 0.15625\n",
            "loss: 2.0825467109680176 acc: 0.140625\n",
            "loss: 2.01720929145813 acc: 0.171875\n",
            "loss: 1.9876418113708496 acc: 0.25\n",
            "loss: 2.0096423625946045 acc: 0.1875\n",
            "loss: 2.024852752685547 acc: 0.15625\n",
            "loss: 2.035165786743164 acc: 0.171875\n",
            "loss: 2.021807909011841 acc: 0.21875\n",
            "loss: 2.006073236465454 acc: 0.25\n",
            "loss: 2.0411453247070312 acc: 0.171875\n",
            "loss: 2.0390427112579346 acc: 0.171875\n",
            "loss: 1.9974271059036255 acc: 0.234375\n",
            "loss: 1.9881194829940796 acc: 0.203125\n",
            "loss: 2.105722188949585 acc: 0.21875\n",
            "loss: 2.001526117324829 acc: 0.140625\n",
            "loss: 2.059091329574585 acc: 0.1875\n",
            "loss: 2.050454616546631 acc: 0.21875\n",
            "loss: 2.0847251415252686 acc: 0.21875\n",
            "loss: 2.0289692878723145 acc: 0.203125\n",
            "loss: 2.001770496368408 acc: 0.171875\n",
            "loss: 1.9610512256622314 acc: 0.1875\n",
            "loss: 2.0501091480255127 acc: 0.125\n",
            "loss: 2.00223445892334 acc: 0.203125\n",
            "loss: 2.0269720554351807 acc: 0.1875\n",
            "loss: 2.0343925952911377 acc: 0.109375\n",
            "loss: 2.0012047290802 acc: 0.1875\n",
            "loss: 2.068301200866699 acc: 0.171875\n",
            "loss: 2.0120766162872314 acc: 0.171875\n",
            "loss: 1.9976998567581177 acc: 0.1875\n",
            "loss: 2.054590940475464 acc: 0.25\n",
            "loss: 2.0786056518554688 acc: 0.15625\n",
            "loss: 2.038088321685791 acc: 0.171875\n",
            "loss: 2.0311574935913086 acc: 0.171875\n",
            "loss: 1.987996220588684 acc: 0.21875\n",
            "loss: 2.0182254314422607 acc: 0.078125\n",
            "loss: 2.0194873809814453 acc: 0.15625\n",
            "loss: 2.0230112075805664 acc: 0.1875\n",
            "loss: 2.0244922637939453 acc: 0.234375\n",
            "loss: 2.0314342975616455 acc: 0.1875\n",
            "loss: 2.0641863346099854 acc: 0.140625\n",
            "loss: 2.0404999256134033 acc: 0.140625\n",
            "loss: 2.028115749359131 acc: 0.1875\n",
            "loss: 2.0730838775634766 acc: 0.109375\n",
            "loss: 2.081730604171753 acc: 0.15625\n",
            "loss: 1.9904725551605225 acc: 0.203125\n",
            "loss: 2.041311502456665 acc: 0.203125\n",
            "loss: 2.068706512451172 acc: 0.09375\n",
            "loss: 2.013038396835327 acc: 0.109375\n",
            "loss: 2.023193359375 acc: 0.171875\n",
            "loss: 2.05411696434021 acc: 0.234375\n",
            "loss: 2.001171588897705 acc: 0.25\n",
            "loss: 2.0599732398986816 acc: 0.265625\n",
            "loss: 1.9813423156738281 acc: 0.171875\n",
            "loss: 2.0231542587280273 acc: 0.1627907007932663\n",
            "76 epoch:\n",
            "loss: 1.9642386436462402 acc: 0.1875\n",
            "loss: 2.0486204624176025 acc: 0.1875\n",
            "loss: 2.033730983734131 acc: 0.15625\n",
            "loss: 1.99895441532135 acc: 0.125\n",
            "loss: 2.046664237976074 acc: 0.21875\n",
            "loss: 2.0389492511749268 acc: 0.203125\n",
            "loss: 2.0529422760009766 acc: 0.078125\n",
            "loss: 1.9720709323883057 acc: 0.234375\n",
            "loss: 2.0066215991973877 acc: 0.15625\n",
            "loss: 1.9582538604736328 acc: 0.1875\n",
            "loss: 2.0640976428985596 acc: 0.21875\n",
            "loss: 2.024319648742676 acc: 0.21875\n",
            "loss: 2.0299086570739746 acc: 0.109375\n",
            "loss: 2.0546975135803223 acc: 0.21875\n",
            "loss: 1.9415403604507446 acc: 0.265625\n",
            "loss: 2.1013662815093994 acc: 0.046875\n",
            "loss: 1.99946928024292 acc: 0.21875\n",
            "loss: 1.977059245109558 acc: 0.203125\n",
            "loss: 1.9945138692855835 acc: 0.1875\n",
            "loss: 2.0403809547424316 acc: 0.15625\n",
            "loss: 1.9595493078231812 acc: 0.25\n",
            "loss: 2.038465976715088 acc: 0.203125\n",
            "loss: 2.002577781677246 acc: 0.28125\n",
            "loss: 2.01339054107666 acc: 0.203125\n",
            "loss: 2.03983211517334 acc: 0.125\n",
            "loss: 2.0032858848571777 acc: 0.234375\n",
            "loss: 2.0788512229919434 acc: 0.109375\n",
            "loss: 2.0316202640533447 acc: 0.140625\n",
            "loss: 1.990748405456543 acc: 0.203125\n",
            "loss: 1.9656407833099365 acc: 0.171875\n",
            "loss: 2.002356767654419 acc: 0.203125\n",
            "loss: 2.014702558517456 acc: 0.125\n",
            "loss: 2.0236148834228516 acc: 0.140625\n",
            "loss: 1.9690595865249634 acc: 0.109375\n",
            "loss: 2.0064127445220947 acc: 0.171875\n",
            "loss: 1.9810409545898438 acc: 0.21875\n",
            "loss: 2.0786800384521484 acc: 0.15625\n",
            "loss: 2.008258819580078 acc: 0.171875\n",
            "loss: 2.0218727588653564 acc: 0.15625\n",
            "loss: 1.9613511562347412 acc: 0.15625\n",
            "loss: 2.0924160480499268 acc: 0.15625\n",
            "loss: 1.9728130102157593 acc: 0.21875\n",
            "loss: 2.0174691677093506 acc: 0.203125\n",
            "loss: 2.031292200088501 acc: 0.171875\n",
            "loss: 2.009784698486328 acc: 0.1875\n",
            "loss: 2.0049405097961426 acc: 0.1875\n",
            "loss: 2.006479501724243 acc: 0.140625\n",
            "loss: 2.1093201637268066 acc: 0.140625\n",
            "loss: 2.06489896774292 acc: 0.15625\n",
            "loss: 1.9410598278045654 acc: 0.21875\n",
            "loss: 2.0450618267059326 acc: 0.109375\n",
            "loss: 2.0027525424957275 acc: 0.265625\n",
            "loss: 2.071197271347046 acc: 0.125\n",
            "loss: 2.0389859676361084 acc: 0.140625\n",
            "loss: 1.9632022380828857 acc: 0.265625\n",
            "loss: 2.016791820526123 acc: 0.1875\n",
            "loss: 2.019818067550659 acc: 0.234375\n",
            "loss: 2.078944444656372 acc: 0.15625\n",
            "loss: 2.0378775596618652 acc: 0.234375\n",
            "loss: 2.122377872467041 acc: 0.1875\n",
            "loss: 2.088390350341797 acc: 0.15625\n",
            "loss: 2.0451865196228027 acc: 0.140625\n",
            "loss: 1.9793022871017456 acc: 0.25\n",
            "loss: 2.077233076095581 acc: 0.109375\n",
            "loss: 2.0203065872192383 acc: 0.234375\n",
            "loss: 2.0181801319122314 acc: 0.25\n",
            "loss: 1.9931821823120117 acc: 0.234375\n",
            "loss: 1.9741898775100708 acc: 0.234375\n",
            "loss: 2.0419225692749023 acc: 0.1875\n",
            "loss: 2.015916585922241 acc: 0.296875\n",
            "loss: 2.0268750190734863 acc: 0.234375\n",
            "loss: 2.0979268550872803 acc: 0.09375\n",
            "loss: 1.9821851253509521 acc: 0.171875\n",
            "loss: 2.052255868911743 acc: 0.203125\n",
            "loss: 2.0329294204711914 acc: 0.15625\n",
            "loss: 2.047475814819336 acc: 0.15625\n",
            "loss: 2.077364683151245 acc: 0.15625\n",
            "loss: 2.041144371032715 acc: 0.140625\n",
            "loss: 2.0435128211975098 acc: 0.109375\n",
            "loss: 2.0512070655822754 acc: 0.203125\n",
            "loss: 2.074995994567871 acc: 0.09375\n",
            "loss: 2.0342612266540527 acc: 0.1875\n",
            "loss: 2.050957202911377 acc: 0.171875\n",
            "loss: 1.990035057067871 acc: 0.140625\n",
            "loss: 2.071817636489868 acc: 0.15625\n",
            "loss: 2.0432798862457275 acc: 0.203125\n",
            "loss: 2.004490852355957 acc: 0.25\n",
            "loss: 2.0272350311279297 acc: 0.15625\n",
            "loss: 2.023577928543091 acc: 0.1875\n",
            "loss: 2.0448460578918457 acc: 0.1875\n",
            "loss: 2.0119447708129883 acc: 0.171875\n",
            "loss: 2.0940561294555664 acc: 0.171875\n",
            "loss: 2.0423226356506348 acc: 0.171875\n",
            "loss: 2.0747768878936768 acc: 0.140625\n",
            "loss: 2.0687689781188965 acc: 0.171875\n",
            "loss: 2.0423545837402344 acc: 0.09375\n",
            "loss: 2.0483903884887695 acc: 0.1875\n",
            "loss: 2.0668294429779053 acc: 0.234375\n",
            "loss: 1.9727957248687744 acc: 0.203125\n",
            "loss: 1.9820754528045654 acc: 0.203125\n",
            "loss: 2.044373035430908 acc: 0.203125\n",
            "loss: 2.0986883640289307 acc: 0.140625\n",
            "loss: 2.017875909805298 acc: 0.21875\n",
            "loss: 2.0480616092681885 acc: 0.171875\n",
            "loss: 2.0129270553588867 acc: 0.109375\n",
            "loss: 1.9879422187805176 acc: 0.25\n",
            "loss: 2.0197625160217285 acc: 0.21875\n",
            "loss: 2.0196454524993896 acc: 0.125\n",
            "loss: 1.9920613765716553 acc: 0.25\n",
            "loss: 1.9670859575271606 acc: 0.23255813121795654\n",
            "77 epoch:\n",
            "loss: 1.9674686193466187 acc: 0.171875\n",
            "loss: 1.9809327125549316 acc: 0.265625\n",
            "loss: 2.056710720062256 acc: 0.09375\n",
            "loss: 2.010188341140747 acc: 0.09375\n",
            "loss: 2.0679008960723877 acc: 0.171875\n",
            "loss: 2.0564935207366943 acc: 0.125\n",
            "loss: 2.0303409099578857 acc: 0.1875\n",
            "loss: 1.977173924446106 acc: 0.234375\n",
            "loss: 1.9878299236297607 acc: 0.15625\n",
            "loss: 1.9883090257644653 acc: 0.15625\n",
            "loss: 1.9961808919906616 acc: 0.25\n",
            "loss: 2.0983614921569824 acc: 0.09375\n",
            "loss: 1.984270691871643 acc: 0.28125\n",
            "loss: 2.0375850200653076 acc: 0.140625\n",
            "loss: 2.0521373748779297 acc: 0.1875\n",
            "loss: 2.055283308029175 acc: 0.15625\n",
            "loss: 2.1095781326293945 acc: 0.078125\n",
            "loss: 1.985672116279602 acc: 0.171875\n",
            "loss: 2.1059041023254395 acc: 0.140625\n",
            "loss: 2.033902406692505 acc: 0.265625\n",
            "loss: 2.0337421894073486 acc: 0.171875\n",
            "loss: 2.0133023262023926 acc: 0.1875\n",
            "loss: 2.058560848236084 acc: 0.171875\n",
            "loss: 2.0412988662719727 acc: 0.140625\n",
            "loss: 1.9729386568069458 acc: 0.234375\n",
            "loss: 2.0049479007720947 acc: 0.21875\n",
            "loss: 1.9740921258926392 acc: 0.296875\n",
            "loss: 1.981452465057373 acc: 0.15625\n",
            "loss: 2.1093714237213135 acc: 0.09375\n",
            "loss: 2.0185866355895996 acc: 0.21875\n",
            "loss: 2.0096359252929688 acc: 0.15625\n",
            "loss: 1.9465913772583008 acc: 0.328125\n",
            "loss: 2.0417098999023438 acc: 0.15625\n",
            "loss: 2.06616473197937 acc: 0.140625\n",
            "loss: 2.03428316116333 acc: 0.125\n",
            "loss: 2.045952081680298 acc: 0.109375\n",
            "loss: 1.9846333265304565 acc: 0.1875\n",
            "loss: 2.02115535736084 acc: 0.25\n",
            "loss: 1.990984320640564 acc: 0.203125\n",
            "loss: 2.049715042114258 acc: 0.140625\n",
            "loss: 2.0288238525390625 acc: 0.1875\n",
            "loss: 1.9845553636550903 acc: 0.203125\n",
            "loss: 1.9854421615600586 acc: 0.203125\n",
            "loss: 1.9981671571731567 acc: 0.21875\n",
            "loss: 2.03580379486084 acc: 0.21875\n",
            "loss: 2.049347162246704 acc: 0.1875\n",
            "loss: 2.041077136993408 acc: 0.15625\n",
            "loss: 2.0013427734375 acc: 0.25\n",
            "loss: 2.03719425201416 acc: 0.25\n",
            "loss: 2.0569159984588623 acc: 0.109375\n",
            "loss: 1.9793123006820679 acc: 0.25\n",
            "loss: 2.057892322540283 acc: 0.125\n",
            "loss: 1.9887291193008423 acc: 0.28125\n",
            "loss: 2.0458734035491943 acc: 0.203125\n",
            "loss: 2.023933172225952 acc: 0.171875\n",
            "loss: 2.0247628688812256 acc: 0.171875\n",
            "loss: 2.0590920448303223 acc: 0.203125\n",
            "loss: 2.023101329803467 acc: 0.171875\n",
            "loss: 2.009504556655884 acc: 0.203125\n",
            "loss: 2.1062397956848145 acc: 0.15625\n",
            "loss: 1.9952330589294434 acc: 0.21875\n",
            "loss: 2.0267233848571777 acc: 0.15625\n",
            "loss: 1.9989138841629028 acc: 0.25\n",
            "loss: 2.0168702602386475 acc: 0.234375\n",
            "loss: 1.9959099292755127 acc: 0.21875\n",
            "loss: 2.091641902923584 acc: 0.15625\n",
            "loss: 2.030787229537964 acc: 0.15625\n",
            "loss: 2.081001043319702 acc: 0.171875\n",
            "loss: 2.0323731899261475 acc: 0.171875\n",
            "loss: 2.0311710834503174 acc: 0.171875\n",
            "loss: 1.995080590248108 acc: 0.203125\n",
            "loss: 2.016997814178467 acc: 0.171875\n",
            "loss: 2.047755002975464 acc: 0.15625\n",
            "loss: 2.009916305541992 acc: 0.171875\n",
            "loss: 1.9739258289337158 acc: 0.171875\n",
            "loss: 2.024369478225708 acc: 0.1875\n",
            "loss: 2.015573740005493 acc: 0.234375\n",
            "loss: 2.0424611568450928 acc: 0.140625\n",
            "loss: 1.970133662223816 acc: 0.3125\n",
            "loss: 2.064539670944214 acc: 0.140625\n",
            "loss: 1.9735747575759888 acc: 0.1875\n",
            "loss: 2.0605404376983643 acc: 0.21875\n",
            "loss: 2.050462007522583 acc: 0.171875\n",
            "loss: 2.026418685913086 acc: 0.1875\n",
            "loss: 2.0143094062805176 acc: 0.25\n",
            "loss: 2.01951265335083 acc: 0.265625\n",
            "loss: 1.9835896492004395 acc: 0.21875\n",
            "loss: 2.00188946723938 acc: 0.203125\n",
            "loss: 2.0300655364990234 acc: 0.203125\n",
            "loss: 1.951034426689148 acc: 0.1875\n",
            "loss: 2.0652353763580322 acc: 0.15625\n",
            "loss: 2.0738754272460938 acc: 0.078125\n",
            "loss: 2.023972988128662 acc: 0.140625\n",
            "loss: 1.9997797012329102 acc: 0.265625\n",
            "loss: 1.9831007719039917 acc: 0.203125\n",
            "loss: 1.978111743927002 acc: 0.125\n",
            "loss: 1.9775468111038208 acc: 0.203125\n",
            "loss: 2.0936806201934814 acc: 0.15625\n",
            "loss: 2.041221857070923 acc: 0.140625\n",
            "loss: 2.0195419788360596 acc: 0.109375\n",
            "loss: 2.0054430961608887 acc: 0.21875\n",
            "loss: 2.0234460830688477 acc: 0.171875\n",
            "loss: 2.1174988746643066 acc: 0.0625\n",
            "loss: 2.076259136199951 acc: 0.15625\n",
            "loss: 2.011796712875366 acc: 0.15625\n",
            "loss: 2.01111102104187 acc: 0.140625\n",
            "loss: 1.984176754951477 acc: 0.234375\n",
            "loss: 1.9965078830718994 acc: 0.140625\n",
            "loss: 2.1018803119659424 acc: 0.15625\n",
            "loss: 2.0533432960510254 acc: 0.20930232107639313\n",
            "78 epoch:\n",
            "loss: 2.012751340866089 acc: 0.171875\n",
            "loss: 1.993659496307373 acc: 0.234375\n",
            "loss: 2.0819926261901855 acc: 0.15625\n",
            "loss: 2.0123960971832275 acc: 0.203125\n",
            "loss: 2.0093765258789062 acc: 0.21875\n",
            "loss: 2.0649452209472656 acc: 0.140625\n",
            "loss: 1.9851754903793335 acc: 0.21875\n",
            "loss: 1.952040672302246 acc: 0.265625\n",
            "loss: 1.9986021518707275 acc: 0.09375\n",
            "loss: 2.0369412899017334 acc: 0.1875\n",
            "loss: 1.9671660661697388 acc: 0.25\n",
            "loss: 1.9887888431549072 acc: 0.171875\n",
            "loss: 2.0832483768463135 acc: 0.140625\n",
            "loss: 2.0148844718933105 acc: 0.203125\n",
            "loss: 2.0423147678375244 acc: 0.078125\n",
            "loss: 2.018946409225464 acc: 0.140625\n",
            "loss: 1.9707279205322266 acc: 0.203125\n",
            "loss: 2.0147907733917236 acc: 0.1875\n",
            "loss: 2.003727912902832 acc: 0.21875\n",
            "loss: 2.0230679512023926 acc: 0.171875\n",
            "loss: 1.9834017753601074 acc: 0.1875\n",
            "loss: 2.0327937602996826 acc: 0.15625\n",
            "loss: 2.0512924194335938 acc: 0.203125\n",
            "loss: 1.964701533317566 acc: 0.1875\n",
            "loss: 2.0118470191955566 acc: 0.3125\n",
            "loss: 2.0188941955566406 acc: 0.171875\n",
            "loss: 1.9298956394195557 acc: 0.296875\n",
            "loss: 2.011091470718384 acc: 0.140625\n",
            "loss: 2.0453732013702393 acc: 0.140625\n",
            "loss: 2.036031484603882 acc: 0.140625\n",
            "loss: 2.0688133239746094 acc: 0.109375\n",
            "loss: 2.0325710773468018 acc: 0.140625\n",
            "loss: 2.069517135620117 acc: 0.21875\n",
            "loss: 2.0185158252716064 acc: 0.203125\n",
            "loss: 2.0400376319885254 acc: 0.21875\n",
            "loss: 2.0705907344818115 acc: 0.203125\n",
            "loss: 1.958771824836731 acc: 0.203125\n",
            "loss: 2.0060527324676514 acc: 0.125\n",
            "loss: 2.0593814849853516 acc: 0.203125\n",
            "loss: 1.9707914590835571 acc: 0.21875\n",
            "loss: 1.9920852184295654 acc: 0.25\n",
            "loss: 2.0420501232147217 acc: 0.21875\n",
            "loss: 2.00630784034729 acc: 0.21875\n",
            "loss: 1.9770872592926025 acc: 0.296875\n",
            "loss: 1.9731616973876953 acc: 0.25\n",
            "loss: 1.9740594625473022 acc: 0.21875\n",
            "loss: 2.0347421169281006 acc: 0.1875\n",
            "loss: 1.9368531703948975 acc: 0.203125\n",
            "loss: 2.0068557262420654 acc: 0.15625\n",
            "loss: 2.1058261394500732 acc: 0.09375\n",
            "loss: 2.003185510635376 acc: 0.265625\n",
            "loss: 2.104410171508789 acc: 0.09375\n",
            "loss: 2.0908923149108887 acc: 0.15625\n",
            "loss: 2.0638067722320557 acc: 0.140625\n",
            "loss: 2.023306131362915 acc: 0.1875\n",
            "loss: 2.027684211730957 acc: 0.171875\n",
            "loss: 2.071146011352539 acc: 0.140625\n",
            "loss: 1.9797347784042358 acc: 0.234375\n",
            "loss: 2.0434865951538086 acc: 0.234375\n",
            "loss: 2.034606456756592 acc: 0.1875\n",
            "loss: 2.1009957790374756 acc: 0.0625\n",
            "loss: 2.034452199935913 acc: 0.109375\n",
            "loss: 2.0854928493499756 acc: 0.125\n",
            "loss: 1.9692580699920654 acc: 0.125\n",
            "loss: 2.0866341590881348 acc: 0.109375\n",
            "loss: 2.0119619369506836 acc: 0.21875\n",
            "loss: 1.9958624839782715 acc: 0.171875\n",
            "loss: 1.9769971370697021 acc: 0.15625\n",
            "loss: 1.9902883768081665 acc: 0.234375\n",
            "loss: 2.06600022315979 acc: 0.203125\n",
            "loss: 2.1178557872772217 acc: 0.125\n",
            "loss: 1.9570317268371582 acc: 0.203125\n",
            "loss: 2.010233163833618 acc: 0.125\n",
            "loss: 2.0534329414367676 acc: 0.140625\n",
            "loss: 1.942463755607605 acc: 0.28125\n",
            "loss: 2.0751023292541504 acc: 0.234375\n",
            "loss: 1.9602159261703491 acc: 0.296875\n",
            "loss: 2.0580291748046875 acc: 0.1875\n",
            "loss: 1.9842989444732666 acc: 0.15625\n",
            "loss: 2.069279432296753 acc: 0.171875\n",
            "loss: 2.0041677951812744 acc: 0.203125\n",
            "loss: 1.9662307500839233 acc: 0.25\n",
            "loss: 2.016772747039795 acc: 0.171875\n",
            "loss: 2.0057404041290283 acc: 0.203125\n",
            "loss: 1.9985791444778442 acc: 0.234375\n",
            "loss: 2.09851336479187 acc: 0.109375\n",
            "loss: 1.9930745363235474 acc: 0.21875\n",
            "loss: 2.067932367324829 acc: 0.109375\n",
            "loss: 2.0451300144195557 acc: 0.125\n",
            "loss: 2.002337694168091 acc: 0.203125\n",
            "loss: 2.0570623874664307 acc: 0.125\n",
            "loss: 2.0337603092193604 acc: 0.09375\n",
            "loss: 2.035832405090332 acc: 0.15625\n",
            "loss: 1.952954888343811 acc: 0.296875\n",
            "loss: 2.053617477416992 acc: 0.171875\n",
            "loss: 2.00557541847229 acc: 0.203125\n",
            "loss: 2.0306897163391113 acc: 0.109375\n",
            "loss: 2.059741497039795 acc: 0.09375\n",
            "loss: 1.9884124994277954 acc: 0.125\n",
            "loss: 2.0130887031555176 acc: 0.21875\n",
            "loss: 1.9881311655044556 acc: 0.21875\n",
            "loss: 1.9790536165237427 acc: 0.203125\n",
            "loss: 2.011096954345703 acc: 0.234375\n",
            "loss: 2.026829719543457 acc: 0.1875\n",
            "loss: 2.02226185798645 acc: 0.203125\n",
            "loss: 1.9874836206436157 acc: 0.203125\n",
            "loss: 2.093984842300415 acc: 0.140625\n",
            "loss: 1.9855566024780273 acc: 0.265625\n",
            "loss: 1.9743396043777466 acc: 0.1875\n",
            "loss: 1.9765355587005615 acc: 0.11627906560897827\n",
            "79 epoch:\n",
            "loss: 2.0051543712615967 acc: 0.171875\n",
            "loss: 1.9401733875274658 acc: 0.28125\n",
            "loss: 1.9470447301864624 acc: 0.203125\n",
            "loss: 2.060100793838501 acc: 0.140625\n",
            "loss: 1.9598474502563477 acc: 0.234375\n",
            "loss: 1.9975486993789673 acc: 0.25\n",
            "loss: 1.9743530750274658 acc: 0.25\n",
            "loss: 1.9666855335235596 acc: 0.203125\n",
            "loss: 1.9788484573364258 acc: 0.234375\n",
            "loss: 1.966531753540039 acc: 0.1875\n",
            "loss: 1.9662396907806396 acc: 0.25\n",
            "loss: 2.007979154586792 acc: 0.265625\n",
            "loss: 2.011059045791626 acc: 0.21875\n",
            "loss: 1.997077226638794 acc: 0.15625\n",
            "loss: 2.05972957611084 acc: 0.15625\n",
            "loss: 2.060584783554077 acc: 0.15625\n",
            "loss: 1.9738621711730957 acc: 0.296875\n",
            "loss: 1.9637597799301147 acc: 0.15625\n",
            "loss: 2.0705230236053467 acc: 0.140625\n",
            "loss: 2.0130677223205566 acc: 0.15625\n",
            "loss: 2.141744375228882 acc: 0.203125\n",
            "loss: 2.029930353164673 acc: 0.1875\n",
            "loss: 1.9993031024932861 acc: 0.203125\n",
            "loss: 2.077132225036621 acc: 0.203125\n",
            "loss: 1.989816665649414 acc: 0.125\n",
            "loss: 2.0376710891723633 acc: 0.1875\n",
            "loss: 2.088444232940674 acc: 0.140625\n",
            "loss: 1.9740915298461914 acc: 0.234375\n",
            "loss: 2.006682872772217 acc: 0.1875\n",
            "loss: 2.062547206878662 acc: 0.125\n",
            "loss: 1.9841086864471436 acc: 0.265625\n",
            "loss: 1.9844727516174316 acc: 0.28125\n",
            "loss: 2.019449472427368 acc: 0.203125\n",
            "loss: 1.9755653142929077 acc: 0.265625\n",
            "loss: 2.124879837036133 acc: 0.15625\n",
            "loss: 2.020062208175659 acc: 0.1875\n",
            "loss: 2.051321268081665 acc: 0.125\n",
            "loss: 2.020188331604004 acc: 0.1875\n",
            "loss: 1.9844578504562378 acc: 0.15625\n",
            "loss: 1.98662269115448 acc: 0.15625\n",
            "loss: 1.9731526374816895 acc: 0.1875\n",
            "loss: 2.0572638511657715 acc: 0.09375\n",
            "loss: 1.9476003646850586 acc: 0.1875\n",
            "loss: 1.9523658752441406 acc: 0.265625\n",
            "loss: 2.0047876834869385 acc: 0.171875\n",
            "loss: 2.0613973140716553 acc: 0.140625\n",
            "loss: 2.053687572479248 acc: 0.140625\n",
            "loss: 1.9125691652297974 acc: 0.203125\n",
            "loss: 2.018230676651001 acc: 0.21875\n",
            "loss: 2.002652645111084 acc: 0.203125\n",
            "loss: 2.0249452590942383 acc: 0.15625\n",
            "loss: 2.0258331298828125 acc: 0.234375\n",
            "loss: 2.040818691253662 acc: 0.125\n",
            "loss: 1.9926073551177979 acc: 0.21875\n",
            "loss: 2.0216360092163086 acc: 0.125\n",
            "loss: 1.9895089864730835 acc: 0.21875\n",
            "loss: 2.108980178833008 acc: 0.109375\n",
            "loss: 1.990161657333374 acc: 0.234375\n",
            "loss: 2.052152156829834 acc: 0.109375\n",
            "loss: 2.015212059020996 acc: 0.21875\n",
            "loss: 2.0578880310058594 acc: 0.1875\n",
            "loss: 2.083754777908325 acc: 0.109375\n",
            "loss: 1.9678336381912231 acc: 0.21875\n",
            "loss: 2.022479772567749 acc: 0.125\n",
            "loss: 1.9601787328720093 acc: 0.21875\n",
            "loss: 2.0412180423736572 acc: 0.15625\n",
            "loss: 2.010773181915283 acc: 0.25\n",
            "loss: 1.9913296699523926 acc: 0.3125\n",
            "loss: 2.060915946960449 acc: 0.21875\n",
            "loss: 1.9640830755233765 acc: 0.265625\n",
            "loss: 1.9738237857818604 acc: 0.234375\n",
            "loss: 2.046485185623169 acc: 0.25\n",
            "loss: 2.097764253616333 acc: 0.140625\n",
            "loss: 2.030383348464966 acc: 0.140625\n",
            "loss: 2.055530309677124 acc: 0.203125\n",
            "loss: 2.0513527393341064 acc: 0.140625\n",
            "loss: 1.9932881593704224 acc: 0.203125\n",
            "loss: 2.012777090072632 acc: 0.265625\n",
            "loss: 2.0301716327667236 acc: 0.078125\n",
            "loss: 2.0281901359558105 acc: 0.109375\n",
            "loss: 2.037921905517578 acc: 0.1875\n",
            "loss: 2.0555007457733154 acc: 0.15625\n",
            "loss: 1.9420359134674072 acc: 0.203125\n",
            "loss: 1.9569875001907349 acc: 0.171875\n",
            "loss: 2.009514331817627 acc: 0.21875\n",
            "loss: 2.0946128368377686 acc: 0.125\n",
            "loss: 2.0120790004730225 acc: 0.15625\n",
            "loss: 2.03381609916687 acc: 0.234375\n",
            "loss: 2.044062376022339 acc: 0.140625\n",
            "loss: 1.9329215288162231 acc: 0.328125\n",
            "loss: 1.9770166873931885 acc: 0.21875\n",
            "loss: 2.047391653060913 acc: 0.28125\n",
            "loss: 2.052330732345581 acc: 0.15625\n",
            "loss: 2.0168285369873047 acc: 0.21875\n",
            "loss: 2.028002977371216 acc: 0.15625\n",
            "loss: 2.0867984294891357 acc: 0.109375\n",
            "loss: 1.9581990242004395 acc: 0.234375\n",
            "loss: 1.9756109714508057 acc: 0.140625\n",
            "loss: 1.9943721294403076 acc: 0.25\n",
            "loss: 1.9840261936187744 acc: 0.234375\n",
            "loss: 2.05954647064209 acc: 0.15625\n",
            "loss: 2.0711841583251953 acc: 0.125\n",
            "loss: 2.0736544132232666 acc: 0.09375\n",
            "loss: 2.094693660736084 acc: 0.171875\n",
            "loss: 2.0229032039642334 acc: 0.1875\n",
            "loss: 1.9963691234588623 acc: 0.25\n",
            "loss: 2.0248234272003174 acc: 0.21875\n",
            "loss: 2.0284533500671387 acc: 0.140625\n",
            "loss: 2.0281522274017334 acc: 0.234375\n",
            "loss: 1.971652865409851 acc: 0.20930232107639313\n",
            "80 epoch:\n",
            "loss: 1.9667296409606934 acc: 0.1875\n",
            "loss: 1.9638394117355347 acc: 0.28125\n",
            "loss: 2.0549492835998535 acc: 0.171875\n",
            "loss: 1.9335851669311523 acc: 0.359375\n",
            "loss: 2.0087904930114746 acc: 0.3125\n",
            "loss: 2.0208816528320312 acc: 0.171875\n",
            "loss: 2.006758451461792 acc: 0.125\n",
            "loss: 2.0050814151763916 acc: 0.203125\n",
            "loss: 1.9417178630828857 acc: 0.234375\n",
            "loss: 1.9023168087005615 acc: 0.265625\n",
            "loss: 2.00227689743042 acc: 0.203125\n",
            "loss: 2.153176784515381 acc: 0.125\n",
            "loss: 1.993762731552124 acc: 0.203125\n",
            "loss: 1.997690200805664 acc: 0.203125\n",
            "loss: 2.0215516090393066 acc: 0.21875\n",
            "loss: 1.9740022420883179 acc: 0.21875\n",
            "loss: 2.030834674835205 acc: 0.109375\n",
            "loss: 1.9939333200454712 acc: 0.203125\n",
            "loss: 2.110661506652832 acc: 0.140625\n",
            "loss: 2.0341413021087646 acc: 0.234375\n",
            "loss: 2.0934033393859863 acc: 0.171875\n",
            "loss: 1.9515630006790161 acc: 0.25\n",
            "loss: 2.006143569946289 acc: 0.171875\n",
            "loss: 2.0840182304382324 acc: 0.203125\n",
            "loss: 1.9512397050857544 acc: 0.21875\n",
            "loss: 1.9639787673950195 acc: 0.203125\n",
            "loss: 1.9738168716430664 acc: 0.21875\n",
            "loss: 2.092787504196167 acc: 0.109375\n",
            "loss: 2.057861804962158 acc: 0.15625\n",
            "loss: 1.9795682430267334 acc: 0.21875\n",
            "loss: 1.9897221326828003 acc: 0.1875\n",
            "loss: 2.006258487701416 acc: 0.15625\n",
            "loss: 1.976394534111023 acc: 0.21875\n",
            "loss: 2.029201030731201 acc: 0.171875\n",
            "loss: 2.049773931503296 acc: 0.15625\n",
            "loss: 2.0132482051849365 acc: 0.15625\n",
            "loss: 2.0233850479125977 acc: 0.1875\n",
            "loss: 1.999910593032837 acc: 0.28125\n",
            "loss: 2.0210156440734863 acc: 0.078125\n",
            "loss: 1.9626659154891968 acc: 0.234375\n",
            "loss: 2.0549726486206055 acc: 0.1875\n",
            "loss: 2.0449745655059814 acc: 0.203125\n",
            "loss: 1.9788577556610107 acc: 0.203125\n",
            "loss: 1.9654226303100586 acc: 0.265625\n",
            "loss: 1.9376060962677002 acc: 0.28125\n",
            "loss: 2.0359559059143066 acc: 0.171875\n",
            "loss: 1.9846011400222778 acc: 0.21875\n",
            "loss: 1.9559539556503296 acc: 0.21875\n",
            "loss: 2.0251007080078125 acc: 0.265625\n",
            "loss: 2.0341298580169678 acc: 0.25\n",
            "loss: 2.066120147705078 acc: 0.140625\n",
            "loss: 2.014742851257324 acc: 0.21875\n",
            "loss: 1.9882616996765137 acc: 0.1875\n",
            "loss: 1.957556962966919 acc: 0.140625\n",
            "loss: 2.0064287185668945 acc: 0.203125\n",
            "loss: 1.9297606945037842 acc: 0.140625\n",
            "loss: 1.9544109106063843 acc: 0.1875\n",
            "loss: 2.0761983394622803 acc: 0.125\n",
            "loss: 1.9808071851730347 acc: 0.234375\n",
            "loss: 2.025686502456665 acc: 0.203125\n",
            "loss: 1.9867061376571655 acc: 0.171875\n",
            "loss: 2.0025711059570312 acc: 0.15625\n",
            "loss: 2.103027820587158 acc: 0.15625\n",
            "loss: 2.0901732444763184 acc: 0.15625\n",
            "loss: 2.067613124847412 acc: 0.171875\n",
            "loss: 1.9929022789001465 acc: 0.171875\n",
            "loss: 2.0816566944122314 acc: 0.140625\n",
            "loss: 2.0931432247161865 acc: 0.140625\n",
            "loss: 1.988145112991333 acc: 0.171875\n",
            "loss: 2.014848232269287 acc: 0.25\n",
            "loss: 2.063763380050659 acc: 0.171875\n",
            "loss: 2.0221362113952637 acc: 0.21875\n",
            "loss: 1.9612900018692017 acc: 0.28125\n",
            "loss: 1.9646503925323486 acc: 0.21875\n",
            "loss: 1.9795539379119873 acc: 0.1875\n",
            "loss: 1.9721156358718872 acc: 0.21875\n",
            "loss: 1.9872080087661743 acc: 0.265625\n",
            "loss: 2.004640817642212 acc: 0.21875\n",
            "loss: 1.9886152744293213 acc: 0.28125\n",
            "loss: 2.042970895767212 acc: 0.140625\n",
            "loss: 1.9922257661819458 acc: 0.15625\n",
            "loss: 2.0113272666931152 acc: 0.25\n",
            "loss: 1.9691598415374756 acc: 0.28125\n",
            "loss: 2.0158393383026123 acc: 0.109375\n",
            "loss: 1.9953895807266235 acc: 0.1875\n",
            "loss: 2.018869400024414 acc: 0.140625\n",
            "loss: 1.9800349473953247 acc: 0.140625\n",
            "loss: 1.9970277547836304 acc: 0.171875\n",
            "loss: 1.982818365097046 acc: 0.171875\n",
            "loss: 2.0037457942962646 acc: 0.25\n",
            "loss: 2.009490489959717 acc: 0.171875\n",
            "loss: 2.0485992431640625 acc: 0.171875\n",
            "loss: 2.010296583175659 acc: 0.1875\n",
            "loss: 1.991782307624817 acc: 0.25\n",
            "loss: 2.0821657180786133 acc: 0.125\n",
            "loss: 2.0028622150421143 acc: 0.234375\n",
            "loss: 1.9858578443527222 acc: 0.140625\n",
            "loss: 2.0500988960266113 acc: 0.140625\n",
            "loss: 2.0081241130828857 acc: 0.1875\n",
            "loss: 1.9283567667007446 acc: 0.28125\n",
            "loss: 2.104170799255371 acc: 0.171875\n",
            "loss: 2.050403594970703 acc: 0.171875\n",
            "loss: 2.0569334030151367 acc: 0.1875\n",
            "loss: 1.9868838787078857 acc: 0.203125\n",
            "loss: 2.0070104598999023 acc: 0.15625\n",
            "loss: 1.9356815814971924 acc: 0.234375\n",
            "loss: 2.0269932746887207 acc: 0.109375\n",
            "loss: 1.9635916948318481 acc: 0.15625\n",
            "loss: 2.0535666942596436 acc: 0.125\n",
            "loss: 2.116475820541382 acc: 0.06976744532585144\n",
            "81 epoch:\n",
            "loss: 1.9511690139770508 acc: 0.234375\n",
            "loss: 1.976739525794983 acc: 0.234375\n",
            "loss: 1.9835526943206787 acc: 0.171875\n",
            "loss: 2.0323121547698975 acc: 0.1875\n",
            "loss: 2.0311801433563232 acc: 0.15625\n",
            "loss: 1.9806733131408691 acc: 0.171875\n",
            "loss: 2.0140061378479004 acc: 0.140625\n",
            "loss: 2.072946786880493 acc: 0.25\n",
            "loss: 1.9627106189727783 acc: 0.15625\n",
            "loss: 2.0137288570404053 acc: 0.203125\n",
            "loss: 2.014146327972412 acc: 0.203125\n",
            "loss: 2.01912784576416 acc: 0.21875\n",
            "loss: 2.068572759628296 acc: 0.1875\n",
            "loss: 1.9861942529678345 acc: 0.203125\n",
            "loss: 2.034038782119751 acc: 0.15625\n",
            "loss: 1.9148565530776978 acc: 0.25\n",
            "loss: 1.9819753170013428 acc: 0.109375\n",
            "loss: 1.984472632408142 acc: 0.15625\n",
            "loss: 2.012653350830078 acc: 0.109375\n",
            "loss: 2.0621776580810547 acc: 0.171875\n",
            "loss: 2.0720603466033936 acc: 0.078125\n",
            "loss: 2.0177087783813477 acc: 0.15625\n",
            "loss: 1.9785149097442627 acc: 0.3125\n",
            "loss: 1.9731215238571167 acc: 0.203125\n",
            "loss: 1.9607415199279785 acc: 0.25\n",
            "loss: 1.9204257726669312 acc: 0.1875\n",
            "loss: 2.014495849609375 acc: 0.125\n",
            "loss: 1.9951825141906738 acc: 0.21875\n",
            "loss: 2.0217771530151367 acc: 0.171875\n",
            "loss: 2.034393310546875 acc: 0.15625\n",
            "loss: 2.1147572994232178 acc: 0.171875\n",
            "loss: 1.9818626642227173 acc: 0.1875\n",
            "loss: 1.9865254163742065 acc: 0.28125\n",
            "loss: 2.025592803955078 acc: 0.21875\n",
            "loss: 2.057436466217041 acc: 0.171875\n",
            "loss: 1.9897297620773315 acc: 0.234375\n",
            "loss: 2.055729389190674 acc: 0.203125\n",
            "loss: 2.017836570739746 acc: 0.234375\n",
            "loss: 1.9295717477798462 acc: 0.3125\n",
            "loss: 1.9820088148117065 acc: 0.25\n",
            "loss: 1.9324955940246582 acc: 0.28125\n",
            "loss: 1.9739974737167358 acc: 0.1875\n",
            "loss: 2.0505590438842773 acc: 0.1875\n",
            "loss: 2.0110790729522705 acc: 0.25\n",
            "loss: 2.008284568786621 acc: 0.15625\n",
            "loss: 1.9743432998657227 acc: 0.203125\n",
            "loss: 1.9494473934173584 acc: 0.1875\n",
            "loss: 2.0128018856048584 acc: 0.125\n",
            "loss: 2.04667592048645 acc: 0.109375\n",
            "loss: 1.9879469871520996 acc: 0.1875\n",
            "loss: 2.081730842590332 acc: 0.140625\n",
            "loss: 1.9160252809524536 acc: 0.25\n",
            "loss: 1.917145848274231 acc: 0.1875\n",
            "loss: 1.9030017852783203 acc: 0.234375\n",
            "loss: 2.0362579822540283 acc: 0.234375\n",
            "loss: 2.0432915687561035 acc: 0.234375\n",
            "loss: 2.049562931060791 acc: 0.15625\n",
            "loss: 1.9456928968429565 acc: 0.234375\n",
            "loss: 2.0453832149505615 acc: 0.234375\n",
            "loss: 2.041781187057495 acc: 0.1875\n",
            "loss: 2.0038235187530518 acc: 0.140625\n",
            "loss: 2.0155701637268066 acc: 0.125\n",
            "loss: 1.9194551706314087 acc: 0.1875\n",
            "loss: 2.0442986488342285 acc: 0.140625\n",
            "loss: 1.9288781881332397 acc: 0.1875\n",
            "loss: 2.012291193008423 acc: 0.28125\n",
            "loss: 2.012197732925415 acc: 0.21875\n",
            "loss: 2.001586437225342 acc: 0.21875\n",
            "loss: 1.9641751050949097 acc: 0.234375\n",
            "loss: 2.039196014404297 acc: 0.15625\n",
            "loss: 2.028697967529297 acc: 0.21875\n",
            "loss: 2.034059762954712 acc: 0.171875\n",
            "loss: 1.9686063528060913 acc: 0.28125\n",
            "loss: 1.9445111751556396 acc: 0.21875\n",
            "loss: 1.9568003416061401 acc: 0.171875\n",
            "loss: 2.075791120529175 acc: 0.21875\n",
            "loss: 2.074084520339966 acc: 0.1875\n",
            "loss: 2.057630777359009 acc: 0.140625\n",
            "loss: 2.0961005687713623 acc: 0.15625\n",
            "loss: 2.0375170707702637 acc: 0.140625\n",
            "loss: 2.016918897628784 acc: 0.21875\n",
            "loss: 1.9700193405151367 acc: 0.265625\n",
            "loss: 1.9871504306793213 acc: 0.21875\n",
            "loss: 2.0750892162323 acc: 0.109375\n",
            "loss: 2.0402238368988037 acc: 0.1875\n",
            "loss: 2.0297703742980957 acc: 0.234375\n",
            "loss: 1.9933199882507324 acc: 0.21875\n",
            "loss: 2.079698085784912 acc: 0.1875\n",
            "loss: 2.0088112354278564 acc: 0.25\n",
            "loss: 2.0376574993133545 acc: 0.125\n",
            "loss: 2.0351686477661133 acc: 0.203125\n",
            "loss: 2.06984806060791 acc: 0.125\n",
            "loss: 1.9792580604553223 acc: 0.265625\n",
            "loss: 1.9869413375854492 acc: 0.234375\n",
            "loss: 1.9868521690368652 acc: 0.140625\n",
            "loss: 2.0276920795440674 acc: 0.140625\n",
            "loss: 2.0051674842834473 acc: 0.140625\n",
            "loss: 2.0419931411743164 acc: 0.125\n",
            "loss: 1.971426010131836 acc: 0.1875\n",
            "loss: 1.9742776155471802 acc: 0.203125\n",
            "loss: 2.0769033432006836 acc: 0.140625\n",
            "loss: 2.0772736072540283 acc: 0.0625\n",
            "loss: 2.065906524658203 acc: 0.15625\n",
            "loss: 2.021094799041748 acc: 0.171875\n",
            "loss: 1.9944008588790894 acc: 0.28125\n",
            "loss: 2.0264031887054443 acc: 0.21875\n",
            "loss: 1.9610973596572876 acc: 0.21875\n",
            "loss: 2.0398800373077393 acc: 0.125\n",
            "loss: 1.9610837697982788 acc: 0.203125\n",
            "loss: 1.9065821170806885 acc: 0.23255813121795654\n",
            "82 epoch:\n",
            "loss: 2.0199661254882812 acc: 0.203125\n",
            "loss: 1.9858206510543823 acc: 0.203125\n",
            "loss: 1.8987528085708618 acc: 0.234375\n",
            "loss: 1.924157738685608 acc: 0.3125\n",
            "loss: 2.040147304534912 acc: 0.15625\n",
            "loss: 2.053205966949463 acc: 0.1875\n",
            "loss: 1.9434300661087036 acc: 0.265625\n",
            "loss: 1.946104645729065 acc: 0.203125\n",
            "loss: 1.9894769191741943 acc: 0.109375\n",
            "loss: 2.024536371231079 acc: 0.1875\n",
            "loss: 2.0149919986724854 acc: 0.171875\n",
            "loss: 1.9747575521469116 acc: 0.1875\n",
            "loss: 2.031919002532959 acc: 0.203125\n",
            "loss: 2.0505564212799072 acc: 0.1875\n",
            "loss: 2.002854347229004 acc: 0.140625\n",
            "loss: 2.009793519973755 acc: 0.234375\n",
            "loss: 1.9887381792068481 acc: 0.171875\n",
            "loss: 2.001835823059082 acc: 0.15625\n",
            "loss: 2.018372058868408 acc: 0.171875\n",
            "loss: 2.026719093322754 acc: 0.203125\n",
            "loss: 1.9731100797653198 acc: 0.203125\n",
            "loss: 1.928663969039917 acc: 0.28125\n",
            "loss: 2.0286507606506348 acc: 0.21875\n",
            "loss: 2.0129261016845703 acc: 0.21875\n",
            "loss: 1.9194068908691406 acc: 0.203125\n",
            "loss: 1.9842811822891235 acc: 0.21875\n",
            "loss: 1.9429757595062256 acc: 0.296875\n",
            "loss: 1.975677490234375 acc: 0.28125\n",
            "loss: 2.0035111904144287 acc: 0.140625\n",
            "loss: 2.053030490875244 acc: 0.15625\n",
            "loss: 2.0184929370880127 acc: 0.203125\n",
            "loss: 2.0177974700927734 acc: 0.203125\n",
            "loss: 2.000340223312378 acc: 0.140625\n",
            "loss: 1.9775887727737427 acc: 0.21875\n",
            "loss: 1.9971226453781128 acc: 0.203125\n",
            "loss: 2.053032159805298 acc: 0.140625\n",
            "loss: 1.9329969882965088 acc: 0.296875\n",
            "loss: 1.9119576215744019 acc: 0.28125\n",
            "loss: 2.0231943130493164 acc: 0.1875\n",
            "loss: 1.9885960817337036 acc: 0.15625\n",
            "loss: 2.0558948516845703 acc: 0.140625\n",
            "loss: 2.0402615070343018 acc: 0.203125\n",
            "loss: 2.0095925331115723 acc: 0.234375\n",
            "loss: 2.0640370845794678 acc: 0.203125\n",
            "loss: 1.8917999267578125 acc: 0.25\n",
            "loss: 2.000516414642334 acc: 0.21875\n",
            "loss: 2.04585862159729 acc: 0.125\n",
            "loss: 2.1604573726654053 acc: 0.125\n",
            "loss: 2.046088695526123 acc: 0.140625\n",
            "loss: 1.9737229347229004 acc: 0.171875\n",
            "loss: 2.0144202709198 acc: 0.21875\n",
            "loss: 2.0777668952941895 acc: 0.140625\n",
            "loss: 1.966203212738037 acc: 0.203125\n",
            "loss: 1.9729180335998535 acc: 0.140625\n",
            "loss: 2.069964647293091 acc: 0.171875\n",
            "loss: 1.9626575708389282 acc: 0.171875\n",
            "loss: 1.9627574682235718 acc: 0.140625\n",
            "loss: 2.0331339836120605 acc: 0.21875\n",
            "loss: 2.0266146659851074 acc: 0.171875\n",
            "loss: 1.9668920040130615 acc: 0.21875\n",
            "loss: 1.9732099771499634 acc: 0.28125\n",
            "loss: 1.9434195756912231 acc: 0.1875\n",
            "loss: 1.9651272296905518 acc: 0.25\n",
            "loss: 2.0500810146331787 acc: 0.140625\n",
            "loss: 1.9672033786773682 acc: 0.21875\n",
            "loss: 1.944003939628601 acc: 0.25\n",
            "loss: 2.069230556488037 acc: 0.1875\n",
            "loss: 1.9600908756256104 acc: 0.234375\n",
            "loss: 2.039907455444336 acc: 0.109375\n",
            "loss: 1.988892674446106 acc: 0.15625\n",
            "loss: 2.080711603164673 acc: 0.109375\n",
            "loss: 2.036376476287842 acc: 0.15625\n",
            "loss: 1.9971446990966797 acc: 0.1875\n",
            "loss: 2.017791509628296 acc: 0.109375\n",
            "loss: 1.9747710227966309 acc: 0.21875\n",
            "loss: 2.0019185543060303 acc: 0.140625\n",
            "loss: 1.9866706132888794 acc: 0.265625\n",
            "loss: 2.037519693374634 acc: 0.140625\n",
            "loss: 1.9997248649597168 acc: 0.21875\n",
            "loss: 2.0093743801116943 acc: 0.15625\n",
            "loss: 2.0205466747283936 acc: 0.203125\n",
            "loss: 1.9939961433410645 acc: 0.234375\n",
            "loss: 1.954223394393921 acc: 0.296875\n",
            "loss: 1.9922590255737305 acc: 0.234375\n",
            "loss: 2.0213494300842285 acc: 0.1875\n",
            "loss: 1.996408224105835 acc: 0.203125\n",
            "loss: 2.0544373989105225 acc: 0.234375\n",
            "loss: 1.9706803560256958 acc: 0.203125\n",
            "loss: 2.106510639190674 acc: 0.109375\n",
            "loss: 1.9312808513641357 acc: 0.28125\n",
            "loss: 1.9503601789474487 acc: 0.21875\n",
            "loss: 2.0787625312805176 acc: 0.203125\n",
            "loss: 1.9765243530273438 acc: 0.140625\n",
            "loss: 2.122239351272583 acc: 0.125\n",
            "loss: 2.088277816772461 acc: 0.140625\n",
            "loss: 1.9607771635055542 acc: 0.28125\n",
            "loss: 2.023846387863159 acc: 0.171875\n",
            "loss: 2.0471549034118652 acc: 0.171875\n",
            "loss: 1.9542888402938843 acc: 0.25\n",
            "loss: 2.00295090675354 acc: 0.203125\n",
            "loss: 2.102646589279175 acc: 0.15625\n",
            "loss: 2.05910587310791 acc: 0.109375\n",
            "loss: 1.9750624895095825 acc: 0.21875\n",
            "loss: 2.0244650840759277 acc: 0.21875\n",
            "loss: 1.9818785190582275 acc: 0.125\n",
            "loss: 1.9900025129318237 acc: 0.15625\n",
            "loss: 1.990436315536499 acc: 0.21875\n",
            "loss: 1.9642101526260376 acc: 0.15625\n",
            "loss: 2.03261137008667 acc: 0.171875\n",
            "loss: 2.0093021392822266 acc: 0.1860465109348297\n",
            "83 epoch:\n",
            "loss: 2.0035226345062256 acc: 0.21875\n",
            "loss: 1.9597851037979126 acc: 0.234375\n",
            "loss: 1.9336556196212769 acc: 0.21875\n",
            "loss: 2.009147882461548 acc: 0.234375\n",
            "loss: 1.9206544160842896 acc: 0.28125\n",
            "loss: 2.047950029373169 acc: 0.171875\n",
            "loss: 1.9895312786102295 acc: 0.15625\n",
            "loss: 1.9570823907852173 acc: 0.140625\n",
            "loss: 1.9775313138961792 acc: 0.265625\n",
            "loss: 2.0142807960510254 acc: 0.25\n",
            "loss: 2.0268542766571045 acc: 0.1875\n",
            "loss: 1.9883168935775757 acc: 0.21875\n",
            "loss: 2.0156590938568115 acc: 0.21875\n",
            "loss: 2.0640392303466797 acc: 0.109375\n",
            "loss: 1.92130708694458 acc: 0.21875\n",
            "loss: 2.0498855113983154 acc: 0.109375\n",
            "loss: 1.9759849309921265 acc: 0.203125\n",
            "loss: 1.9341106414794922 acc: 0.203125\n",
            "loss: 1.9479954242706299 acc: 0.171875\n",
            "loss: 1.9967494010925293 acc: 0.15625\n",
            "loss: 1.9908316135406494 acc: 0.265625\n",
            "loss: 2.039422035217285 acc: 0.109375\n",
            "loss: 1.9296437501907349 acc: 0.25\n",
            "loss: 1.9842126369476318 acc: 0.21875\n",
            "loss: 2.0300955772399902 acc: 0.234375\n",
            "loss: 1.9840264320373535 acc: 0.28125\n",
            "loss: 2.061065196990967 acc: 0.203125\n",
            "loss: 2.023212432861328 acc: 0.1875\n",
            "loss: 2.0443716049194336 acc: 0.15625\n",
            "loss: 1.9644001722335815 acc: 0.28125\n",
            "loss: 2.089221715927124 acc: 0.15625\n",
            "loss: 2.0057835578918457 acc: 0.21875\n",
            "loss: 2.045963764190674 acc: 0.171875\n",
            "loss: 1.9314900636672974 acc: 0.1875\n",
            "loss: 1.9672945737838745 acc: 0.1875\n",
            "loss: 1.9806479215621948 acc: 0.25\n",
            "loss: 1.9422961473464966 acc: 0.21875\n",
            "loss: 2.0050160884857178 acc: 0.296875\n",
            "loss: 1.942352056503296 acc: 0.28125\n",
            "loss: 1.9928722381591797 acc: 0.21875\n",
            "loss: 1.9854453802108765 acc: 0.21875\n",
            "loss: 1.9917560815811157 acc: 0.125\n",
            "loss: 1.9797450304031372 acc: 0.21875\n",
            "loss: 1.9578344821929932 acc: 0.3125\n",
            "loss: 1.925054669380188 acc: 0.1875\n",
            "loss: 1.983639121055603 acc: 0.171875\n",
            "loss: 1.975617527961731 acc: 0.15625\n",
            "loss: 2.021995782852173 acc: 0.140625\n",
            "loss: 1.9887950420379639 acc: 0.234375\n",
            "loss: 1.9375346899032593 acc: 0.296875\n",
            "loss: 2.0358972549438477 acc: 0.171875\n",
            "loss: 1.973328709602356 acc: 0.203125\n",
            "loss: 1.9584909677505493 acc: 0.1875\n",
            "loss: 2.0201568603515625 acc: 0.203125\n",
            "loss: 1.8970003128051758 acc: 0.203125\n",
            "loss: 2.081658363342285 acc: 0.171875\n",
            "loss: 1.9701060056686401 acc: 0.328125\n",
            "loss: 2.017735004425049 acc: 0.171875\n",
            "loss: 1.96927011013031 acc: 0.21875\n",
            "loss: 2.0336930751800537 acc: 0.140625\n",
            "loss: 1.9801385402679443 acc: 0.1875\n",
            "loss: 2.039867401123047 acc: 0.15625\n",
            "loss: 1.977018117904663 acc: 0.21875\n",
            "loss: 1.9343074560165405 acc: 0.3125\n",
            "loss: 1.941935658454895 acc: 0.234375\n",
            "loss: 1.9401682615280151 acc: 0.21875\n",
            "loss: 1.9160956144332886 acc: 0.171875\n",
            "loss: 1.9982876777648926 acc: 0.1875\n",
            "loss: 1.9987980127334595 acc: 0.203125\n",
            "loss: 2.044390916824341 acc: 0.15625\n",
            "loss: 1.962552547454834 acc: 0.140625\n",
            "loss: 1.915715217590332 acc: 0.234375\n",
            "loss: 1.9709819555282593 acc: 0.28125\n",
            "loss: 2.0059263706207275 acc: 0.203125\n",
            "loss: 2.059558629989624 acc: 0.125\n",
            "loss: 1.9486370086669922 acc: 0.203125\n",
            "loss: 1.9057843685150146 acc: 0.296875\n",
            "loss: 1.9646661281585693 acc: 0.1875\n",
            "loss: 2.0109102725982666 acc: 0.140625\n",
            "loss: 1.977243423461914 acc: 0.140625\n",
            "loss: 2.0204856395721436 acc: 0.15625\n",
            "loss: 1.9048182964324951 acc: 0.28125\n",
            "loss: 2.0009286403656006 acc: 0.1875\n",
            "loss: 1.9533482789993286 acc: 0.25\n",
            "loss: 1.95351243019104 acc: 0.203125\n",
            "loss: 2.119715929031372 acc: 0.125\n",
            "loss: 2.096449613571167 acc: 0.171875\n",
            "loss: 2.021523952484131 acc: 0.140625\n",
            "loss: 2.035236358642578 acc: 0.15625\n",
            "loss: 2.0168793201446533 acc: 0.265625\n",
            "loss: 2.02478289604187 acc: 0.21875\n",
            "loss: 2.022773504257202 acc: 0.21875\n",
            "loss: 2.015377998352051 acc: 0.28125\n",
            "loss: 1.986912727355957 acc: 0.203125\n",
            "loss: 1.990836262702942 acc: 0.25\n",
            "loss: 2.010605812072754 acc: 0.171875\n",
            "loss: 2.044457197189331 acc: 0.140625\n",
            "loss: 1.8578269481658936 acc: 0.25\n",
            "loss: 1.859979271888733 acc: 0.296875\n",
            "loss: 2.0048677921295166 acc: 0.171875\n",
            "loss: 1.9988449811935425 acc: 0.171875\n",
            "loss: 1.9108248949050903 acc: 0.25\n",
            "loss: 1.969782829284668 acc: 0.1875\n",
            "loss: 2.1419122219085693 acc: 0.078125\n",
            "loss: 2.061997413635254 acc: 0.171875\n",
            "loss: 2.020930767059326 acc: 0.15625\n",
            "loss: 2.031521797180176 acc: 0.15625\n",
            "loss: 2.1198556423187256 acc: 0.140625\n",
            "loss: 1.9953303337097168 acc: 0.234375\n",
            "loss: 1.9967455863952637 acc: 0.1627907007932663\n",
            "84 epoch:\n",
            "loss: 2.01259446144104 acc: 0.1875\n",
            "loss: 1.8929204940795898 acc: 0.265625\n",
            "loss: 1.971643090248108 acc: 0.21875\n",
            "loss: 2.0188217163085938 acc: 0.140625\n",
            "loss: 1.9792726039886475 acc: 0.21875\n",
            "loss: 1.8999874591827393 acc: 0.328125\n",
            "loss: 1.9917842149734497 acc: 0.203125\n",
            "loss: 1.9010447263717651 acc: 0.1875\n",
            "loss: 1.9564483165740967 acc: 0.21875\n",
            "loss: 1.894276738166809 acc: 0.296875\n",
            "loss: 1.969277024269104 acc: 0.21875\n",
            "loss: 2.0562334060668945 acc: 0.109375\n",
            "loss: 1.9656010866165161 acc: 0.28125\n",
            "loss: 1.934372901916504 acc: 0.234375\n",
            "loss: 1.8760980367660522 acc: 0.3125\n",
            "loss: 1.942438006401062 acc: 0.125\n",
            "loss: 2.0156569480895996 acc: 0.125\n",
            "loss: 1.9961918592453003 acc: 0.1875\n",
            "loss: 2.0128133296966553 acc: 0.234375\n",
            "loss: 1.9479159116744995 acc: 0.234375\n",
            "loss: 1.9219038486480713 acc: 0.28125\n",
            "loss: 1.9625426530838013 acc: 0.21875\n",
            "loss: 2.032445192337036 acc: 0.15625\n",
            "loss: 1.923066258430481 acc: 0.265625\n",
            "loss: 1.9145503044128418 acc: 0.25\n",
            "loss: 2.1111228466033936 acc: 0.109375\n",
            "loss: 1.9697115421295166 acc: 0.15625\n",
            "loss: 1.988166332244873 acc: 0.21875\n",
            "loss: 1.9834487438201904 acc: 0.25\n",
            "loss: 1.9676289558410645 acc: 0.21875\n",
            "loss: 1.9831665754318237 acc: 0.1875\n",
            "loss: 2.012183427810669 acc: 0.21875\n",
            "loss: 2.0527474880218506 acc: 0.25\n",
            "loss: 1.975858449935913 acc: 0.265625\n",
            "loss: 2.0012521743774414 acc: 0.1875\n",
            "loss: 1.9261822700500488 acc: 0.203125\n",
            "loss: 1.9620085954666138 acc: 0.21875\n",
            "loss: 2.0238311290740967 acc: 0.25\n",
            "loss: 1.9578770399093628 acc: 0.203125\n",
            "loss: 1.9330133199691772 acc: 0.28125\n",
            "loss: 1.9693986177444458 acc: 0.203125\n",
            "loss: 1.9332646131515503 acc: 0.28125\n",
            "loss: 1.9877967834472656 acc: 0.203125\n",
            "loss: 2.0597150325775146 acc: 0.171875\n",
            "loss: 1.9417177438735962 acc: 0.1875\n",
            "loss: 2.0213639736175537 acc: 0.171875\n",
            "loss: 2.0203614234924316 acc: 0.21875\n",
            "loss: 1.8929120302200317 acc: 0.265625\n",
            "loss: 2.022930383682251 acc: 0.171875\n",
            "loss: 2.0298216342926025 acc: 0.25\n",
            "loss: 1.9668574333190918 acc: 0.28125\n",
            "loss: 1.9960606098175049 acc: 0.171875\n",
            "loss: 1.9751476049423218 acc: 0.125\n",
            "loss: 1.9334874153137207 acc: 0.25\n",
            "loss: 2.0533840656280518 acc: 0.203125\n",
            "loss: 2.0835540294647217 acc: 0.15625\n",
            "loss: 2.032953977584839 acc: 0.21875\n",
            "loss: 2.0138163566589355 acc: 0.171875\n",
            "loss: 2.003885269165039 acc: 0.203125\n",
            "loss: 1.9002176523208618 acc: 0.3125\n",
            "loss: 2.0167133808135986 acc: 0.203125\n",
            "loss: 2.01668119430542 acc: 0.140625\n",
            "loss: 1.9939249753952026 acc: 0.21875\n",
            "loss: 1.9622701406478882 acc: 0.171875\n",
            "loss: 2.057359218597412 acc: 0.203125\n",
            "loss: 2.0398707389831543 acc: 0.15625\n",
            "loss: 2.03157377243042 acc: 0.140625\n",
            "loss: 1.9766349792480469 acc: 0.21875\n",
            "loss: 1.981868863105774 acc: 0.21875\n",
            "loss: 2.0027413368225098 acc: 0.09375\n",
            "loss: 1.987975001335144 acc: 0.234375\n",
            "loss: 1.9906483888626099 acc: 0.203125\n",
            "loss: 2.000277519226074 acc: 0.234375\n",
            "loss: 2.026663064956665 acc: 0.21875\n",
            "loss: 1.973015308380127 acc: 0.15625\n",
            "loss: 1.9866302013397217 acc: 0.203125\n",
            "loss: 1.8902829885482788 acc: 0.265625\n",
            "loss: 1.9844326972961426 acc: 0.1875\n",
            "loss: 2.002422332763672 acc: 0.21875\n",
            "loss: 2.017874240875244 acc: 0.234375\n",
            "loss: 1.9888314008712769 acc: 0.234375\n",
            "loss: 1.943657398223877 acc: 0.203125\n",
            "loss: 2.1211495399475098 acc: 0.140625\n",
            "loss: 1.9857486486434937 acc: 0.203125\n",
            "loss: 2.0126748085021973 acc: 0.15625\n",
            "loss: 2.035827875137329 acc: 0.140625\n",
            "loss: 2.01997971534729 acc: 0.21875\n",
            "loss: 2.004741907119751 acc: 0.1875\n",
            "loss: 1.8884598016738892 acc: 0.296875\n",
            "loss: 1.9827289581298828 acc: 0.15625\n",
            "loss: 2.0319876670837402 acc: 0.15625\n",
            "loss: 1.9919688701629639 acc: 0.171875\n",
            "loss: 1.9500561952590942 acc: 0.1875\n",
            "loss: 2.007988214492798 acc: 0.234375\n",
            "loss: 1.9914400577545166 acc: 0.21875\n",
            "loss: 2.0368659496307373 acc: 0.171875\n",
            "loss: 2.0440361499786377 acc: 0.265625\n",
            "loss: 2.014913558959961 acc: 0.1875\n",
            "loss: 2.0464608669281006 acc: 0.15625\n",
            "loss: 2.0087063312530518 acc: 0.171875\n",
            "loss: 2.038825035095215 acc: 0.1875\n",
            "loss: 2.0064384937286377 acc: 0.171875\n",
            "loss: 2.0253489017486572 acc: 0.171875\n",
            "loss: 2.022301197052002 acc: 0.203125\n",
            "loss: 2.0218214988708496 acc: 0.140625\n",
            "loss: 1.98062264919281 acc: 0.203125\n",
            "loss: 2.0966269969940186 acc: 0.140625\n",
            "loss: 1.9375157356262207 acc: 0.234375\n",
            "loss: 1.974449872970581 acc: 0.203125\n",
            "loss: 1.990894079208374 acc: 0.23255813121795654\n",
            "85 epoch:\n",
            "loss: 1.9477872848510742 acc: 0.203125\n",
            "loss: 2.006835699081421 acc: 0.234375\n",
            "loss: 1.9114683866500854 acc: 0.171875\n",
            "loss: 1.9902571439743042 acc: 0.21875\n",
            "loss: 1.9568408727645874 acc: 0.296875\n",
            "loss: 1.9684901237487793 acc: 0.1875\n",
            "loss: 1.9581667184829712 acc: 0.234375\n",
            "loss: 1.9924464225769043 acc: 0.140625\n",
            "loss: 2.0272905826568604 acc: 0.140625\n",
            "loss: 1.9453392028808594 acc: 0.171875\n",
            "loss: 1.9881846904754639 acc: 0.171875\n",
            "loss: 1.953873634338379 acc: 0.234375\n",
            "loss: 1.933161735534668 acc: 0.1875\n",
            "loss: 1.9234892129898071 acc: 0.21875\n",
            "loss: 1.9024806022644043 acc: 0.328125\n",
            "loss: 1.9827287197113037 acc: 0.21875\n",
            "loss: 1.9040781259536743 acc: 0.3125\n",
            "loss: 1.9839987754821777 acc: 0.15625\n",
            "loss: 2.0823702812194824 acc: 0.109375\n",
            "loss: 1.9774844646453857 acc: 0.1875\n",
            "loss: 1.9141408205032349 acc: 0.1875\n",
            "loss: 2.0886013507843018 acc: 0.1875\n",
            "loss: 1.9561882019042969 acc: 0.203125\n",
            "loss: 1.9287617206573486 acc: 0.25\n",
            "loss: 1.877629041671753 acc: 0.296875\n",
            "loss: 1.9751571416854858 acc: 0.15625\n",
            "loss: 1.9508190155029297 acc: 0.203125\n",
            "loss: 1.9242247343063354 acc: 0.234375\n",
            "loss: 1.9955233335494995 acc: 0.21875\n",
            "loss: 1.9694452285766602 acc: 0.265625\n",
            "loss: 2.002138614654541 acc: 0.21875\n",
            "loss: 1.9479037523269653 acc: 0.1875\n",
            "loss: 2.037982940673828 acc: 0.234375\n",
            "loss: 1.9070775508880615 acc: 0.234375\n",
            "loss: 2.0182645320892334 acc: 0.1875\n",
            "loss: 2.042766571044922 acc: 0.1875\n",
            "loss: 1.9881970882415771 acc: 0.234375\n",
            "loss: 2.0586094856262207 acc: 0.203125\n",
            "loss: 1.9354052543640137 acc: 0.234375\n",
            "loss: 2.078474998474121 acc: 0.1875\n",
            "loss: 2.041959285736084 acc: 0.1875\n",
            "loss: 2.0474538803100586 acc: 0.203125\n",
            "loss: 2.0329527854919434 acc: 0.171875\n",
            "loss: 2.0489211082458496 acc: 0.15625\n",
            "loss: 1.9605436325073242 acc: 0.25\n",
            "loss: 2.006510019302368 acc: 0.1875\n",
            "loss: 1.9218111038208008 acc: 0.1875\n",
            "loss: 1.9794942140579224 acc: 0.25\n",
            "loss: 2.056504487991333 acc: 0.109375\n",
            "loss: 1.9929741621017456 acc: 0.15625\n",
            "loss: 2.0372202396392822 acc: 0.203125\n",
            "loss: 1.942525863647461 acc: 0.1875\n",
            "loss: 1.9598084688186646 acc: 0.203125\n",
            "loss: 1.9110910892486572 acc: 0.265625\n",
            "loss: 1.9900462627410889 acc: 0.265625\n",
            "loss: 1.9748988151550293 acc: 0.171875\n",
            "loss: 2.001267671585083 acc: 0.234375\n",
            "loss: 1.9565455913543701 acc: 0.21875\n",
            "loss: 1.8884155750274658 acc: 0.21875\n",
            "loss: 2.0675220489501953 acc: 0.1875\n",
            "loss: 2.013629913330078 acc: 0.265625\n",
            "loss: 1.9810162782669067 acc: 0.203125\n",
            "loss: 2.083664894104004 acc: 0.109375\n",
            "loss: 1.965989351272583 acc: 0.1875\n",
            "loss: 2.020963430404663 acc: 0.1875\n",
            "loss: 2.026193141937256 acc: 0.140625\n",
            "loss: 1.8704509735107422 acc: 0.234375\n",
            "loss: 1.9944933652877808 acc: 0.21875\n",
            "loss: 1.9887615442276 acc: 0.234375\n",
            "loss: 2.018862009048462 acc: 0.203125\n",
            "loss: 1.9342082738876343 acc: 0.21875\n",
            "loss: 2.011255979537964 acc: 0.171875\n",
            "loss: 1.983008623123169 acc: 0.1875\n",
            "loss: 2.001333236694336 acc: 0.140625\n",
            "loss: 1.8889518976211548 acc: 0.265625\n",
            "loss: 1.9943270683288574 acc: 0.21875\n",
            "loss: 2.0226869583129883 acc: 0.15625\n",
            "loss: 2.039064884185791 acc: 0.1875\n",
            "loss: 1.9738378524780273 acc: 0.203125\n",
            "loss: 2.023068428039551 acc: 0.140625\n",
            "loss: 2.1107754707336426 acc: 0.15625\n",
            "loss: 1.9350733757019043 acc: 0.21875\n",
            "loss: 2.0501785278320312 acc: 0.1875\n",
            "loss: 1.9352929592132568 acc: 0.265625\n",
            "loss: 1.9411382675170898 acc: 0.25\n",
            "loss: 2.0655293464660645 acc: 0.125\n",
            "loss: 1.9792362451553345 acc: 0.140625\n",
            "loss: 2.0530896186828613 acc: 0.171875\n",
            "loss: 1.9381494522094727 acc: 0.328125\n",
            "loss: 1.9900044202804565 acc: 0.265625\n",
            "loss: 1.9790139198303223 acc: 0.21875\n",
            "loss: 1.970227599143982 acc: 0.265625\n",
            "loss: 1.9535977840423584 acc: 0.203125\n",
            "loss: 2.0092034339904785 acc: 0.1875\n",
            "loss: 1.9954272508621216 acc: 0.25\n",
            "loss: 1.9750112295150757 acc: 0.203125\n",
            "loss: 2.0092244148254395 acc: 0.203125\n",
            "loss: 2.045387029647827 acc: 0.21875\n",
            "loss: 1.9503415822982788 acc: 0.234375\n",
            "loss: 1.9271924495697021 acc: 0.25\n",
            "loss: 1.9752177000045776 acc: 0.3125\n",
            "loss: 1.956254482269287 acc: 0.234375\n",
            "loss: 2.0836398601531982 acc: 0.109375\n",
            "loss: 1.999259114265442 acc: 0.1875\n",
            "loss: 2.088526487350464 acc: 0.1875\n",
            "loss: 1.9623119831085205 acc: 0.25\n",
            "loss: 1.9865493774414062 acc: 0.234375\n",
            "loss: 1.958255648612976 acc: 0.21875\n",
            "loss: 1.9917172193527222 acc: 0.203125\n",
            "loss: 2.0932066440582275 acc: 0.1860465109348297\n",
            "86 epoch:\n",
            "loss: 1.9148950576782227 acc: 0.234375\n",
            "loss: 1.9537378549575806 acc: 0.1875\n",
            "loss: 1.990280032157898 acc: 0.203125\n",
            "loss: 1.9921953678131104 acc: 0.265625\n",
            "loss: 1.9566950798034668 acc: 0.1875\n",
            "loss: 2.046908140182495 acc: 0.09375\n",
            "loss: 2.0456862449645996 acc: 0.140625\n",
            "loss: 1.948776125907898 acc: 0.265625\n",
            "loss: 1.973328709602356 acc: 0.25\n",
            "loss: 1.96377694606781 acc: 0.1875\n",
            "loss: 1.9731717109680176 acc: 0.171875\n",
            "loss: 2.0346922874450684 acc: 0.21875\n",
            "loss: 1.9486446380615234 acc: 0.25\n",
            "loss: 1.97642183303833 acc: 0.1875\n",
            "loss: 1.9163734912872314 acc: 0.21875\n",
            "loss: 1.8740891218185425 acc: 0.234375\n",
            "loss: 1.9266307353973389 acc: 0.234375\n",
            "loss: 1.9911901950836182 acc: 0.203125\n",
            "loss: 1.92915940284729 acc: 0.234375\n",
            "loss: 1.9473094940185547 acc: 0.15625\n",
            "loss: 2.001132011413574 acc: 0.171875\n",
            "loss: 1.9842381477355957 acc: 0.25\n",
            "loss: 1.965487003326416 acc: 0.171875\n",
            "loss: 1.9886972904205322 acc: 0.140625\n",
            "loss: 1.9940547943115234 acc: 0.21875\n",
            "loss: 1.9739797115325928 acc: 0.171875\n",
            "loss: 1.9327279329299927 acc: 0.21875\n",
            "loss: 2.0000898838043213 acc: 0.21875\n",
            "loss: 2.066908359527588 acc: 0.15625\n",
            "loss: 1.954777479171753 acc: 0.203125\n",
            "loss: 2.0357718467712402 acc: 0.15625\n",
            "loss: 1.9905284643173218 acc: 0.15625\n",
            "loss: 1.9914541244506836 acc: 0.15625\n",
            "loss: 1.9670825004577637 acc: 0.234375\n",
            "loss: 1.8996027708053589 acc: 0.265625\n",
            "loss: 2.063631772994995 acc: 0.140625\n",
            "loss: 2.0180273056030273 acc: 0.15625\n",
            "loss: 1.9761836528778076 acc: 0.25\n",
            "loss: 2.075766086578369 acc: 0.21875\n",
            "loss: 2.022963523864746 acc: 0.15625\n",
            "loss: 2.0044498443603516 acc: 0.171875\n",
            "loss: 1.869510531425476 acc: 0.328125\n",
            "loss: 1.9817590713500977 acc: 0.21875\n",
            "loss: 2.082169532775879 acc: 0.21875\n",
            "loss: 1.979975700378418 acc: 0.1875\n",
            "loss: 2.056833267211914 acc: 0.1875\n",
            "loss: 1.9945846796035767 acc: 0.171875\n",
            "loss: 1.9035829305648804 acc: 0.203125\n",
            "loss: 1.9721100330352783 acc: 0.15625\n",
            "loss: 1.9511512517929077 acc: 0.234375\n",
            "loss: 1.9354722499847412 acc: 0.21875\n",
            "loss: 1.9529528617858887 acc: 0.265625\n",
            "loss: 1.9100040197372437 acc: 0.296875\n",
            "loss: 1.9324414730072021 acc: 0.21875\n",
            "loss: 1.9586615562438965 acc: 0.203125\n",
            "loss: 2.0146498680114746 acc: 0.15625\n",
            "loss: 2.0270726680755615 acc: 0.171875\n",
            "loss: 1.9568785429000854 acc: 0.203125\n",
            "loss: 1.9896162748336792 acc: 0.203125\n",
            "loss: 1.9727619886398315 acc: 0.28125\n",
            "loss: 1.9144291877746582 acc: 0.265625\n",
            "loss: 1.994826316833496 acc: 0.234375\n",
            "loss: 2.1094753742218018 acc: 0.140625\n",
            "loss: 2.033416509628296 acc: 0.203125\n",
            "loss: 1.963433861732483 acc: 0.203125\n",
            "loss: 2.027449131011963 acc: 0.09375\n",
            "loss: 2.0676887035369873 acc: 0.171875\n",
            "loss: 2.0089879035949707 acc: 0.140625\n",
            "loss: 1.996023178100586 acc: 0.21875\n",
            "loss: 2.037753105163574 acc: 0.171875\n",
            "loss: 1.9983551502227783 acc: 0.1875\n",
            "loss: 2.004450798034668 acc: 0.3125\n",
            "loss: 1.9437137842178345 acc: 0.171875\n",
            "loss: 1.9254404306411743 acc: 0.203125\n",
            "loss: 2.087510824203491 acc: 0.140625\n",
            "loss: 1.9705618619918823 acc: 0.21875\n",
            "loss: 2.032761812210083 acc: 0.203125\n",
            "loss: 2.045694351196289 acc: 0.1875\n",
            "loss: 1.9821089506149292 acc: 0.203125\n",
            "loss: 1.9301704168319702 acc: 0.21875\n",
            "loss: 1.934421181678772 acc: 0.1875\n",
            "loss: 2.062640428543091 acc: 0.171875\n",
            "loss: 1.885475516319275 acc: 0.296875\n",
            "loss: 2.014557123184204 acc: 0.21875\n",
            "loss: 1.9012889862060547 acc: 0.296875\n",
            "loss: 1.9658572673797607 acc: 0.234375\n",
            "loss: 1.9394407272338867 acc: 0.1875\n",
            "loss: 1.9676005840301514 acc: 0.234375\n",
            "loss: 1.8938791751861572 acc: 0.265625\n",
            "loss: 1.9880092144012451 acc: 0.21875\n",
            "loss: 2.017799139022827 acc: 0.171875\n",
            "loss: 2.055413246154785 acc: 0.140625\n",
            "loss: 2.069214344024658 acc: 0.1875\n",
            "loss: 1.9625701904296875 acc: 0.25\n",
            "loss: 1.9521281719207764 acc: 0.25\n",
            "loss: 1.9482096433639526 acc: 0.203125\n",
            "loss: 1.9296740293502808 acc: 0.265625\n",
            "loss: 2.019796848297119 acc: 0.203125\n",
            "loss: 1.9544918537139893 acc: 0.203125\n",
            "loss: 2.00667667388916 acc: 0.203125\n",
            "loss: 1.9238884449005127 acc: 0.1875\n",
            "loss: 1.9877687692642212 acc: 0.171875\n",
            "loss: 1.97727632522583 acc: 0.203125\n",
            "loss: 2.0632166862487793 acc: 0.15625\n",
            "loss: 2.0205442905426025 acc: 0.171875\n",
            "loss: 1.940925121307373 acc: 0.25\n",
            "loss: 2.0073142051696777 acc: 0.140625\n",
            "loss: 1.9850562810897827 acc: 0.234375\n",
            "loss: 2.056948661804199 acc: 0.109375\n",
            "loss: 1.899762511253357 acc: 0.23255813121795654\n",
            "87 epoch:\n",
            "loss: 2.004085063934326 acc: 0.1875\n",
            "loss: 1.9889342784881592 acc: 0.265625\n",
            "loss: 2.0077009201049805 acc: 0.25\n",
            "loss: 1.8516299724578857 acc: 0.28125\n",
            "loss: 1.9619464874267578 acc: 0.15625\n",
            "loss: 1.927481770515442 acc: 0.234375\n",
            "loss: 2.0236706733703613 acc: 0.15625\n",
            "loss: 1.9337432384490967 acc: 0.203125\n",
            "loss: 1.923795461654663 acc: 0.3125\n",
            "loss: 1.9569065570831299 acc: 0.171875\n",
            "loss: 1.8758747577667236 acc: 0.28125\n",
            "loss: 1.9818888902664185 acc: 0.140625\n",
            "loss: 1.8328160047531128 acc: 0.25\n",
            "loss: 1.978607177734375 acc: 0.265625\n",
            "loss: 1.919080376625061 acc: 0.34375\n",
            "loss: 1.9033787250518799 acc: 0.1875\n",
            "loss: 2.0115199089050293 acc: 0.234375\n",
            "loss: 1.9741908311843872 acc: 0.25\n",
            "loss: 1.9302412271499634 acc: 0.234375\n",
            "loss: 1.9486136436462402 acc: 0.234375\n",
            "loss: 1.9710088968276978 acc: 0.25\n",
            "loss: 2.070449113845825 acc: 0.125\n",
            "loss: 1.9233028888702393 acc: 0.28125\n",
            "loss: 1.9116430282592773 acc: 0.3125\n",
            "loss: 1.937835454940796 acc: 0.234375\n",
            "loss: 1.9518736600875854 acc: 0.234375\n",
            "loss: 1.9275658130645752 acc: 0.203125\n",
            "loss: 1.905344843864441 acc: 0.1875\n",
            "loss: 2.0249223709106445 acc: 0.1875\n",
            "loss: 1.9685019254684448 acc: 0.171875\n",
            "loss: 1.881414771080017 acc: 0.25\n",
            "loss: 1.9154449701309204 acc: 0.28125\n",
            "loss: 2.0149569511413574 acc: 0.15625\n",
            "loss: 1.974652647972107 acc: 0.203125\n",
            "loss: 1.947299599647522 acc: 0.234375\n",
            "loss: 1.941784143447876 acc: 0.1875\n",
            "loss: 2.013947010040283 acc: 0.109375\n",
            "loss: 2.0021965503692627 acc: 0.1875\n",
            "loss: 1.955171823501587 acc: 0.1875\n",
            "loss: 2.012152671813965 acc: 0.234375\n",
            "loss: 2.0137362480163574 acc: 0.203125\n",
            "loss: 1.9331681728363037 acc: 0.3125\n",
            "loss: 1.974488377571106 acc: 0.203125\n",
            "loss: 2.0470616817474365 acc: 0.25\n",
            "loss: 1.8700779676437378 acc: 0.1875\n",
            "loss: 2.0711965560913086 acc: 0.171875\n",
            "loss: 1.9363309144973755 acc: 0.296875\n",
            "loss: 2.0142414569854736 acc: 0.1875\n",
            "loss: 1.879014253616333 acc: 0.234375\n",
            "loss: 1.873190999031067 acc: 0.34375\n",
            "loss: 2.0077741146087646 acc: 0.171875\n",
            "loss: 1.9732625484466553 acc: 0.21875\n",
            "loss: 1.9866427183151245 acc: 0.171875\n",
            "loss: 2.052764415740967 acc: 0.171875\n",
            "loss: 2.0295934677124023 acc: 0.171875\n",
            "loss: 1.9665358066558838 acc: 0.203125\n",
            "loss: 1.968794584274292 acc: 0.203125\n",
            "loss: 2.109386920928955 acc: 0.078125\n",
            "loss: 1.9382705688476562 acc: 0.28125\n",
            "loss: 1.9927058219909668 acc: 0.171875\n",
            "loss: 2.021258592605591 acc: 0.25\n",
            "loss: 1.9904465675354004 acc: 0.171875\n",
            "loss: 2.0279784202575684 acc: 0.21875\n",
            "loss: 1.934472918510437 acc: 0.3125\n",
            "loss: 2.0695533752441406 acc: 0.15625\n",
            "loss: 2.0042712688446045 acc: 0.1875\n",
            "loss: 1.9176554679870605 acc: 0.203125\n",
            "loss: 1.933671236038208 acc: 0.25\n",
            "loss: 1.9860117435455322 acc: 0.15625\n",
            "loss: 1.9718180894851685 acc: 0.1875\n",
            "loss: 2.019865036010742 acc: 0.15625\n",
            "loss: 1.988677978515625 acc: 0.1875\n",
            "loss: 1.9772411584854126 acc: 0.1875\n",
            "loss: 1.9396556615829468 acc: 0.1875\n",
            "loss: 1.9463878870010376 acc: 0.234375\n",
            "loss: 1.9076420068740845 acc: 0.28125\n",
            "loss: 1.9036433696746826 acc: 0.34375\n",
            "loss: 1.9159802198410034 acc: 0.265625\n",
            "loss: 2.0284571647644043 acc: 0.171875\n",
            "loss: 2.0780229568481445 acc: 0.15625\n",
            "loss: 2.0621652603149414 acc: 0.203125\n",
            "loss: 1.9467921257019043 acc: 0.203125\n",
            "loss: 2.0466060638427734 acc: 0.125\n",
            "loss: 1.8789560794830322 acc: 0.34375\n",
            "loss: 2.0298759937286377 acc: 0.1875\n",
            "loss: 2.0104246139526367 acc: 0.171875\n",
            "loss: 1.9811768531799316 acc: 0.265625\n",
            "loss: 1.9630529880523682 acc: 0.265625\n",
            "loss: 1.960559368133545 acc: 0.1875\n",
            "loss: 1.9774789810180664 acc: 0.265625\n",
            "loss: 2.000765085220337 acc: 0.1875\n",
            "loss: 1.9810433387756348 acc: 0.1875\n",
            "loss: 1.9427872896194458 acc: 0.234375\n",
            "loss: 2.040905237197876 acc: 0.109375\n",
            "loss: 1.9566644430160522 acc: 0.203125\n",
            "loss: 1.9509280920028687 acc: 0.1875\n",
            "loss: 1.9828683137893677 acc: 0.21875\n",
            "loss: 1.997051477432251 acc: 0.203125\n",
            "loss: 1.999255895614624 acc: 0.1875\n",
            "loss: 1.9454717636108398 acc: 0.171875\n",
            "loss: 2.0373244285583496 acc: 0.140625\n",
            "loss: 1.9834129810333252 acc: 0.265625\n",
            "loss: 1.9936261177062988 acc: 0.171875\n",
            "loss: 1.9969760179519653 acc: 0.25\n",
            "loss: 1.9001033306121826 acc: 0.328125\n",
            "loss: 1.9799041748046875 acc: 0.15625\n",
            "loss: 1.9694234132766724 acc: 0.140625\n",
            "loss: 1.8393634557724 acc: 0.28125\n",
            "loss: 1.9063026905059814 acc: 0.171875\n",
            "loss: 1.9584898948669434 acc: 0.25581395626068115\n",
            "88 epoch:\n",
            "loss: 1.936259388923645 acc: 0.25\n",
            "loss: 2.0168585777282715 acc: 0.140625\n",
            "loss: 1.926271677017212 acc: 0.1875\n",
            "loss: 1.9066619873046875 acc: 0.1875\n",
            "loss: 1.963616132736206 acc: 0.25\n",
            "loss: 2.0436184406280518 acc: 0.203125\n",
            "loss: 1.9150028228759766 acc: 0.265625\n",
            "loss: 1.917036771774292 acc: 0.296875\n",
            "loss: 1.9567174911499023 acc: 0.203125\n",
            "loss: 1.9614239931106567 acc: 0.234375\n",
            "loss: 1.9801377058029175 acc: 0.21875\n",
            "loss: 2.003134250640869 acc: 0.203125\n",
            "loss: 1.91563880443573 acc: 0.203125\n",
            "loss: 2.0246758460998535 acc: 0.109375\n",
            "loss: 1.8837313652038574 acc: 0.296875\n",
            "loss: 1.9268553256988525 acc: 0.171875\n",
            "loss: 1.9756296873092651 acc: 0.234375\n",
            "loss: 1.866994857788086 acc: 0.328125\n",
            "loss: 2.05819034576416 acc: 0.203125\n",
            "loss: 1.8593494892120361 acc: 0.265625\n",
            "loss: 1.9262807369232178 acc: 0.265625\n",
            "loss: 1.9424232244491577 acc: 0.171875\n",
            "loss: 2.0181169509887695 acc: 0.203125\n",
            "loss: 1.9281630516052246 acc: 0.265625\n",
            "loss: 1.987282156944275 acc: 0.21875\n",
            "loss: 2.031477928161621 acc: 0.171875\n",
            "loss: 2.0112462043762207 acc: 0.234375\n",
            "loss: 1.9400004148483276 acc: 0.21875\n",
            "loss: 2.0288407802581787 acc: 0.078125\n",
            "loss: 2.0025994777679443 acc: 0.21875\n",
            "loss: 1.9347150325775146 acc: 0.203125\n",
            "loss: 2.0021181106567383 acc: 0.21875\n",
            "loss: 2.0069100856781006 acc: 0.15625\n",
            "loss: 1.9069414138793945 acc: 0.21875\n",
            "loss: 1.978536605834961 acc: 0.234375\n",
            "loss: 1.8959245681762695 acc: 0.25\n",
            "loss: 1.9269814491271973 acc: 0.234375\n",
            "loss: 1.9396581649780273 acc: 0.28125\n",
            "loss: 1.9489797353744507 acc: 0.171875\n",
            "loss: 2.0290117263793945 acc: 0.171875\n",
            "loss: 2.108018159866333 acc: 0.140625\n",
            "loss: 1.9485466480255127 acc: 0.203125\n",
            "loss: 1.9874712228775024 acc: 0.1875\n",
            "loss: 1.9551165103912354 acc: 0.1875\n",
            "loss: 1.9267919063568115 acc: 0.234375\n",
            "loss: 1.9454425573349 acc: 0.25\n",
            "loss: 2.0129568576812744 acc: 0.234375\n",
            "loss: 1.975056529045105 acc: 0.234375\n",
            "loss: 2.0266358852386475 acc: 0.140625\n",
            "loss: 2.0110907554626465 acc: 0.234375\n",
            "loss: 1.9413596391677856 acc: 0.21875\n",
            "loss: 1.9914441108703613 acc: 0.234375\n",
            "loss: 1.975829839706421 acc: 0.140625\n",
            "loss: 2.022487163543701 acc: 0.15625\n",
            "loss: 2.096296787261963 acc: 0.125\n",
            "loss: 1.9771829843521118 acc: 0.203125\n",
            "loss: 1.9435856342315674 acc: 0.265625\n",
            "loss: 1.9049807786941528 acc: 0.28125\n",
            "loss: 1.999322533607483 acc: 0.203125\n",
            "loss: 1.9878710508346558 acc: 0.21875\n",
            "loss: 2.0402016639709473 acc: 0.125\n",
            "loss: 1.9217537641525269 acc: 0.265625\n",
            "loss: 1.9389679431915283 acc: 0.234375\n",
            "loss: 1.9400851726531982 acc: 0.203125\n",
            "loss: 2.042607069015503 acc: 0.15625\n",
            "loss: 1.9787003993988037 acc: 0.15625\n",
            "loss: 2.0178682804107666 acc: 0.234375\n",
            "loss: 1.99553644657135 acc: 0.21875\n",
            "loss: 1.9425222873687744 acc: 0.1875\n",
            "loss: 1.8763245344161987 acc: 0.25\n",
            "loss: 1.8757284879684448 acc: 0.296875\n",
            "loss: 1.9736638069152832 acc: 0.25\n",
            "loss: 2.0291199684143066 acc: 0.1875\n",
            "loss: 1.9447944164276123 acc: 0.21875\n",
            "loss: 1.9230767488479614 acc: 0.203125\n",
            "loss: 1.9730188846588135 acc: 0.265625\n",
            "loss: 1.939948558807373 acc: 0.25\n",
            "loss: 2.055522918701172 acc: 0.203125\n",
            "loss: 1.9590555429458618 acc: 0.21875\n",
            "loss: 1.9961987733840942 acc: 0.15625\n",
            "loss: 1.9004344940185547 acc: 0.234375\n",
            "loss: 2.0307092666625977 acc: 0.203125\n",
            "loss: 1.9515982866287231 acc: 0.203125\n",
            "loss: 2.0109550952911377 acc: 0.21875\n",
            "loss: 2.022143840789795 acc: 0.203125\n",
            "loss: 1.9936522245407104 acc: 0.25\n",
            "loss: 1.9774709939956665 acc: 0.234375\n",
            "loss: 1.9804919958114624 acc: 0.15625\n",
            "loss: 2.023050546646118 acc: 0.109375\n",
            "loss: 1.9955066442489624 acc: 0.171875\n",
            "loss: 2.0059874057769775 acc: 0.234375\n",
            "loss: 1.972833514213562 acc: 0.203125\n",
            "loss: 1.9729392528533936 acc: 0.203125\n",
            "loss: 1.8628199100494385 acc: 0.34375\n",
            "loss: 1.9845818281173706 acc: 0.140625\n",
            "loss: 1.8759338855743408 acc: 0.3125\n",
            "loss: 1.9849846363067627 acc: 0.203125\n",
            "loss: 1.9890803098678589 acc: 0.171875\n",
            "loss: 1.905207633972168 acc: 0.171875\n",
            "loss: 2.0202338695526123 acc: 0.15625\n",
            "loss: 2.0147669315338135 acc: 0.140625\n",
            "loss: 1.9829241037368774 acc: 0.265625\n",
            "loss: 1.8693034648895264 acc: 0.3125\n",
            "loss: 2.030940055847168 acc: 0.21875\n",
            "loss: 1.9816876649856567 acc: 0.1875\n",
            "loss: 1.9905563592910767 acc: 0.140625\n",
            "loss: 1.9296690225601196 acc: 0.265625\n",
            "loss: 1.9264287948608398 acc: 0.21875\n",
            "loss: 2.0228848457336426 acc: 0.140625\n",
            "loss: 2.0524044036865234 acc: 0.1860465109348297\n",
            "89 epoch:\n",
            "loss: 1.923851728439331 acc: 0.265625\n",
            "loss: 1.946311593055725 acc: 0.171875\n",
            "loss: 1.9604225158691406 acc: 0.140625\n",
            "loss: 1.9462896585464478 acc: 0.28125\n",
            "loss: 1.8857142925262451 acc: 0.28125\n",
            "loss: 1.9114664793014526 acc: 0.234375\n",
            "loss: 1.9887349605560303 acc: 0.140625\n",
            "loss: 1.9472956657409668 acc: 0.25\n",
            "loss: 2.074021577835083 acc: 0.171875\n",
            "loss: 1.8663166761398315 acc: 0.296875\n",
            "loss: 2.0048694610595703 acc: 0.171875\n",
            "loss: 1.9238015413284302 acc: 0.1875\n",
            "loss: 1.8800793886184692 acc: 0.234375\n",
            "loss: 1.9537384510040283 acc: 0.21875\n",
            "loss: 1.9514989852905273 acc: 0.171875\n",
            "loss: 2.0414485931396484 acc: 0.1875\n",
            "loss: 1.974375605583191 acc: 0.15625\n",
            "loss: 1.988879919052124 acc: 0.21875\n",
            "loss: 1.9561666250228882 acc: 0.15625\n",
            "loss: 1.9971873760223389 acc: 0.140625\n",
            "loss: 1.9157781600952148 acc: 0.234375\n",
            "loss: 1.9486057758331299 acc: 0.25\n",
            "loss: 2.035917043685913 acc: 0.15625\n",
            "loss: 1.9627861976623535 acc: 0.21875\n",
            "loss: 1.9360171556472778 acc: 0.25\n",
            "loss: 1.9562276601791382 acc: 0.21875\n",
            "loss: 1.860914945602417 acc: 0.28125\n",
            "loss: 1.9573380947113037 acc: 0.234375\n",
            "loss: 2.0017151832580566 acc: 0.1875\n",
            "loss: 1.956465721130371 acc: 0.25\n",
            "loss: 2.0033929347991943 acc: 0.171875\n",
            "loss: 1.9292545318603516 acc: 0.265625\n",
            "loss: 1.9502248764038086 acc: 0.25\n",
            "loss: 1.9449390172958374 acc: 0.265625\n",
            "loss: 1.9021327495574951 acc: 0.265625\n",
            "loss: 1.9541826248168945 acc: 0.21875\n",
            "loss: 1.9826843738555908 acc: 0.265625\n",
            "loss: 1.8588154315948486 acc: 0.234375\n",
            "loss: 1.9517459869384766 acc: 0.28125\n",
            "loss: 1.9448301792144775 acc: 0.28125\n",
            "loss: 1.845251441001892 acc: 0.3125\n",
            "loss: 1.9802908897399902 acc: 0.15625\n",
            "loss: 1.9809601306915283 acc: 0.203125\n",
            "loss: 1.9137438535690308 acc: 0.21875\n",
            "loss: 1.9772229194641113 acc: 0.21875\n",
            "loss: 2.0512845516204834 acc: 0.1875\n",
            "loss: 1.987979531288147 acc: 0.21875\n",
            "loss: 1.8721671104431152 acc: 0.171875\n",
            "loss: 2.0795719623565674 acc: 0.140625\n",
            "loss: 1.9803792238235474 acc: 0.234375\n",
            "loss: 1.9612568616867065 acc: 0.1875\n",
            "loss: 1.9755158424377441 acc: 0.25\n",
            "loss: 1.9256196022033691 acc: 0.21875\n",
            "loss: 1.9113290309906006 acc: 0.296875\n",
            "loss: 2.027163028717041 acc: 0.203125\n",
            "loss: 1.9533579349517822 acc: 0.21875\n",
            "loss: 1.9361107349395752 acc: 0.265625\n",
            "loss: 1.9645291566848755 acc: 0.21875\n",
            "loss: 2.001035213470459 acc: 0.171875\n",
            "loss: 1.9564775228500366 acc: 0.21875\n",
            "loss: 1.888210415840149 acc: 0.296875\n",
            "loss: 2.0709431171417236 acc: 0.140625\n",
            "loss: 1.9161123037338257 acc: 0.28125\n",
            "loss: 1.9174994230270386 acc: 0.1875\n",
            "loss: 1.9370633363723755 acc: 0.265625\n",
            "loss: 1.9865630865097046 acc: 0.125\n",
            "loss: 1.9232687950134277 acc: 0.265625\n",
            "loss: 1.9368629455566406 acc: 0.171875\n",
            "loss: 1.9427759647369385 acc: 0.203125\n",
            "loss: 2.034355878829956 acc: 0.171875\n",
            "loss: 1.9950610399246216 acc: 0.15625\n",
            "loss: 2.04850172996521 acc: 0.21875\n",
            "loss: 1.9877543449401855 acc: 0.171875\n",
            "loss: 2.0202796459198 acc: 0.15625\n",
            "loss: 1.9863860607147217 acc: 0.1875\n",
            "loss: 1.981813669204712 acc: 0.234375\n",
            "loss: 2.005838632583618 acc: 0.21875\n",
            "loss: 1.9459229707717896 acc: 0.21875\n",
            "loss: 2.0240702629089355 acc: 0.15625\n",
            "loss: 1.9022254943847656 acc: 0.3125\n",
            "loss: 2.0398316383361816 acc: 0.171875\n",
            "loss: 1.962345838546753 acc: 0.265625\n",
            "loss: 1.8950475454330444 acc: 0.265625\n",
            "loss: 1.9674060344696045 acc: 0.171875\n",
            "loss: 1.9291757345199585 acc: 0.359375\n",
            "loss: 1.9135316610336304 acc: 0.28125\n",
            "loss: 1.8756420612335205 acc: 0.28125\n",
            "loss: 1.961521029472351 acc: 0.21875\n",
            "loss: 1.9533156156539917 acc: 0.21875\n",
            "loss: 1.9886959791183472 acc: 0.171875\n",
            "loss: 1.953904390335083 acc: 0.25\n",
            "loss: 1.8893285989761353 acc: 0.203125\n",
            "loss: 1.8833907842636108 acc: 0.203125\n",
            "loss: 1.898005485534668 acc: 0.1875\n",
            "loss: 1.9145407676696777 acc: 0.171875\n",
            "loss: 1.8947453498840332 acc: 0.3125\n",
            "loss: 1.9458223581314087 acc: 0.28125\n",
            "loss: 2.053501844406128 acc: 0.140625\n",
            "loss: 1.9648081064224243 acc: 0.171875\n",
            "loss: 1.9706089496612549 acc: 0.1875\n",
            "loss: 2.0008649826049805 acc: 0.171875\n",
            "loss: 1.992089033126831 acc: 0.234375\n",
            "loss: 1.9745266437530518 acc: 0.25\n",
            "loss: 1.9816263914108276 acc: 0.234375\n",
            "loss: 1.9748661518096924 acc: 0.1875\n",
            "loss: 1.912009596824646 acc: 0.390625\n",
            "loss: 1.910048246383667 acc: 0.265625\n",
            "loss: 1.9986248016357422 acc: 0.1875\n",
            "loss: 1.9347236156463623 acc: 0.21875\n",
            "loss: 1.9168922901153564 acc: 0.27906978130340576\n",
            "90 epoch:\n",
            "loss: 1.984711766242981 acc: 0.15625\n",
            "loss: 1.8824436664581299 acc: 0.34375\n",
            "loss: 1.9782841205596924 acc: 0.234375\n",
            "loss: 1.9177043437957764 acc: 0.296875\n",
            "loss: 1.9264599084854126 acc: 0.28125\n",
            "loss: 2.056152582168579 acc: 0.21875\n",
            "loss: 1.9539960622787476 acc: 0.15625\n",
            "loss: 1.9644230604171753 acc: 0.1875\n",
            "loss: 1.8416310548782349 acc: 0.296875\n",
            "loss: 1.9186331033706665 acc: 0.234375\n",
            "loss: 1.8520259857177734 acc: 0.234375\n",
            "loss: 2.026416063308716 acc: 0.203125\n",
            "loss: 1.9503326416015625 acc: 0.1875\n",
            "loss: 1.9548274278640747 acc: 0.28125\n",
            "loss: 1.9037967920303345 acc: 0.1875\n",
            "loss: 1.8623844385147095 acc: 0.296875\n",
            "loss: 2.001594066619873 acc: 0.1875\n",
            "loss: 1.9274059534072876 acc: 0.234375\n",
            "loss: 1.796322226524353 acc: 0.34375\n",
            "loss: 2.0081441402435303 acc: 0.1875\n",
            "loss: 1.9040113687515259 acc: 0.34375\n",
            "loss: 2.000129461288452 acc: 0.125\n",
            "loss: 1.9687172174453735 acc: 0.171875\n",
            "loss: 1.938875436782837 acc: 0.296875\n",
            "loss: 1.9756619930267334 acc: 0.1875\n",
            "loss: 1.9811420440673828 acc: 0.21875\n",
            "loss: 1.989772081375122 acc: 0.28125\n",
            "loss: 1.9787596464157104 acc: 0.1875\n",
            "loss: 1.859281301498413 acc: 0.34375\n",
            "loss: 1.9569599628448486 acc: 0.21875\n",
            "loss: 1.887929916381836 acc: 0.234375\n",
            "loss: 1.9987002611160278 acc: 0.25\n",
            "loss: 1.9614074230194092 acc: 0.203125\n",
            "loss: 1.8746273517608643 acc: 0.25\n",
            "loss: 1.9784191846847534 acc: 0.171875\n",
            "loss: 1.9522937536239624 acc: 0.171875\n",
            "loss: 1.8561816215515137 acc: 0.359375\n",
            "loss: 1.9736584424972534 acc: 0.234375\n",
            "loss: 2.0281314849853516 acc: 0.171875\n",
            "loss: 2.024017572402954 acc: 0.1875\n",
            "loss: 2.023254871368408 acc: 0.171875\n",
            "loss: 2.041384220123291 acc: 0.234375\n",
            "loss: 2.025843858718872 acc: 0.203125\n",
            "loss: 1.9608632326126099 acc: 0.25\n",
            "loss: 1.9563504457473755 acc: 0.265625\n",
            "loss: 1.9215346574783325 acc: 0.21875\n",
            "loss: 1.9473497867584229 acc: 0.171875\n",
            "loss: 2.026341199874878 acc: 0.15625\n",
            "loss: 1.9359127283096313 acc: 0.203125\n",
            "loss: 1.8816554546356201 acc: 0.296875\n",
            "loss: 1.9925150871276855 acc: 0.203125\n",
            "loss: 1.9552059173583984 acc: 0.21875\n",
            "loss: 1.8961540460586548 acc: 0.25\n",
            "loss: 1.9684710502624512 acc: 0.21875\n",
            "loss: 1.9832450151443481 acc: 0.21875\n",
            "loss: 1.859146237373352 acc: 0.28125\n",
            "loss: 1.9526982307434082 acc: 0.265625\n",
            "loss: 1.9409512281417847 acc: 0.25\n",
            "loss: 1.9734177589416504 acc: 0.171875\n",
            "loss: 1.9999600648880005 acc: 0.21875\n",
            "loss: 1.9031426906585693 acc: 0.359375\n",
            "loss: 1.838864803314209 acc: 0.296875\n",
            "loss: 1.866143822669983 acc: 0.265625\n",
            "loss: 1.926255464553833 acc: 0.25\n",
            "loss: 1.9858227968215942 acc: 0.25\n",
            "loss: 1.8427293300628662 acc: 0.28125\n",
            "loss: 1.9411802291870117 acc: 0.265625\n",
            "loss: 2.0615999698638916 acc: 0.203125\n",
            "loss: 1.9316368103027344 acc: 0.203125\n",
            "loss: 1.9942231178283691 acc: 0.171875\n",
            "loss: 1.8293428421020508 acc: 0.296875\n",
            "loss: 1.9118974208831787 acc: 0.265625\n",
            "loss: 1.8819762468338013 acc: 0.28125\n",
            "loss: 1.9600718021392822 acc: 0.171875\n",
            "loss: 1.9558542966842651 acc: 0.234375\n",
            "loss: 2.0161867141723633 acc: 0.203125\n",
            "loss: 2.085214853286743 acc: 0.21875\n",
            "loss: 1.9450715780258179 acc: 0.25\n",
            "loss: 2.0159809589385986 acc: 0.1875\n",
            "loss: 1.8644962310791016 acc: 0.28125\n",
            "loss: 2.0598669052124023 acc: 0.203125\n",
            "loss: 1.9192605018615723 acc: 0.203125\n",
            "loss: 1.974399209022522 acc: 0.203125\n",
            "loss: 2.0020523071289062 acc: 0.203125\n",
            "loss: 1.9699187278747559 acc: 0.203125\n",
            "loss: 1.9732412099838257 acc: 0.171875\n",
            "loss: 1.9704750776290894 acc: 0.1875\n",
            "loss: 1.96956205368042 acc: 0.171875\n",
            "loss: 1.9853888750076294 acc: 0.28125\n",
            "loss: 1.8975259065628052 acc: 0.203125\n",
            "loss: 1.8511933088302612 acc: 0.28125\n",
            "loss: 1.8991090059280396 acc: 0.265625\n",
            "loss: 1.961822509765625 acc: 0.265625\n",
            "loss: 1.9814050197601318 acc: 0.25\n",
            "loss: 1.9787957668304443 acc: 0.234375\n",
            "loss: 1.9251426458358765 acc: 0.21875\n",
            "loss: 1.9016810655593872 acc: 0.1875\n",
            "loss: 1.8799495697021484 acc: 0.234375\n",
            "loss: 2.0017940998077393 acc: 0.1875\n",
            "loss: 1.9877418279647827 acc: 0.1875\n",
            "loss: 1.9768949747085571 acc: 0.234375\n",
            "loss: 1.9880547523498535 acc: 0.21875\n",
            "loss: 1.8684364557266235 acc: 0.28125\n",
            "loss: 1.9842201471328735 acc: 0.1875\n",
            "loss: 1.9556940793991089 acc: 0.171875\n",
            "loss: 2.001903772354126 acc: 0.21875\n",
            "loss: 1.8560980558395386 acc: 0.21875\n",
            "loss: 2.0763115882873535 acc: 0.109375\n",
            "loss: 1.934433102607727 acc: 0.234375\n",
            "loss: 1.9594366550445557 acc: 0.23255813121795654\n",
            "91 epoch:\n",
            "loss: 1.9504358768463135 acc: 0.28125\n",
            "loss: 1.9055964946746826 acc: 0.328125\n",
            "loss: 1.985514521598816 acc: 0.234375\n",
            "loss: 1.8069056272506714 acc: 0.3125\n",
            "loss: 1.905227541923523 acc: 0.265625\n",
            "loss: 1.9911675453186035 acc: 0.25\n",
            "loss: 1.976299524307251 acc: 0.234375\n",
            "loss: 1.9307796955108643 acc: 0.1875\n",
            "loss: 2.0504143238067627 acc: 0.25\n",
            "loss: 1.9268097877502441 acc: 0.1875\n",
            "loss: 1.9394335746765137 acc: 0.265625\n",
            "loss: 1.853926181793213 acc: 0.25\n",
            "loss: 2.0673508644104004 acc: 0.140625\n",
            "loss: 1.9665753841400146 acc: 0.265625\n",
            "loss: 1.8622803688049316 acc: 0.328125\n",
            "loss: 1.9258044958114624 acc: 0.25\n",
            "loss: 1.9219741821289062 acc: 0.1875\n",
            "loss: 1.9069746732711792 acc: 0.234375\n",
            "loss: 1.957379698753357 acc: 0.171875\n",
            "loss: 1.8809794187545776 acc: 0.234375\n",
            "loss: 1.9739680290222168 acc: 0.09375\n",
            "loss: 1.8630880117416382 acc: 0.296875\n",
            "loss: 1.9378105401992798 acc: 0.3125\n",
            "loss: 1.9228129386901855 acc: 0.3125\n",
            "loss: 1.8537797927856445 acc: 0.25\n",
            "loss: 1.9938825368881226 acc: 0.234375\n",
            "loss: 1.9444636106491089 acc: 0.21875\n",
            "loss: 1.9091910123825073 acc: 0.25\n",
            "loss: 2.0955779552459717 acc: 0.265625\n",
            "loss: 1.9441497325897217 acc: 0.203125\n",
            "loss: 1.8945238590240479 acc: 0.1875\n",
            "loss: 1.853738784790039 acc: 0.21875\n",
            "loss: 1.8989979028701782 acc: 0.3125\n",
            "loss: 1.9096745252609253 acc: 0.203125\n",
            "loss: 1.9096109867095947 acc: 0.296875\n",
            "loss: 2.0206637382507324 acc: 0.1875\n",
            "loss: 1.9434548616409302 acc: 0.28125\n",
            "loss: 1.8920048475265503 acc: 0.25\n",
            "loss: 1.962507724761963 acc: 0.203125\n",
            "loss: 1.9704045057296753 acc: 0.21875\n",
            "loss: 1.8408117294311523 acc: 0.21875\n",
            "loss: 1.9702188968658447 acc: 0.234375\n",
            "loss: 1.9624862670898438 acc: 0.203125\n",
            "loss: 1.888791799545288 acc: 0.25\n",
            "loss: 1.924630880355835 acc: 0.234375\n",
            "loss: 1.955002784729004 acc: 0.203125\n",
            "loss: 1.9234970808029175 acc: 0.25\n",
            "loss: 1.8726129531860352 acc: 0.28125\n",
            "loss: 1.9991025924682617 acc: 0.203125\n",
            "loss: 2.0185625553131104 acc: 0.203125\n",
            "loss: 1.999258279800415 acc: 0.1875\n",
            "loss: 1.9537652730941772 acc: 0.25\n",
            "loss: 2.029492139816284 acc: 0.21875\n",
            "loss: 1.9113942384719849 acc: 0.296875\n",
            "loss: 1.8113453388214111 acc: 0.265625\n",
            "loss: 1.9687803983688354 acc: 0.203125\n",
            "loss: 2.0179407596588135 acc: 0.203125\n",
            "loss: 1.9923876523971558 acc: 0.15625\n",
            "loss: 1.9762684106826782 acc: 0.28125\n",
            "loss: 1.9806891679763794 acc: 0.171875\n",
            "loss: 1.9317328929901123 acc: 0.234375\n",
            "loss: 1.940380334854126 acc: 0.265625\n",
            "loss: 1.9014424085617065 acc: 0.265625\n",
            "loss: 1.8976802825927734 acc: 0.21875\n",
            "loss: 1.834542989730835 acc: 0.375\n",
            "loss: 2.0581178665161133 acc: 0.1875\n",
            "loss: 1.9849622249603271 acc: 0.21875\n",
            "loss: 2.0216050148010254 acc: 0.234375\n",
            "loss: 1.944696307182312 acc: 0.21875\n",
            "loss: 2.0194664001464844 acc: 0.171875\n",
            "loss: 1.9536393880844116 acc: 0.25\n",
            "loss: 1.956440806388855 acc: 0.203125\n",
            "loss: 2.0343894958496094 acc: 0.140625\n",
            "loss: 1.9558451175689697 acc: 0.234375\n",
            "loss: 1.921700358390808 acc: 0.296875\n",
            "loss: 1.8599690198898315 acc: 0.28125\n",
            "loss: 1.966388463973999 acc: 0.21875\n",
            "loss: 1.8821450471878052 acc: 0.25\n",
            "loss: 1.9732753038406372 acc: 0.171875\n",
            "loss: 1.9206373691558838 acc: 0.265625\n",
            "loss: 1.8595938682556152 acc: 0.140625\n",
            "loss: 2.001985788345337 acc: 0.1875\n",
            "loss: 1.9576598405838013 acc: 0.1875\n",
            "loss: 1.9516825675964355 acc: 0.1875\n",
            "loss: 2.0424301624298096 acc: 0.234375\n",
            "loss: 2.056857109069824 acc: 0.1875\n",
            "loss: 1.8992230892181396 acc: 0.328125\n",
            "loss: 2.0633974075317383 acc: 0.140625\n",
            "loss: 2.112860679626465 acc: 0.109375\n",
            "loss: 1.8958547115325928 acc: 0.203125\n",
            "loss: 1.949510097503662 acc: 0.28125\n",
            "loss: 2.049027681350708 acc: 0.15625\n",
            "loss: 1.9673091173171997 acc: 0.203125\n",
            "loss: 1.9482734203338623 acc: 0.15625\n",
            "loss: 1.9379887580871582 acc: 0.28125\n",
            "loss: 1.932307243347168 acc: 0.203125\n",
            "loss: 1.9233572483062744 acc: 0.265625\n",
            "loss: 2.0052413940429688 acc: 0.25\n",
            "loss: 1.9547951221466064 acc: 0.234375\n",
            "loss: 1.9227865934371948 acc: 0.234375\n",
            "loss: 1.932607889175415 acc: 0.234375\n",
            "loss: 1.97337806224823 acc: 0.234375\n",
            "loss: 2.000495195388794 acc: 0.140625\n",
            "loss: 1.964060664176941 acc: 0.21875\n",
            "loss: 1.954162359237671 acc: 0.15625\n",
            "loss: 1.911959171295166 acc: 0.296875\n",
            "loss: 1.9159324169158936 acc: 0.296875\n",
            "loss: 1.9383411407470703 acc: 0.1875\n",
            "loss: 1.9776679277420044 acc: 0.234375\n",
            "loss: 2.0028982162475586 acc: 0.1860465109348297\n",
            "92 epoch:\n",
            "loss: 1.9338583946228027 acc: 0.25\n",
            "loss: 1.9419291019439697 acc: 0.234375\n",
            "loss: 1.8114715814590454 acc: 0.28125\n",
            "loss: 2.0424628257751465 acc: 0.171875\n",
            "loss: 1.9470691680908203 acc: 0.25\n",
            "loss: 1.958993673324585 acc: 0.21875\n",
            "loss: 1.9617358446121216 acc: 0.234375\n",
            "loss: 1.8381651639938354 acc: 0.28125\n",
            "loss: 1.9168481826782227 acc: 0.25\n",
            "loss: 1.9514909982681274 acc: 0.265625\n",
            "loss: 1.996476411819458 acc: 0.15625\n",
            "loss: 1.9490673542022705 acc: 0.234375\n",
            "loss: 2.01357364654541 acc: 0.21875\n",
            "loss: 1.8912185430526733 acc: 0.265625\n",
            "loss: 2.007594108581543 acc: 0.234375\n",
            "loss: 1.926317811012268 acc: 0.125\n",
            "loss: 1.9877209663391113 acc: 0.25\n",
            "loss: 1.8446069955825806 acc: 0.3125\n",
            "loss: 1.9186309576034546 acc: 0.1875\n",
            "loss: 1.9453495740890503 acc: 0.203125\n",
            "loss: 1.9845525026321411 acc: 0.21875\n",
            "loss: 2.0187065601348877 acc: 0.171875\n",
            "loss: 1.8106398582458496 acc: 0.328125\n",
            "loss: 1.865964651107788 acc: 0.265625\n",
            "loss: 1.9807530641555786 acc: 0.21875\n",
            "loss: 1.9008969068527222 acc: 0.265625\n",
            "loss: 2.034743309020996 acc: 0.296875\n",
            "loss: 1.974315881729126 acc: 0.203125\n",
            "loss: 1.9575676918029785 acc: 0.296875\n",
            "loss: 1.8593659400939941 acc: 0.328125\n",
            "loss: 1.8339128494262695 acc: 0.28125\n",
            "loss: 1.9154127836227417 acc: 0.28125\n",
            "loss: 1.9283925294876099 acc: 0.1875\n",
            "loss: 1.938870906829834 acc: 0.21875\n",
            "loss: 1.8915951251983643 acc: 0.28125\n",
            "loss: 1.9847439527511597 acc: 0.1875\n",
            "loss: 1.990591287612915 acc: 0.1875\n",
            "loss: 1.877690076828003 acc: 0.296875\n",
            "loss: 2.0056774616241455 acc: 0.21875\n",
            "loss: 1.9662165641784668 acc: 0.21875\n",
            "loss: 2.0102365016937256 acc: 0.171875\n",
            "loss: 1.9329618215560913 acc: 0.265625\n",
            "loss: 1.9920753240585327 acc: 0.1875\n",
            "loss: 1.8935858011245728 acc: 0.296875\n",
            "loss: 1.9740793704986572 acc: 0.234375\n",
            "loss: 1.9283913373947144 acc: 0.234375\n",
            "loss: 1.8736553192138672 acc: 0.34375\n",
            "loss: 1.946240782737732 acc: 0.28125\n",
            "loss: 2.026069164276123 acc: 0.15625\n",
            "loss: 2.0187063217163086 acc: 0.140625\n",
            "loss: 1.9574769735336304 acc: 0.265625\n",
            "loss: 1.9163092374801636 acc: 0.25\n",
            "loss: 1.845750093460083 acc: 0.25\n",
            "loss: 1.8764721155166626 acc: 0.328125\n",
            "loss: 2.00681209564209 acc: 0.21875\n",
            "loss: 1.8358076810836792 acc: 0.296875\n",
            "loss: 1.9635697603225708 acc: 0.21875\n",
            "loss: 1.921912670135498 acc: 0.140625\n",
            "loss: 1.9892555475234985 acc: 0.25\n",
            "loss: 2.036177158355713 acc: 0.296875\n",
            "loss: 2.006655693054199 acc: 0.15625\n",
            "loss: 1.8946889638900757 acc: 0.28125\n",
            "loss: 1.9966214895248413 acc: 0.171875\n",
            "loss: 1.8998879194259644 acc: 0.265625\n",
            "loss: 1.9452272653579712 acc: 0.171875\n",
            "loss: 2.020620346069336 acc: 0.234375\n",
            "loss: 1.9177706241607666 acc: 0.21875\n",
            "loss: 1.9627461433410645 acc: 0.21875\n",
            "loss: 1.8973979949951172 acc: 0.21875\n",
            "loss: 2.022115707397461 acc: 0.125\n",
            "loss: 1.9963057041168213 acc: 0.15625\n",
            "loss: 1.9389469623565674 acc: 0.25\n",
            "loss: 1.9445734024047852 acc: 0.265625\n",
            "loss: 1.9801913499832153 acc: 0.1875\n",
            "loss: 1.9309989213943481 acc: 0.21875\n",
            "loss: 2.0505576133728027 acc: 0.171875\n",
            "loss: 1.874046802520752 acc: 0.21875\n",
            "loss: 1.9799420833587646 acc: 0.203125\n",
            "loss: 1.9425263404846191 acc: 0.21875\n",
            "loss: 1.9690150022506714 acc: 0.265625\n",
            "loss: 1.9180363416671753 acc: 0.28125\n",
            "loss: 1.9733186960220337 acc: 0.296875\n",
            "loss: 1.8858031034469604 acc: 0.21875\n",
            "loss: 1.883962631225586 acc: 0.203125\n",
            "loss: 1.8376646041870117 acc: 0.25\n",
            "loss: 1.9214228391647339 acc: 0.21875\n",
            "loss: 2.075401544570923 acc: 0.171875\n",
            "loss: 1.8808661699295044 acc: 0.203125\n",
            "loss: 1.9241523742675781 acc: 0.234375\n",
            "loss: 1.985196590423584 acc: 0.203125\n",
            "loss: 1.9080175161361694 acc: 0.28125\n",
            "loss: 1.9024574756622314 acc: 0.296875\n",
            "loss: 2.0920910835266113 acc: 0.15625\n",
            "loss: 1.895063877105713 acc: 0.234375\n",
            "loss: 1.8802025318145752 acc: 0.265625\n",
            "loss: 1.9880174398422241 acc: 0.140625\n",
            "loss: 1.9440208673477173 acc: 0.203125\n",
            "loss: 1.9356809854507446 acc: 0.21875\n",
            "loss: 1.872056007385254 acc: 0.28125\n",
            "loss: 2.050931692123413 acc: 0.15625\n",
            "loss: 1.8936257362365723 acc: 0.15625\n",
            "loss: 1.928439974784851 acc: 0.21875\n",
            "loss: 1.8425257205963135 acc: 0.3125\n",
            "loss: 1.8842978477478027 acc: 0.234375\n",
            "loss: 1.8975310325622559 acc: 0.21875\n",
            "loss: 1.9348084926605225 acc: 0.21875\n",
            "loss: 2.0007128715515137 acc: 0.203125\n",
            "loss: 2.0117199420928955 acc: 0.21875\n",
            "loss: 1.999981164932251 acc: 0.109375\n",
            "loss: 1.9773494005203247 acc: 0.1627907007932663\n",
            "93 epoch:\n",
            "loss: 1.8860987424850464 acc: 0.15625\n",
            "loss: 2.025944948196411 acc: 0.1875\n",
            "loss: 1.9132380485534668 acc: 0.21875\n",
            "loss: 1.9405280351638794 acc: 0.1875\n",
            "loss: 1.9243789911270142 acc: 0.265625\n",
            "loss: 1.9267563819885254 acc: 0.25\n",
            "loss: 1.8303247690200806 acc: 0.265625\n",
            "loss: 1.85409677028656 acc: 0.265625\n",
            "loss: 1.9844696521759033 acc: 0.125\n",
            "loss: 1.859201431274414 acc: 0.28125\n",
            "loss: 1.9067529439926147 acc: 0.296875\n",
            "loss: 1.869599461555481 acc: 0.203125\n",
            "loss: 1.9764584302902222 acc: 0.15625\n",
            "loss: 1.8709535598754883 acc: 0.328125\n",
            "loss: 1.8793330192565918 acc: 0.234375\n",
            "loss: 1.96694016456604 acc: 0.21875\n",
            "loss: 1.8594835996627808 acc: 0.265625\n",
            "loss: 1.895246982574463 acc: 0.25\n",
            "loss: 2.000469446182251 acc: 0.171875\n",
            "loss: 1.8503366708755493 acc: 0.21875\n",
            "loss: 1.8972526788711548 acc: 0.25\n",
            "loss: 1.9547216892242432 acc: 0.171875\n",
            "loss: 1.8215404748916626 acc: 0.328125\n",
            "loss: 1.9073985815048218 acc: 0.171875\n",
            "loss: 1.9819504022598267 acc: 0.28125\n",
            "loss: 1.8685470819473267 acc: 0.3125\n",
            "loss: 1.9559038877487183 acc: 0.1875\n",
            "loss: 1.9013608694076538 acc: 0.171875\n",
            "loss: 1.894608497619629 acc: 0.171875\n",
            "loss: 1.9141261577606201 acc: 0.234375\n",
            "loss: 1.9179126024246216 acc: 0.28125\n",
            "loss: 1.8785892724990845 acc: 0.25\n",
            "loss: 1.9001942873001099 acc: 0.3125\n",
            "loss: 1.9577019214630127 acc: 0.25\n",
            "loss: 1.9287397861480713 acc: 0.09375\n",
            "loss: 2.015869379043579 acc: 0.125\n",
            "loss: 1.9420794248580933 acc: 0.28125\n",
            "loss: 1.9071375131607056 acc: 0.25\n",
            "loss: 1.9316922426223755 acc: 0.234375\n",
            "loss: 1.8814643621444702 acc: 0.296875\n",
            "loss: 1.8817647695541382 acc: 0.203125\n",
            "loss: 1.8969769477844238 acc: 0.140625\n",
            "loss: 2.101471185684204 acc: 0.21875\n",
            "loss: 1.9861257076263428 acc: 0.21875\n",
            "loss: 1.988541603088379 acc: 0.25\n",
            "loss: 1.9465994834899902 acc: 0.21875\n",
            "loss: 1.8598861694335938 acc: 0.28125\n",
            "loss: 1.901562213897705 acc: 0.25\n",
            "loss: 1.8640170097351074 acc: 0.296875\n",
            "loss: 1.97544264793396 acc: 0.234375\n",
            "loss: 2.0022504329681396 acc: 0.203125\n",
            "loss: 1.970097541809082 acc: 0.234375\n",
            "loss: 1.840695858001709 acc: 0.328125\n",
            "loss: 1.9850459098815918 acc: 0.359375\n",
            "loss: 1.9116404056549072 acc: 0.21875\n",
            "loss: 2.0279786586761475 acc: 0.203125\n",
            "loss: 1.9591950178146362 acc: 0.1875\n",
            "loss: 2.0059449672698975 acc: 0.15625\n",
            "loss: 1.9326682090759277 acc: 0.15625\n",
            "loss: 1.9799690246582031 acc: 0.203125\n",
            "loss: 1.9412121772766113 acc: 0.265625\n",
            "loss: 1.9901221990585327 acc: 0.28125\n",
            "loss: 1.9907902479171753 acc: 0.265625\n",
            "loss: 1.9183028936386108 acc: 0.265625\n",
            "loss: 1.9603562355041504 acc: 0.171875\n",
            "loss: 2.032282590866089 acc: 0.171875\n",
            "loss: 1.9586304426193237 acc: 0.203125\n",
            "loss: 1.9453599452972412 acc: 0.28125\n",
            "loss: 1.9098443984985352 acc: 0.25\n",
            "loss: 2.077362060546875 acc: 0.109375\n",
            "loss: 1.8943746089935303 acc: 0.1875\n",
            "loss: 1.9988845586776733 acc: 0.15625\n",
            "loss: 2.0013859272003174 acc: 0.1875\n",
            "loss: 1.8786170482635498 acc: 0.234375\n",
            "loss: 1.9779967069625854 acc: 0.1875\n",
            "loss: 1.8767590522766113 acc: 0.25\n",
            "loss: 1.8944480419158936 acc: 0.25\n",
            "loss: 1.9228442907333374 acc: 0.234375\n",
            "loss: 2.0271081924438477 acc: 0.203125\n",
            "loss: 1.9185402393341064 acc: 0.25\n",
            "loss: 1.9075629711151123 acc: 0.328125\n",
            "loss: 1.963051438331604 acc: 0.28125\n",
            "loss: 1.9353182315826416 acc: 0.203125\n",
            "loss: 1.9624780416488647 acc: 0.21875\n",
            "loss: 1.9500247240066528 acc: 0.203125\n",
            "loss: 1.8821566104888916 acc: 0.25\n",
            "loss: 1.9189735651016235 acc: 0.234375\n",
            "loss: 2.027799129486084 acc: 0.21875\n",
            "loss: 1.9458857774734497 acc: 0.21875\n",
            "loss: 1.8777216672897339 acc: 0.296875\n",
            "loss: 1.9938867092132568 acc: 0.28125\n",
            "loss: 1.9260952472686768 acc: 0.234375\n",
            "loss: 1.9409477710723877 acc: 0.234375\n",
            "loss: 1.9718419313430786 acc: 0.25\n",
            "loss: 1.933259129524231 acc: 0.25\n",
            "loss: 2.0261054039001465 acc: 0.15625\n",
            "loss: 1.974199891090393 acc: 0.203125\n",
            "loss: 1.9636380672454834 acc: 0.234375\n",
            "loss: 1.9186890125274658 acc: 0.234375\n",
            "loss: 1.909454345703125 acc: 0.21875\n",
            "loss: 1.916427731513977 acc: 0.234375\n",
            "loss: 1.980783224105835 acc: 0.21875\n",
            "loss: 1.9095383882522583 acc: 0.25\n",
            "loss: 1.8768569231033325 acc: 0.234375\n",
            "loss: 1.9331040382385254 acc: 0.203125\n",
            "loss: 1.919675350189209 acc: 0.15625\n",
            "loss: 1.9335802793502808 acc: 0.171875\n",
            "loss: 1.993952751159668 acc: 0.1875\n",
            "loss: 1.9784525632858276 acc: 0.25\n",
            "loss: 1.9009290933609009 acc: 0.1860465109348297\n",
            "94 epoch:\n",
            "loss: 1.868023157119751 acc: 0.265625\n",
            "loss: 2.0203723907470703 acc: 0.203125\n",
            "loss: 1.947007417678833 acc: 0.15625\n",
            "loss: 1.9047635793685913 acc: 0.28125\n",
            "loss: 1.9818928241729736 acc: 0.265625\n",
            "loss: 1.8162716627120972 acc: 0.3125\n",
            "loss: 1.9666597843170166 acc: 0.265625\n",
            "loss: 1.9196765422821045 acc: 0.265625\n",
            "loss: 1.8616201877593994 acc: 0.296875\n",
            "loss: 1.841041088104248 acc: 0.265625\n",
            "loss: 1.884703278541565 acc: 0.25\n",
            "loss: 1.9207335710525513 acc: 0.21875\n",
            "loss: 1.9277536869049072 acc: 0.1875\n",
            "loss: 1.915541172027588 acc: 0.21875\n",
            "loss: 1.9217629432678223 acc: 0.234375\n",
            "loss: 1.9463704824447632 acc: 0.234375\n",
            "loss: 1.9471418857574463 acc: 0.15625\n",
            "loss: 1.8877637386322021 acc: 0.296875\n",
            "loss: 1.8515514135360718 acc: 0.296875\n",
            "loss: 1.9124380350112915 acc: 0.21875\n",
            "loss: 1.8347551822662354 acc: 0.265625\n",
            "loss: 1.8804597854614258 acc: 0.203125\n",
            "loss: 1.968806505203247 acc: 0.1875\n",
            "loss: 1.8696180582046509 acc: 0.265625\n",
            "loss: 1.9075493812561035 acc: 0.265625\n",
            "loss: 1.947274088859558 acc: 0.25\n",
            "loss: 1.996805191040039 acc: 0.15625\n",
            "loss: 1.7556419372558594 acc: 0.34375\n",
            "loss: 1.8204513788223267 acc: 0.28125\n",
            "loss: 1.8388440608978271 acc: 0.3125\n",
            "loss: 1.8854442834854126 acc: 0.328125\n",
            "loss: 1.9047129154205322 acc: 0.203125\n",
            "loss: 1.9051735401153564 acc: 0.265625\n",
            "loss: 1.810255527496338 acc: 0.3125\n",
            "loss: 1.9358680248260498 acc: 0.234375\n",
            "loss: 1.9797452688217163 acc: 0.1875\n",
            "loss: 1.8413679599761963 acc: 0.234375\n",
            "loss: 1.9125499725341797 acc: 0.296875\n",
            "loss: 1.8809782266616821 acc: 0.25\n",
            "loss: 1.9961730241775513 acc: 0.203125\n",
            "loss: 2.0119659900665283 acc: 0.15625\n",
            "loss: 1.969323754310608 acc: 0.15625\n",
            "loss: 1.899743914604187 acc: 0.203125\n",
            "loss: 1.890546202659607 acc: 0.234375\n",
            "loss: 1.9126719236373901 acc: 0.25\n",
            "loss: 1.796323537826538 acc: 0.25\n",
            "loss: 2.039308786392212 acc: 0.171875\n",
            "loss: 2.0115702152252197 acc: 0.140625\n",
            "loss: 1.9528958797454834 acc: 0.171875\n",
            "loss: 1.9309229850769043 acc: 0.28125\n",
            "loss: 1.9006434679031372 acc: 0.265625\n",
            "loss: 2.047029733657837 acc: 0.109375\n",
            "loss: 1.8250207901000977 acc: 0.34375\n",
            "loss: 1.9362777471542358 acc: 0.25\n",
            "loss: 1.8804435729980469 acc: 0.28125\n",
            "loss: 1.987441062927246 acc: 0.25\n",
            "loss: 2.0796964168548584 acc: 0.109375\n",
            "loss: 1.9486322402954102 acc: 0.234375\n",
            "loss: 1.8973454236984253 acc: 0.34375\n",
            "loss: 1.991245985031128 acc: 0.203125\n",
            "loss: 2.046912908554077 acc: 0.171875\n",
            "loss: 1.8533811569213867 acc: 0.25\n",
            "loss: 1.9017586708068848 acc: 0.21875\n",
            "loss: 1.8513652086257935 acc: 0.25\n",
            "loss: 1.971155047416687 acc: 0.25\n",
            "loss: 2.000396728515625 acc: 0.265625\n",
            "loss: 1.9008018970489502 acc: 0.28125\n",
            "loss: 1.9907714128494263 acc: 0.171875\n",
            "loss: 1.970212459564209 acc: 0.234375\n",
            "loss: 2.0258796215057373 acc: 0.1875\n",
            "loss: 2.004265069961548 acc: 0.15625\n",
            "loss: 2.109428882598877 acc: 0.140625\n",
            "loss: 1.9695954322814941 acc: 0.203125\n",
            "loss: 1.9814581871032715 acc: 0.140625\n",
            "loss: 2.034742593765259 acc: 0.078125\n",
            "loss: 1.9987941980361938 acc: 0.15625\n",
            "loss: 1.9025431871414185 acc: 0.265625\n",
            "loss: 1.9416195154190063 acc: 0.203125\n",
            "loss: 1.9033509492874146 acc: 0.171875\n",
            "loss: 1.9253721237182617 acc: 0.203125\n",
            "loss: 1.9732035398483276 acc: 0.125\n",
            "loss: 1.9017244577407837 acc: 0.3125\n",
            "loss: 1.9642672538757324 acc: 0.21875\n",
            "loss: 1.8778975009918213 acc: 0.21875\n",
            "loss: 1.8501466512680054 acc: 0.234375\n",
            "loss: 1.9555317163467407 acc: 0.21875\n",
            "loss: 1.8936346769332886 acc: 0.234375\n",
            "loss: 1.951532244682312 acc: 0.234375\n",
            "loss: 1.872957706451416 acc: 0.296875\n",
            "loss: 1.9782007932662964 acc: 0.203125\n",
            "loss: 1.9930871725082397 acc: 0.125\n",
            "loss: 1.8748868703842163 acc: 0.28125\n",
            "loss: 1.9507478475570679 acc: 0.34375\n",
            "loss: 1.8829718828201294 acc: 0.328125\n",
            "loss: 1.9674758911132812 acc: 0.25\n",
            "loss: 1.984665036201477 acc: 0.28125\n",
            "loss: 1.8493165969848633 acc: 0.296875\n",
            "loss: 1.820650577545166 acc: 0.34375\n",
            "loss: 1.9451453685760498 acc: 0.21875\n",
            "loss: 1.9781931638717651 acc: 0.296875\n",
            "loss: 2.0146238803863525 acc: 0.203125\n",
            "loss: 1.8645225763320923 acc: 0.28125\n",
            "loss: 1.9219063520431519 acc: 0.234375\n",
            "loss: 1.8915363550186157 acc: 0.21875\n",
            "loss: 2.042875289916992 acc: 0.171875\n",
            "loss: 1.9662556648254395 acc: 0.21875\n",
            "loss: 1.932546854019165 acc: 0.21875\n",
            "loss: 1.904871940612793 acc: 0.28125\n",
            "loss: 1.9637341499328613 acc: 0.21875\n",
            "loss: 1.9929457902908325 acc: 0.1627907007932663\n",
            "95 epoch:\n",
            "loss: 1.9848147630691528 acc: 0.171875\n",
            "loss: 1.8845977783203125 acc: 0.296875\n",
            "loss: 1.8077096939086914 acc: 0.28125\n",
            "loss: 1.8337830305099487 acc: 0.296875\n",
            "loss: 1.9941017627716064 acc: 0.28125\n",
            "loss: 1.8751239776611328 acc: 0.21875\n",
            "loss: 1.8557140827178955 acc: 0.28125\n",
            "loss: 1.9079866409301758 acc: 0.328125\n",
            "loss: 1.863296389579773 acc: 0.296875\n",
            "loss: 1.8963687419891357 acc: 0.21875\n",
            "loss: 1.9062491655349731 acc: 0.21875\n",
            "loss: 1.9442840814590454 acc: 0.1875\n",
            "loss: 1.8194347620010376 acc: 0.28125\n",
            "loss: 1.9310531616210938 acc: 0.234375\n",
            "loss: 1.908383846282959 acc: 0.1875\n",
            "loss: 1.7940874099731445 acc: 0.328125\n",
            "loss: 1.8963210582733154 acc: 0.25\n",
            "loss: 1.687086820602417 acc: 0.359375\n",
            "loss: 1.8595678806304932 acc: 0.3125\n",
            "loss: 1.759887456893921 acc: 0.328125\n",
            "loss: 1.8907626867294312 acc: 0.234375\n",
            "loss: 1.856306791305542 acc: 0.28125\n",
            "loss: 1.9974576234817505 acc: 0.203125\n",
            "loss: 2.0153770446777344 acc: 0.171875\n",
            "loss: 1.8837463855743408 acc: 0.375\n",
            "loss: 1.8761355876922607 acc: 0.28125\n",
            "loss: 2.048816680908203 acc: 0.203125\n",
            "loss: 1.9719691276550293 acc: 0.15625\n",
            "loss: 1.8947076797485352 acc: 0.234375\n",
            "loss: 1.9364720582962036 acc: 0.25\n",
            "loss: 1.9578051567077637 acc: 0.234375\n",
            "loss: 1.910088300704956 acc: 0.203125\n",
            "loss: 1.9152920246124268 acc: 0.234375\n",
            "loss: 1.8769354820251465 acc: 0.265625\n",
            "loss: 1.8232769966125488 acc: 0.296875\n",
            "loss: 1.9886904954910278 acc: 0.171875\n",
            "loss: 1.9108986854553223 acc: 0.171875\n",
            "loss: 1.874956727027893 acc: 0.34375\n",
            "loss: 2.031163215637207 acc: 0.15625\n",
            "loss: 2.040994167327881 acc: 0.21875\n",
            "loss: 1.8788000345230103 acc: 0.265625\n",
            "loss: 1.949721336364746 acc: 0.203125\n",
            "loss: 1.9668692350387573 acc: 0.1875\n",
            "loss: 1.8062978982925415 acc: 0.296875\n",
            "loss: 2.008104085922241 acc: 0.15625\n",
            "loss: 1.9044466018676758 acc: 0.265625\n",
            "loss: 1.9269453287124634 acc: 0.28125\n",
            "loss: 1.8146823644638062 acc: 0.28125\n",
            "loss: 1.8976353406906128 acc: 0.21875\n",
            "loss: 1.8722277879714966 acc: 0.28125\n",
            "loss: 2.022212266921997 acc: 0.234375\n",
            "loss: 1.8922096490859985 acc: 0.265625\n",
            "loss: 1.8960906267166138 acc: 0.25\n",
            "loss: 1.879764437675476 acc: 0.1875\n",
            "loss: 1.9347783327102661 acc: 0.265625\n",
            "loss: 1.880133867263794 acc: 0.296875\n",
            "loss: 2.030825138092041 acc: 0.203125\n",
            "loss: 1.9041314125061035 acc: 0.296875\n",
            "loss: 1.938974380493164 acc: 0.28125\n",
            "loss: 1.8208545446395874 acc: 0.21875\n",
            "loss: 1.9844598770141602 acc: 0.21875\n",
            "loss: 1.8804138898849487 acc: 0.171875\n",
            "loss: 1.896287202835083 acc: 0.21875\n",
            "loss: 1.996739149093628 acc: 0.21875\n",
            "loss: 1.8804690837860107 acc: 0.328125\n",
            "loss: 1.8763176202774048 acc: 0.3125\n",
            "loss: 1.9225705862045288 acc: 0.234375\n",
            "loss: 1.9081717729568481 acc: 0.28125\n",
            "loss: 2.060394763946533 acc: 0.25\n",
            "loss: 1.9540612697601318 acc: 0.21875\n",
            "loss: 1.823997139930725 acc: 0.28125\n",
            "loss: 1.8942432403564453 acc: 0.265625\n",
            "loss: 1.9181697368621826 acc: 0.171875\n",
            "loss: 1.8585680723190308 acc: 0.296875\n",
            "loss: 1.9077088832855225 acc: 0.265625\n",
            "loss: 1.896864891052246 acc: 0.28125\n",
            "loss: 1.7990082502365112 acc: 0.28125\n",
            "loss: 1.9399532079696655 acc: 0.234375\n",
            "loss: 1.9261860847473145 acc: 0.234375\n",
            "loss: 2.0682244300842285 acc: 0.203125\n",
            "loss: 1.9382860660552979 acc: 0.25\n",
            "loss: 1.9316599369049072 acc: 0.21875\n",
            "loss: 1.913563847541809 acc: 0.203125\n",
            "loss: 1.961225986480713 acc: 0.203125\n",
            "loss: 1.952573299407959 acc: 0.1875\n",
            "loss: 1.8835062980651855 acc: 0.28125\n",
            "loss: 1.920475721359253 acc: 0.21875\n",
            "loss: 1.8179011344909668 acc: 0.296875\n",
            "loss: 1.8971624374389648 acc: 0.171875\n",
            "loss: 2.0169901847839355 acc: 0.171875\n",
            "loss: 1.8849467039108276 acc: 0.203125\n",
            "loss: 1.9082183837890625 acc: 0.3125\n",
            "loss: 1.9888708591461182 acc: 0.21875\n",
            "loss: 1.8678053617477417 acc: 0.234375\n",
            "loss: 1.943061351776123 acc: 0.171875\n",
            "loss: 1.828637957572937 acc: 0.25\n",
            "loss: 1.9113168716430664 acc: 0.21875\n",
            "loss: 1.8597043752670288 acc: 0.265625\n",
            "loss: 2.0171592235565186 acc: 0.1875\n",
            "loss: 1.8936129808425903 acc: 0.328125\n",
            "loss: 1.9069273471832275 acc: 0.28125\n",
            "loss: 1.847524881362915 acc: 0.3125\n",
            "loss: 1.9122037887573242 acc: 0.1875\n",
            "loss: 1.9337564706802368 acc: 0.234375\n",
            "loss: 1.9779443740844727 acc: 0.1875\n",
            "loss: 1.9045242071151733 acc: 0.234375\n",
            "loss: 1.969254970550537 acc: 0.21875\n",
            "loss: 1.836498737335205 acc: 0.296875\n",
            "loss: 1.913609266281128 acc: 0.203125\n",
            "loss: 1.8896663188934326 acc: 0.23255813121795654\n",
            "96 epoch:\n",
            "loss: 1.8558839559555054 acc: 0.234375\n",
            "loss: 1.9491245746612549 acc: 0.171875\n",
            "loss: 1.8254976272583008 acc: 0.28125\n",
            "loss: 1.9068729877471924 acc: 0.234375\n",
            "loss: 1.9043316841125488 acc: 0.265625\n",
            "loss: 1.8342785835266113 acc: 0.3125\n",
            "loss: 1.9165898561477661 acc: 0.28125\n",
            "loss: 2.041529893875122 acc: 0.1875\n",
            "loss: 1.9792673587799072 acc: 0.203125\n",
            "loss: 1.9615062475204468 acc: 0.25\n",
            "loss: 1.866254210472107 acc: 0.296875\n",
            "loss: 1.85774827003479 acc: 0.296875\n",
            "loss: 1.861114740371704 acc: 0.296875\n",
            "loss: 2.0172221660614014 acc: 0.1875\n",
            "loss: 1.8729937076568604 acc: 0.21875\n",
            "loss: 1.8182834386825562 acc: 0.296875\n",
            "loss: 1.8963069915771484 acc: 0.265625\n",
            "loss: 1.8230750560760498 acc: 0.34375\n",
            "loss: 1.9067357778549194 acc: 0.25\n",
            "loss: 1.874172329902649 acc: 0.21875\n",
            "loss: 1.872116208076477 acc: 0.28125\n",
            "loss: 1.9054497480392456 acc: 0.28125\n",
            "loss: 1.9554816484451294 acc: 0.234375\n",
            "loss: 1.8956103324890137 acc: 0.203125\n",
            "loss: 1.7648766040802002 acc: 0.359375\n",
            "loss: 1.9006662368774414 acc: 0.25\n",
            "loss: 1.852749228477478 acc: 0.296875\n",
            "loss: 1.9328805208206177 acc: 0.265625\n",
            "loss: 1.9344608783721924 acc: 0.25\n",
            "loss: 1.997823715209961 acc: 0.171875\n",
            "loss: 1.8426523208618164 acc: 0.390625\n",
            "loss: 1.9280961751937866 acc: 0.234375\n",
            "loss: 1.9328867197036743 acc: 0.203125\n",
            "loss: 2.0011370182037354 acc: 0.1875\n",
            "loss: 1.9720680713653564 acc: 0.234375\n",
            "loss: 1.9005510807037354 acc: 0.203125\n",
            "loss: 1.862410068511963 acc: 0.328125\n",
            "loss: 1.9838476181030273 acc: 0.21875\n",
            "loss: 1.9041316509246826 acc: 0.25\n",
            "loss: 1.8961448669433594 acc: 0.234375\n",
            "loss: 1.9175193309783936 acc: 0.265625\n",
            "loss: 1.8370550870895386 acc: 0.25\n",
            "loss: 1.9253318309783936 acc: 0.296875\n",
            "loss: 1.8066115379333496 acc: 0.328125\n",
            "loss: 1.8490060567855835 acc: 0.28125\n",
            "loss: 2.0359835624694824 acc: 0.171875\n",
            "loss: 1.844452142715454 acc: 0.203125\n",
            "loss: 2.043517589569092 acc: 0.15625\n",
            "loss: 1.9117414951324463 acc: 0.296875\n",
            "loss: 1.8196265697479248 acc: 0.3125\n",
            "loss: 1.86395263671875 acc: 0.34375\n",
            "loss: 1.9560775756835938 acc: 0.25\n",
            "loss: 1.897937536239624 acc: 0.296875\n",
            "loss: 1.992248296737671 acc: 0.15625\n",
            "loss: 1.9579282999038696 acc: 0.140625\n",
            "loss: 1.9115259647369385 acc: 0.28125\n",
            "loss: 1.8988828659057617 acc: 0.25\n",
            "loss: 1.9547795057296753 acc: 0.203125\n",
            "loss: 1.9575212001800537 acc: 0.28125\n",
            "loss: 1.8925278186798096 acc: 0.28125\n",
            "loss: 2.0424840450286865 acc: 0.265625\n",
            "loss: 1.9237240552902222 acc: 0.25\n",
            "loss: 1.932131290435791 acc: 0.171875\n",
            "loss: 1.9061872959136963 acc: 0.28125\n",
            "loss: 1.8541709184646606 acc: 0.28125\n",
            "loss: 1.9515807628631592 acc: 0.21875\n",
            "loss: 1.9009755849838257 acc: 0.234375\n",
            "loss: 1.9169872999191284 acc: 0.21875\n",
            "loss: 1.8970755338668823 acc: 0.25\n",
            "loss: 2.005640745162964 acc: 0.234375\n",
            "loss: 1.9531174898147583 acc: 0.140625\n",
            "loss: 1.8937950134277344 acc: 0.234375\n",
            "loss: 1.9534188508987427 acc: 0.171875\n",
            "loss: 1.89201021194458 acc: 0.203125\n",
            "loss: 1.9237135648727417 acc: 0.25\n",
            "loss: 1.9036626815795898 acc: 0.171875\n",
            "loss: 1.8820723295211792 acc: 0.28125\n",
            "loss: 1.955167531967163 acc: 0.203125\n",
            "loss: 1.942832589149475 acc: 0.265625\n",
            "loss: 1.8677483797073364 acc: 0.28125\n",
            "loss: 1.7674195766448975 acc: 0.359375\n",
            "loss: 1.8620238304138184 acc: 0.203125\n",
            "loss: 1.9291199445724487 acc: 0.25\n",
            "loss: 1.955216407775879 acc: 0.25\n",
            "loss: 1.9033535718917847 acc: 0.25\n",
            "loss: 1.9115043878555298 acc: 0.265625\n",
            "loss: 1.8865175247192383 acc: 0.25\n",
            "loss: 2.0599987506866455 acc: 0.15625\n",
            "loss: 1.7929219007492065 acc: 0.25\n",
            "loss: 2.0267043113708496 acc: 0.234375\n",
            "loss: 2.0419821739196777 acc: 0.265625\n",
            "loss: 1.8429940938949585 acc: 0.265625\n",
            "loss: 1.8815362453460693 acc: 0.375\n",
            "loss: 1.9566013813018799 acc: 0.171875\n",
            "loss: 1.8053417205810547 acc: 0.34375\n",
            "loss: 1.8191219568252563 acc: 0.25\n",
            "loss: 1.911900520324707 acc: 0.25\n",
            "loss: 1.8194012641906738 acc: 0.34375\n",
            "loss: 1.8197678327560425 acc: 0.28125\n",
            "loss: 2.028562545776367 acc: 0.203125\n",
            "loss: 1.8863967657089233 acc: 0.21875\n",
            "loss: 1.9563465118408203 acc: 0.171875\n",
            "loss: 1.8590331077575684 acc: 0.234375\n",
            "loss: 1.915459394454956 acc: 0.203125\n",
            "loss: 1.915431022644043 acc: 0.25\n",
            "loss: 1.8869010210037231 acc: 0.25\n",
            "loss: 1.8934799432754517 acc: 0.21875\n",
            "loss: 1.8188303709030151 acc: 0.28125\n",
            "loss: 1.8972779512405396 acc: 0.234375\n",
            "loss: 1.852185845375061 acc: 0.302325576543808\n",
            "97 epoch:\n",
            "loss: 1.8172473907470703 acc: 0.328125\n",
            "loss: 1.8992128372192383 acc: 0.1875\n",
            "loss: 1.8697865009307861 acc: 0.234375\n",
            "loss: 1.9247382879257202 acc: 0.203125\n",
            "loss: 1.9856773614883423 acc: 0.25\n",
            "loss: 1.966833472251892 acc: 0.203125\n",
            "loss: 1.862462043762207 acc: 0.21875\n",
            "loss: 1.865966796875 acc: 0.265625\n",
            "loss: 1.905623197555542 acc: 0.21875\n",
            "loss: 1.8937164545059204 acc: 0.234375\n",
            "loss: 1.8592259883880615 acc: 0.203125\n",
            "loss: 1.865077018737793 acc: 0.296875\n",
            "loss: 1.9126336574554443 acc: 0.21875\n",
            "loss: 1.8987069129943848 acc: 0.28125\n",
            "loss: 1.8512171506881714 acc: 0.234375\n",
            "loss: 1.8872528076171875 acc: 0.1875\n",
            "loss: 1.882115125656128 acc: 0.25\n",
            "loss: 1.8215076923370361 acc: 0.234375\n",
            "loss: 1.8799337148666382 acc: 0.328125\n",
            "loss: 1.9107779264450073 acc: 0.203125\n",
            "loss: 1.8426823616027832 acc: 0.25\n",
            "loss: 1.9018181562423706 acc: 0.203125\n",
            "loss: 1.8768315315246582 acc: 0.328125\n",
            "loss: 1.9364213943481445 acc: 0.1875\n",
            "loss: 2.0236260890960693 acc: 0.25\n",
            "loss: 1.910913109779358 acc: 0.265625\n",
            "loss: 1.9827568531036377 acc: 0.25\n",
            "loss: 1.8816038370132446 acc: 0.265625\n",
            "loss: 1.934818148612976 acc: 0.296875\n",
            "loss: 1.9563148021697998 acc: 0.1875\n",
            "loss: 1.8434189558029175 acc: 0.234375\n",
            "loss: 1.9449937343597412 acc: 0.203125\n",
            "loss: 1.9104197025299072 acc: 0.234375\n",
            "loss: 1.9824663400650024 acc: 0.171875\n",
            "loss: 1.9857587814331055 acc: 0.1875\n",
            "loss: 1.8837727308273315 acc: 0.234375\n",
            "loss: 1.9222882986068726 acc: 0.234375\n",
            "loss: 1.97165846824646 acc: 0.21875\n",
            "loss: 1.8543682098388672 acc: 0.28125\n",
            "loss: 1.9058237075805664 acc: 0.171875\n",
            "loss: 1.909433126449585 acc: 0.296875\n",
            "loss: 1.9814404249191284 acc: 0.15625\n",
            "loss: 1.9160842895507812 acc: 0.296875\n",
            "loss: 1.9032838344573975 acc: 0.171875\n",
            "loss: 1.8745689392089844 acc: 0.296875\n",
            "loss: 1.9449504613876343 acc: 0.21875\n",
            "loss: 1.8997572660446167 acc: 0.171875\n",
            "loss: 1.9420826435089111 acc: 0.171875\n",
            "loss: 2.006284475326538 acc: 0.25\n",
            "loss: 1.9437758922576904 acc: 0.234375\n",
            "loss: 1.8318030834197998 acc: 0.296875\n",
            "loss: 1.8693307638168335 acc: 0.234375\n",
            "loss: 1.8904006481170654 acc: 0.34375\n",
            "loss: 1.843170404434204 acc: 0.296875\n",
            "loss: 1.8110930919647217 acc: 0.328125\n",
            "loss: 1.941554069519043 acc: 0.203125\n",
            "loss: 1.855881929397583 acc: 0.203125\n",
            "loss: 1.9180827140808105 acc: 0.25\n",
            "loss: 1.9206030368804932 acc: 0.28125\n",
            "loss: 1.94353449344635 acc: 0.203125\n",
            "loss: 1.9283910989761353 acc: 0.3125\n",
            "loss: 1.8763668537139893 acc: 0.203125\n",
            "loss: 2.081834554672241 acc: 0.125\n",
            "loss: 1.9267675876617432 acc: 0.328125\n",
            "loss: 1.8372236490249634 acc: 0.21875\n",
            "loss: 1.8278168439865112 acc: 0.3125\n",
            "loss: 1.8562965393066406 acc: 0.28125\n",
            "loss: 1.9179514646530151 acc: 0.34375\n",
            "loss: 1.8446317911148071 acc: 0.265625\n",
            "loss: 1.9317760467529297 acc: 0.140625\n",
            "loss: 1.8016445636749268 acc: 0.328125\n",
            "loss: 1.9284480810165405 acc: 0.265625\n",
            "loss: 1.9462441205978394 acc: 0.234375\n",
            "loss: 1.7942084074020386 acc: 0.34375\n",
            "loss: 1.86896550655365 acc: 0.25\n",
            "loss: 1.8261491060256958 acc: 0.3125\n",
            "loss: 1.895355224609375 acc: 0.25\n",
            "loss: 1.8551241159439087 acc: 0.265625\n",
            "loss: 2.0698018074035645 acc: 0.15625\n",
            "loss: 1.7514203786849976 acc: 0.40625\n",
            "loss: 1.8808839321136475 acc: 0.28125\n",
            "loss: 1.8839651346206665 acc: 0.234375\n",
            "loss: 1.835670828819275 acc: 0.25\n",
            "loss: 1.8479406833648682 acc: 0.296875\n",
            "loss: 1.8819246292114258 acc: 0.25\n",
            "loss: 1.9231003522872925 acc: 0.234375\n",
            "loss: 1.7969897985458374 acc: 0.328125\n",
            "loss: 1.885680913925171 acc: 0.25\n",
            "loss: 1.9379092454910278 acc: 0.1875\n",
            "loss: 1.983022689819336 acc: 0.140625\n",
            "loss: 1.8880633115768433 acc: 0.234375\n",
            "loss: 1.9766749143600464 acc: 0.21875\n",
            "loss: 1.934824824333191 acc: 0.25\n",
            "loss: 2.018728017807007 acc: 0.171875\n",
            "loss: 1.8409180641174316 acc: 0.25\n",
            "loss: 1.958615779876709 acc: 0.234375\n",
            "loss: 1.8807638883590698 acc: 0.28125\n",
            "loss: 1.8974820375442505 acc: 0.28125\n",
            "loss: 1.9328678846359253 acc: 0.203125\n",
            "loss: 1.8563288450241089 acc: 0.265625\n",
            "loss: 1.8932065963745117 acc: 0.265625\n",
            "loss: 1.8521192073822021 acc: 0.28125\n",
            "loss: 1.8439109325408936 acc: 0.265625\n",
            "loss: 1.7808611392974854 acc: 0.265625\n",
            "loss: 1.8440979719161987 acc: 0.234375\n",
            "loss: 1.861570954322815 acc: 0.21875\n",
            "loss: 1.8920170068740845 acc: 0.25\n",
            "loss: 1.9818768501281738 acc: 0.234375\n",
            "loss: 1.8890894651412964 acc: 0.234375\n",
            "loss: 1.9681804180145264 acc: 0.20930232107639313\n",
            "98 epoch:\n",
            "loss: 1.8898677825927734 acc: 0.25\n",
            "loss: 1.7301673889160156 acc: 0.296875\n",
            "loss: 1.9571973085403442 acc: 0.1875\n",
            "loss: 1.9398376941680908 acc: 0.1875\n",
            "loss: 1.8333138227462769 acc: 0.328125\n",
            "loss: 1.9464609622955322 acc: 0.21875\n",
            "loss: 1.8441503047943115 acc: 0.34375\n",
            "loss: 1.883123517036438 acc: 0.21875\n",
            "loss: 1.8446370363235474 acc: 0.25\n",
            "loss: 1.9214686155319214 acc: 0.203125\n",
            "loss: 1.8275564908981323 acc: 0.296875\n",
            "loss: 1.885322093963623 acc: 0.28125\n",
            "loss: 1.7904294729232788 acc: 0.3125\n",
            "loss: 1.9445172548294067 acc: 0.21875\n",
            "loss: 1.8055014610290527 acc: 0.34375\n",
            "loss: 1.8590400218963623 acc: 0.28125\n",
            "loss: 1.841174602508545 acc: 0.328125\n",
            "loss: 1.960810661315918 acc: 0.25\n",
            "loss: 1.8309412002563477 acc: 0.296875\n",
            "loss: 1.9104949235916138 acc: 0.234375\n",
            "loss: 1.8831071853637695 acc: 0.28125\n",
            "loss: 1.9631706476211548 acc: 0.15625\n",
            "loss: 1.8892481327056885 acc: 0.234375\n",
            "loss: 1.8424415588378906 acc: 0.34375\n",
            "loss: 1.9244751930236816 acc: 0.234375\n",
            "loss: 1.7887818813323975 acc: 0.3125\n",
            "loss: 1.8866097927093506 acc: 0.265625\n",
            "loss: 1.9097633361816406 acc: 0.265625\n",
            "loss: 1.8841333389282227 acc: 0.21875\n",
            "loss: 1.9737290143966675 acc: 0.25\n",
            "loss: 1.7838586568832397 acc: 0.296875\n",
            "loss: 1.8517554998397827 acc: 0.28125\n",
            "loss: 1.8352279663085938 acc: 0.234375\n",
            "loss: 1.682019829750061 acc: 0.34375\n",
            "loss: 2.06018328666687 acc: 0.203125\n",
            "loss: 1.7830650806427002 acc: 0.28125\n",
            "loss: 1.8555686473846436 acc: 0.265625\n",
            "loss: 1.883394718170166 acc: 0.25\n",
            "loss: 1.8450405597686768 acc: 0.28125\n",
            "loss: 1.8013582229614258 acc: 0.328125\n",
            "loss: 1.8567754030227661 acc: 0.296875\n",
            "loss: 1.88527250289917 acc: 0.21875\n",
            "loss: 1.908111572265625 acc: 0.265625\n",
            "loss: 1.9116857051849365 acc: 0.234375\n",
            "loss: 1.7985494136810303 acc: 0.234375\n",
            "loss: 1.8741837739944458 acc: 0.234375\n",
            "loss: 1.8251092433929443 acc: 0.28125\n",
            "loss: 1.8860193490982056 acc: 0.203125\n",
            "loss: 1.9336106777191162 acc: 0.203125\n",
            "loss: 1.8102785348892212 acc: 0.328125\n",
            "loss: 1.9125375747680664 acc: 0.296875\n",
            "loss: 1.8337661027908325 acc: 0.296875\n",
            "loss: 1.8513340950012207 acc: 0.25\n",
            "loss: 1.8969104290008545 acc: 0.21875\n",
            "loss: 1.8985388278961182 acc: 0.15625\n",
            "loss: 2.0886850357055664 acc: 0.203125\n",
            "loss: 1.9816715717315674 acc: 0.15625\n",
            "loss: 1.853722095489502 acc: 0.28125\n",
            "loss: 1.8959567546844482 acc: 0.265625\n",
            "loss: 1.874515414237976 acc: 0.203125\n",
            "loss: 1.8640328645706177 acc: 0.28125\n",
            "loss: 1.9333446025848389 acc: 0.171875\n",
            "loss: 1.95369553565979 acc: 0.1875\n",
            "loss: 1.8500564098358154 acc: 0.234375\n",
            "loss: 1.7734609842300415 acc: 0.296875\n",
            "loss: 1.9444904327392578 acc: 0.265625\n",
            "loss: 1.8965420722961426 acc: 0.21875\n",
            "loss: 1.8952014446258545 acc: 0.25\n",
            "loss: 1.8802151679992676 acc: 0.3125\n",
            "loss: 1.9339478015899658 acc: 0.328125\n",
            "loss: 1.9641729593276978 acc: 0.21875\n",
            "loss: 2.008570671081543 acc: 0.21875\n",
            "loss: 1.835508942604065 acc: 0.359375\n",
            "loss: 1.8367804288864136 acc: 0.203125\n",
            "loss: 1.934904932975769 acc: 0.21875\n",
            "loss: 1.934871792793274 acc: 0.234375\n",
            "loss: 1.8851510286331177 acc: 0.28125\n",
            "loss: 1.8742690086364746 acc: 0.21875\n",
            "loss: 2.018721580505371 acc: 0.1875\n",
            "loss: 2.0686397552490234 acc: 0.171875\n",
            "loss: 1.8852707147598267 acc: 0.265625\n",
            "loss: 1.7697643041610718 acc: 0.375\n",
            "loss: 1.7947126626968384 acc: 0.265625\n",
            "loss: 1.9272526502609253 acc: 0.21875\n",
            "loss: 1.8090041875839233 acc: 0.3125\n",
            "loss: 1.9770549535751343 acc: 0.203125\n",
            "loss: 1.9862921237945557 acc: 0.203125\n",
            "loss: 2.1385605335235596 acc: 0.15625\n",
            "loss: 1.8911912441253662 acc: 0.3125\n",
            "loss: 1.9227548837661743 acc: 0.1875\n",
            "loss: 1.8663049936294556 acc: 0.203125\n",
            "loss: 1.9942172765731812 acc: 0.140625\n",
            "loss: 1.9770537614822388 acc: 0.203125\n",
            "loss: 1.9122997522354126 acc: 0.21875\n",
            "loss: 2.020158529281616 acc: 0.1875\n",
            "loss: 1.8752658367156982 acc: 0.265625\n",
            "loss: 1.9436447620391846 acc: 0.1875\n",
            "loss: 1.9750392436981201 acc: 0.21875\n",
            "loss: 1.931524395942688 acc: 0.1875\n",
            "loss: 1.8783714771270752 acc: 0.25\n",
            "loss: 1.945724606513977 acc: 0.21875\n",
            "loss: 1.8851029872894287 acc: 0.328125\n",
            "loss: 1.9121348857879639 acc: 0.28125\n",
            "loss: 1.9692635536193848 acc: 0.3125\n",
            "loss: 1.9189010858535767 acc: 0.234375\n",
            "loss: 1.9571231603622437 acc: 0.15625\n",
            "loss: 1.877694845199585 acc: 0.203125\n",
            "loss: 1.9034192562103271 acc: 0.265625\n",
            "loss: 1.923141598701477 acc: 0.203125\n",
            "loss: 1.9470956325531006 acc: 0.23255813121795654\n",
            "99 epoch:\n",
            "loss: 1.8388012647628784 acc: 0.359375\n",
            "loss: 1.8788831233978271 acc: 0.1875\n",
            "loss: 1.8209280967712402 acc: 0.328125\n",
            "loss: 1.840924620628357 acc: 0.234375\n",
            "loss: 1.7927318811416626 acc: 0.296875\n",
            "loss: 1.951492428779602 acc: 0.203125\n",
            "loss: 1.7945929765701294 acc: 0.25\n",
            "loss: 1.8091288805007935 acc: 0.28125\n",
            "loss: 1.8265595436096191 acc: 0.296875\n",
            "loss: 2.006840705871582 acc: 0.21875\n",
            "loss: 1.7727433443069458 acc: 0.328125\n",
            "loss: 1.813948631286621 acc: 0.265625\n",
            "loss: 1.761460781097412 acc: 0.28125\n",
            "loss: 1.8748631477355957 acc: 0.34375\n",
            "loss: 1.8137366771697998 acc: 0.28125\n",
            "loss: 1.696565866470337 acc: 0.359375\n",
            "loss: 1.7406519651412964 acc: 0.375\n",
            "loss: 1.9748648405075073 acc: 0.203125\n",
            "loss: 1.8919895887374878 acc: 0.28125\n",
            "loss: 1.802570104598999 acc: 0.375\n",
            "loss: 1.7318094968795776 acc: 0.375\n",
            "loss: 1.8228633403778076 acc: 0.3125\n",
            "loss: 1.7843719720840454 acc: 0.328125\n",
            "loss: 1.829297661781311 acc: 0.328125\n",
            "loss: 1.9029200077056885 acc: 0.28125\n",
            "loss: 1.8310551643371582 acc: 0.359375\n",
            "loss: 1.90579092502594 acc: 0.296875\n",
            "loss: 1.7525264024734497 acc: 0.328125\n",
            "loss: 1.8430559635162354 acc: 0.28125\n",
            "loss: 1.832358717918396 acc: 0.21875\n",
            "loss: 1.9363296031951904 acc: 0.25\n",
            "loss: 1.9432802200317383 acc: 0.203125\n",
            "loss: 1.7744743824005127 acc: 0.296875\n",
            "loss: 2.018841505050659 acc: 0.203125\n",
            "loss: 1.8601645231246948 acc: 0.265625\n",
            "loss: 1.8792853355407715 acc: 0.25\n",
            "loss: 1.8413423299789429 acc: 0.25\n",
            "loss: 1.8450398445129395 acc: 0.28125\n",
            "loss: 1.8735750913619995 acc: 0.234375\n",
            "loss: 1.765755534172058 acc: 0.359375\n",
            "loss: 1.9169975519180298 acc: 0.234375\n",
            "loss: 1.884985327720642 acc: 0.265625\n",
            "loss: 2.0595250129699707 acc: 0.1875\n",
            "loss: 1.8552337884902954 acc: 0.25\n",
            "loss: 1.9036273956298828 acc: 0.203125\n",
            "loss: 1.8889766931533813 acc: 0.1875\n",
            "loss: 1.8488810062408447 acc: 0.296875\n",
            "loss: 1.8649629354476929 acc: 0.265625\n",
            "loss: 1.7580710649490356 acc: 0.28125\n",
            "loss: 1.8732593059539795 acc: 0.203125\n",
            "loss: 1.8362919092178345 acc: 0.28125\n",
            "loss: 1.8347961902618408 acc: 0.265625\n",
            "loss: 1.857577919960022 acc: 0.265625\n",
            "loss: 1.9167885780334473 acc: 0.21875\n",
            "loss: 1.8593249320983887 acc: 0.28125\n",
            "loss: 1.8450284004211426 acc: 0.28125\n",
            "loss: 1.896195411682129 acc: 0.28125\n",
            "loss: 1.91327965259552 acc: 0.296875\n",
            "loss: 1.844360589981079 acc: 0.3125\n",
            "loss: 1.8938642740249634 acc: 0.234375\n",
            "loss: 1.8728750944137573 acc: 0.25\n",
            "loss: 1.8790485858917236 acc: 0.1875\n",
            "loss: 2.0507075786590576 acc: 0.1875\n",
            "loss: 1.9457718133926392 acc: 0.1875\n",
            "loss: 1.9225879907608032 acc: 0.1875\n",
            "loss: 1.8397881984710693 acc: 0.296875\n",
            "loss: 1.8939169645309448 acc: 0.3125\n",
            "loss: 2.0314276218414307 acc: 0.1875\n",
            "loss: 1.7665905952453613 acc: 0.359375\n",
            "loss: 1.8782095909118652 acc: 0.171875\n",
            "loss: 1.9281435012817383 acc: 0.234375\n",
            "loss: 2.0477941036224365 acc: 0.1875\n",
            "loss: 1.8437186479568481 acc: 0.265625\n",
            "loss: 1.8852993249893188 acc: 0.25\n",
            "loss: 1.941498875617981 acc: 0.21875\n",
            "loss: 1.9047085046768188 acc: 0.3125\n",
            "loss: 2.0081734657287598 acc: 0.15625\n",
            "loss: 1.8770848512649536 acc: 0.296875\n",
            "loss: 1.992936611175537 acc: 0.25\n",
            "loss: 2.0577895641326904 acc: 0.125\n",
            "loss: 1.8135111331939697 acc: 0.28125\n",
            "loss: 1.8416332006454468 acc: 0.28125\n",
            "loss: 1.8932467699050903 acc: 0.265625\n",
            "loss: 1.8375272750854492 acc: 0.265625\n",
            "loss: 1.8893874883651733 acc: 0.25\n",
            "loss: 1.7678276300430298 acc: 0.28125\n",
            "loss: 1.9456053972244263 acc: 0.296875\n",
            "loss: 1.894431233406067 acc: 0.21875\n",
            "loss: 1.8309048414230347 acc: 0.296875\n",
            "loss: 1.9299111366271973 acc: 0.25\n",
            "loss: 1.8195093870162964 acc: 0.265625\n",
            "loss: 1.8373265266418457 acc: 0.265625\n",
            "loss: 1.852021336555481 acc: 0.328125\n",
            "loss: 1.9931490421295166 acc: 0.171875\n",
            "loss: 1.9817092418670654 acc: 0.1875\n",
            "loss: 1.8668107986450195 acc: 0.265625\n",
            "loss: 1.8992301225662231 acc: 0.296875\n",
            "loss: 1.8800610303878784 acc: 0.28125\n",
            "loss: 1.877821683883667 acc: 0.234375\n",
            "loss: 1.96308434009552 acc: 0.3125\n",
            "loss: 1.9496972560882568 acc: 0.171875\n",
            "loss: 1.8480783700942993 acc: 0.296875\n",
            "loss: 1.9935134649276733 acc: 0.203125\n",
            "loss: 1.8932099342346191 acc: 0.15625\n",
            "loss: 1.7856812477111816 acc: 0.34375\n",
            "loss: 2.0261967182159424 acc: 0.109375\n",
            "loss: 1.9129829406738281 acc: 0.203125\n",
            "loss: 1.8452987670898438 acc: 0.359375\n",
            "loss: 2.0203404426574707 acc: 0.125\n",
            "loss: 1.8995096683502197 acc: 0.25581395626068115\n",
            "100 epoch:\n",
            "loss: 1.7631257772445679 acc: 0.34375\n",
            "loss: 1.8079280853271484 acc: 0.421875\n",
            "loss: 1.7071341276168823 acc: 0.34375\n",
            "loss: 1.8388373851776123 acc: 0.28125\n",
            "loss: 1.8508281707763672 acc: 0.25\n",
            "loss: 1.8361010551452637 acc: 0.25\n",
            "loss: 1.8517392873764038 acc: 0.296875\n",
            "loss: 1.8878848552703857 acc: 0.21875\n",
            "loss: 1.979886531829834 acc: 0.109375\n",
            "loss: 1.807484745979309 acc: 0.34375\n",
            "loss: 1.8674108982086182 acc: 0.21875\n",
            "loss: 1.8988761901855469 acc: 0.265625\n",
            "loss: 1.7923468351364136 acc: 0.28125\n",
            "loss: 1.8790136575698853 acc: 0.140625\n",
            "loss: 1.8628387451171875 acc: 0.25\n",
            "loss: 1.8921935558319092 acc: 0.28125\n",
            "loss: 1.7800750732421875 acc: 0.34375\n",
            "loss: 1.7424991130828857 acc: 0.328125\n",
            "loss: 1.8542371988296509 acc: 0.3125\n",
            "loss: 1.9875222444534302 acc: 0.1875\n",
            "loss: 1.8907607793807983 acc: 0.25\n",
            "loss: 1.9054901599884033 acc: 0.328125\n",
            "loss: 2.0620713233947754 acc: 0.21875\n",
            "loss: 1.84037446975708 acc: 0.296875\n",
            "loss: 1.850178599357605 acc: 0.28125\n",
            "loss: 1.9376602172851562 acc: 0.265625\n",
            "loss: 1.993279218673706 acc: 0.21875\n",
            "loss: 1.8693643808364868 acc: 0.28125\n",
            "loss: 1.987060785293579 acc: 0.28125\n",
            "loss: 1.819808840751648 acc: 0.296875\n",
            "loss: 1.9761269092559814 acc: 0.1875\n",
            "loss: 1.9618489742279053 acc: 0.171875\n",
            "loss: 1.9381035566329956 acc: 0.203125\n",
            "loss: 2.0712080001831055 acc: 0.1875\n",
            "loss: 1.911120057106018 acc: 0.1875\n",
            "loss: 1.8325248956680298 acc: 0.28125\n",
            "loss: 1.8280153274536133 acc: 0.28125\n",
            "loss: 1.8036571741104126 acc: 0.234375\n",
            "loss: 1.849401593208313 acc: 0.3125\n",
            "loss: 1.9067869186401367 acc: 0.25\n",
            "loss: 1.8056762218475342 acc: 0.328125\n",
            "loss: 1.8127766847610474 acc: 0.28125\n",
            "loss: 1.9175810813903809 acc: 0.296875\n",
            "loss: 1.8432005643844604 acc: 0.15625\n",
            "loss: 1.9621366262435913 acc: 0.171875\n",
            "loss: 1.9290684461593628 acc: 0.21875\n",
            "loss: 1.8678234815597534 acc: 0.265625\n",
            "loss: 1.9229168891906738 acc: 0.1875\n",
            "loss: 1.8731963634490967 acc: 0.25\n",
            "loss: 1.7907512187957764 acc: 0.328125\n",
            "loss: 1.858317494392395 acc: 0.34375\n",
            "loss: 1.8711457252502441 acc: 0.265625\n",
            "loss: 1.8592967987060547 acc: 0.21875\n",
            "loss: 1.8676897287368774 acc: 0.21875\n",
            "loss: 1.9235023260116577 acc: 0.203125\n",
            "loss: 1.9472763538360596 acc: 0.234375\n",
            "loss: 1.9636988639831543 acc: 0.203125\n",
            "loss: 1.9949125051498413 acc: 0.234375\n",
            "loss: 1.8673067092895508 acc: 0.265625\n",
            "loss: 1.8890196084976196 acc: 0.234375\n",
            "loss: 1.9203643798828125 acc: 0.25\n",
            "loss: 1.786240577697754 acc: 0.28125\n",
            "loss: 1.9100801944732666 acc: 0.28125\n",
            "loss: 1.894749402999878 acc: 0.203125\n",
            "loss: 1.9213634729385376 acc: 0.1875\n",
            "loss: 1.878100872039795 acc: 0.265625\n",
            "loss: 1.9265410900115967 acc: 0.1875\n",
            "loss: 1.857470154762268 acc: 0.3125\n",
            "loss: 1.795055866241455 acc: 0.3125\n",
            "loss: 1.9941487312316895 acc: 0.171875\n",
            "loss: 1.924410343170166 acc: 0.234375\n",
            "loss: 1.8573232889175415 acc: 0.25\n",
            "loss: 1.8999406099319458 acc: 0.1875\n",
            "loss: 1.849226713180542 acc: 0.28125\n",
            "loss: 1.8029955625534058 acc: 0.25\n",
            "loss: 1.7158470153808594 acc: 0.375\n",
            "loss: 1.8952507972717285 acc: 0.15625\n",
            "loss: 1.875304937362671 acc: 0.28125\n",
            "loss: 1.8567618131637573 acc: 0.265625\n",
            "loss: 1.6496021747589111 acc: 0.40625\n",
            "loss: 1.8683539628982544 acc: 0.28125\n",
            "loss: 1.8147778511047363 acc: 0.265625\n",
            "loss: 1.8849810361862183 acc: 0.21875\n",
            "loss: 1.8628934621810913 acc: 0.265625\n",
            "loss: 1.855254888534546 acc: 0.265625\n",
            "loss: 1.7768193483352661 acc: 0.265625\n",
            "loss: 1.869657039642334 acc: 0.296875\n",
            "loss: 1.8702998161315918 acc: 0.171875\n",
            "loss: 1.7858906984329224 acc: 0.3125\n",
            "loss: 1.7923563718795776 acc: 0.25\n",
            "loss: 1.8462016582489014 acc: 0.265625\n",
            "loss: 1.8365479707717896 acc: 0.34375\n",
            "loss: 2.0138134956359863 acc: 0.140625\n",
            "loss: 1.8029446601867676 acc: 0.28125\n",
            "loss: 1.83636474609375 acc: 0.296875\n",
            "loss: 1.9216010570526123 acc: 0.203125\n",
            "loss: 1.9354815483093262 acc: 0.28125\n",
            "loss: 1.888188362121582 acc: 0.359375\n",
            "loss: 1.811854600906372 acc: 0.328125\n",
            "loss: 1.9253323078155518 acc: 0.234375\n",
            "loss: 1.8474037647247314 acc: 0.28125\n",
            "loss: 1.8277251720428467 acc: 0.359375\n",
            "loss: 1.8973004817962646 acc: 0.203125\n",
            "loss: 1.9112952947616577 acc: 0.234375\n",
            "loss: 1.8873543739318848 acc: 0.28125\n",
            "loss: 1.7674204111099243 acc: 0.296875\n",
            "loss: 1.8777501583099365 acc: 0.203125\n",
            "loss: 1.8515278100967407 acc: 0.265625\n",
            "loss: 2.0010616779327393 acc: 0.203125\n",
            "loss: 1.7445762157440186 acc: 0.302325576543808\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 2.2148420810699463 top1: 0.09375\n",
            "loss: 2.3595287799835205 top1: 0.140625\n",
            "loss: 2.1996958255767822 top1: 0.203125\n",
            "loss: 2.3099417686462402 top1: 0.109375\n",
            "loss: 2.187011957168579 top1: 0.078125\n",
            "loss: 2.1475861072540283 top1: 0.234375\n",
            "loss: 2.366140604019165 top1: 0.09375\n",
            "loss: 2.175977945327759 top1: 0.1875\n",
            "loss: 2.1622865200042725 top1: 0.171875\n",
            "loss: 2.2420008182525635 top1: 0.046875\n",
            "loss: 2.333207368850708 top1: 0.078125\n",
            "loss: 2.185371160507202 top1: 0.140625\n",
            "loss: 2.204240560531616 top1: 0.171875\n",
            "loss: 2.189215898513794 top1: 0.21875\n",
            "loss: 2.361299753189087 top1: 0.09375\n",
            "loss: 2.1898486614227295 top1: 0.203125\n",
            "loss: 2.391968011856079 top1: 0.09375\n",
            "loss: 2.139730930328369 top1: 0.15625\n",
            "loss: 2.2002902030944824 top1: 0.15625\n",
            "loss: 2.3006110191345215 top1: 0.09375\n",
            "loss: 2.217603921890259 top1: 0.09375\n",
            "loss: 2.3263492584228516 top1: 0.09375\n",
            "loss: 2.380478858947754 top1: 0.109375\n",
            "loss: 2.2862842082977295 top1: 0.078125\n",
            "loss: 2.2620766162872314 top1: 0.140625\n",
            "loss: 2.2191991806030273 top1: 0.15625\n",
            "loss: 2.284498453140259 top1: 0.140625\n",
            "loss: 2.004655599594116 top1: 0.29629629850387573\n",
            "\n",
            "\n",
            "Top-1 Accuracy: 0.1350427269935608\n"
          ]
        }
      ],
      "source": [
        "# main function\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    root_path = r'/content/drive/MyDrive/grey/'\n",
        "    train_data_file=r'/content/drive/MyDrive/grey/2bintrainval.txt'\n",
        "    test_data_file=r'/content/drive/MyDrive/grey/2bintest.txt'\n",
        "    batch_size=64\n",
        "    lr=best_trial.params['lr'] #learning rate\n",
        "    epoch_num=best_trial.params['epoch_num']\n",
        "    layers=best_trial.params['n_layer']\n",
        "    kernals=best_trial.params['kernel_size']\n",
        "    # lr=0.01 #learning rate\n",
        "    # epoch_num=100\n",
        "    # layers=5\n",
        "    # kernals=5\n",
        "    device='cuda:0'\n",
        "    # get model and put model on the device\n",
        "    model=CNet(n_layer = layers, kernel_size = kernals)\n",
        "    model.to(device)\n",
        "\n",
        "    training(model,root_path,train_data_file,batch_size,lr,epoch_num)\n",
        "    torch.cuda.empty_cache()\n",
        "    test(model,root_path,test_data_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "827tZvE7OP_N"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}